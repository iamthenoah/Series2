The Vision of Software Clone Management:
Past, Present, and Future (Keynote Paper)
Chanchal K. Roy Minhaz F. Zibran Rainer Koschke y
University of Saskatchewan, Canada yUniversity of Bremen, Germany
{chanchal.roy, minhaz.zibran}@usask.ca, koschke@informatik.uni-bremen.de
Abstract —Duplicated code or code clones are a kind of code
smell that have both positive and negative impacts on the
development and maintenance of software systems. Software
clone research in the past mostly focused on the detection
and analysis of code clones, while research in recent years
extends to the whole spectrum of clone management. In the last
decade, three surveys appeared in the literature, which cover
the detection, analysis, and evolutionary characteristics of code
clones. This paper presents a comprehensive survey on the state
of the art in clone management, with in-depth investigation
of clone management activities (e.g., tracing, refactoring, cost-
beneﬁt analysis) beyond the detection and analysis. This is
the ﬁrst survey on clone management, where we point to the
achievements so far, and reveal avenues for further research
necessary towards an integrated clone management system. We
believe that we have done a good job in surveying the area of
clone management and that this work may serve as a roadmap
for future research in the area
Index Terms —Code Clones, Clone Analysis, Clone Manage-
ment, Future Research Directions
I. I NTRODUCTION AND MOTIVATION
Copying existing code and pasting it in somewhere else
followed by minor or major edits is a common practice
that developers adopt to increase productivity. Such a reuse
mechanism typically results in duplicate or very similar code
fragments residing in the code base. Those duplicate or near-
duplicate code segments are commonly known as code clones.
There are many reasons why developers intentionally perform
such code cloning. Obvious reasons include reuse of exist-
ing implementations without “re-inventing the wheel". More
comprehensive discussions on the reasons for code cloning
can be found elsewhere [104]. Code clones may also appear
in the code base without the awareness of the developers.
Such unintentional/accidental clones may be introduced, for
example, due to the use of certain design patterns, use of
certain APIs to accomplish similar programming tasks, or
coding conventions imposed by the organization.
The reuse mechanism by code cloning offers some beneﬁts.
For instance, cloning of existing code that is already known to
be ﬂawless, might save the developers from probable mistakes
they might have made if they had to implement the same from
scratch. It also saves time and effort in devising the logic
and typing the corresponding textual code. Code cloning may
also help in decoupling classes or components and facilitate
independent evolution of similar feature implementations.
On the other end of the spectrum, code clones may also
be detrimental in many cases. Obviously, redundant code mayinﬂate the code base and may increase resource requirements.
This may be crucial for embedded systems and systems such
as hand held devices, telecommunication switches, and small
sensor systems. Moreover, cloning a code snippet that contains
any unknown fault may result in propagation of that fault
to all copies of the faulty fragment. From the maintenance
perspective, a change in one code segment may necessitate
consistent changes in all clones of that fragment. Any incon-
sistency may introduce bugs or vulnerabilities in the system.
Fowler et al. [35] recognize code clones as a serious kind of
code smell.
However, during the software development process, duplica-
tion cannot be avoided at times. For example, duplication may
be enforced by the limitation of the programming language’s
necessary mechanism to implement an efﬁcient generic solu-
tion of a problem at hand. Code generators may also generate
duplicated code that the developers may have to modify.
Although controversial, previous research reports empirical
evidences that a signiﬁcant portion (generally 9%-17% [145])
of a typical software system consists of cloned code, and the
proportion of code clones in the code base may be as low
as 5% [104] and as high as even 50% [103]. Indeed, due to
the negative impact of code clones in the maintenance effort,
one might want to remove code clones by active refactoring,
wherever feasible. However, in reality, aggressive refactoring
of code clones appears not to be a very good idea [22], and not
all clones are really removable through refactoring. Due to the
dual role of code clones in the development and maintenance
of software systems, as well as the pragmatic difﬁculty in
avoiding or removing those, researchers and practitioners have
agreed that code clones should be detected and managed
efﬁciently [95, 143].
Since the emergence of software clones as a research area in
early 1990s, signiﬁcant contributions over years made the ﬁeld
grow and become quite a mature area of research. Over the
entire course of software clone research there have been only
two notable general surveys on clones. Koschke [80], in 2007,
presented a brief summary of the important ﬁndings about
different aspects of software clones including cause-effect of
cloning, clone avoidance, detection, and evolution along with a
set of open questions. In the same year, Roy and Cordy [104]
also published another survey containing a thorough review
on those same areas with speciﬁc focus on clone detection
tools and techniques. A few recent surveys either focus on
detection [102, 107] or evolution of clones [99]. In this visionarXiv:2005.01005v1  [cs.SE]  3 May 2020
paper, we provide an extensive survey on code clone research
with strong emphasis on clone management and point readers
to future research directions.
This paper is organized as follows. In Section II, we
present a systematic review on a repository of 353 publications
appeared over 20 years. The review draws a “birds-eye"
view on the overall contributions and growth along different
dimensions of software clone research. This survey is the
outcome of careful investigation of literature beyond the said
repository (described in Section II), and through analysis in the
light of our experience. Section III introduces different aspects
of clone management activities starting with the deﬁnition and
types of clones. While in Section IV, we list different stand-
alone clone detection techniques, we discuss the IDE-based
clone detectors in Section V. We then talk about clone doc-
umentation in Section VI and that of tracking over evolution
in Section VII. We discuss clone evolution studies including
visualization of clone evolution in Section VIII. Then, in
Section IX, we discuss clone annotation. Section X presents
the techniques for clone removal or clone based reengineering.
In Section XI, we describe the analyses for the identiﬁcation
of potential clones as candidates for refactoring/reengineering
including the visualization of clones, cost-beneﬁt analysis
and scheduling of clones for refactoring. In section XII, we
brieﬂy summarize the root causes for clones followed by clone
management strategies in Section XIII. In Section XIV, we
brieﬂy describe the design space for a clone management
system. Our view on the challenges for industrial adoption
of clone management is presented in Section XV. Finally,
Section XVI concludes the paper with a rough summary of
the state of the art along with future research directions.
II. A S YSTEMATIC REVIEW OF CLONE LITERATURE
There has been more than a decade of research in the ﬁeld
of software clones. To understand the growth and trends in
the different dimensions of clone research, we carried out a
quantitative review on related publications. Robert Tiras has
been maintaining a repository [120] of scholarly articles that
make signiﬁcant contributions in the area. Until today, the
corpus consists of 353 scholarly articles published between
1994 and 2013 in different refereed venues including Ph.D.,
M.Sc., and Diploma theses. The repository organizes the
publications by categorizing them based on their contributions
in four major sub-areas of clone research. The categories are
as follows:
Detection Publications in this category address techniques
and tools for the detection of software clones.
Analysis This category contains publications that perform
analysis on the various traits of software clones, their
etiology, existence, effects in software systems, as well
as investigation of clone reengineering opportunities and
implications. A majority of such publications report ﬁnd-
ings from qualitative or quantitative empirical studies.
Management Publications in this category address the issues,
techniques and tools for the management of code clones
beyond detection.Tool Evaluation This category comprises the publications
that contribute to the quantitative or qualitative evaluation
of the techniques and tools for clone detection.
Figure 1 plots the number of distinct authors contributing
to clone research in the years from 1994 through 2013. As the
ﬁgure indicates, the clone research community has experienced
a signiﬁcant growth over the recent years. In Figure 2, we
present the number of publications appear every year con-
tributing to each of the four sub-areas of clone research. As
seen in the ﬁgure, early work on software clone research was
dominated by the research on clone detection with some work
on analysis. In the recent years, the work on clone analysis and
detection has grown signiﬁcantly while clone management has
emerged and growing as a signiﬁcant research topic. Despite
the fast growth of the clone research community, the work
purely on clone management received relatively less attention
compared to analysis and detection, which can be more clearly
perceived from Figure 3. This, in combination with the realized
importance of research in clone management, points to the
further need and potential for research in this sub-area.
It can also be noticed from both Figure 2 and Figure 3
that over the entire span (1994–2013) of software clone
research a very few studies focused on the evaluation of clone
detection techniques or tools, although more than 40 different
clone detection tools have been produced realizing a wide
variety of techniques [107]. Indeed, the detection of clones
is a fundamental topic for software clone research, and the
effectiveness of clone management largely depends on clone
detection.
III. C LONE MANAGEMENT
“Clone management summarizes all process activities which
are targeted at detecting, avoiding or removing clones" [37].
Thus, clone management encompasses a wide range of cate-
gories of activities including clone detection, tracking of clone
evolution, and refactoring of code clones. As support for these
operations, the documentation and analysis of code clones can
be regarded as parts of clone management. Moreover, clone
visualization may also be an effective aid to clone analysis,
and thus to clone management.
A. Deﬁnition of Code Clone
Though duplicate or similar code fragments are roughly
known to be code clones, the deﬁnition of clone has remained
more or less vague over the last decade. The vagueness is
reﬂected in the deﬁnition given by Ira Baxter, “Clones are
segments of code that are similar according to some deﬁnition
of similarity" [12]. Despite ongoing debates in the research
community, there is no consensus on a precise deﬁnition yet.
Currently, a researcher’s deﬁnition of similarity is typically
constrained by the program representation and detection mech-
anism of his or her particular clone detector and, hence, varies
from tool to tool and also from parameter settings controlling
a tool. The least common denominator widely accepted today
is the following taxonomy, which was created in the context
of a study on comparing clone detectors [15]:
Fig. 1. Yearly number of distinct authors contributing to clone research
Fig. 2. Categories of publications on software clone research in different years
Fig. 3. Proportion of publications in each category over the period 1994–2013
Type-1 Clone Identical code fragments except for variations
in white-spaces and comments are Type-1 clones.
Type-2 Clone Structurally/syntactically identical fragments
except for variations in the names of identiﬁers, literals,
types, layout and comments are called Type-2 clones.
Type-3 Clone Code fragments that exhibit similarity as of
Type-2 clones and also allow further differences suchas additions, deletions or modiﬁcations of statements are
known as Type-3 clones.
Type-4 Clone Code fragments that exhibit identical func-
tional behaviour but are implemented through very dif-
ferent syntactic structures are known as Type-4 clones.
Type-2 and type-3 clones are often collectively called near-
miss clones . There have been alternative, more elaborated
taxonomies proposed by Mayrand et al. [89], Balazinska et
al. [7], and Kontogiannis [79], but they are not as widely used
as the simple categorization by Bellon et al. [15].
A common deﬁnition is needed when empirical results are to
be compared, for instance, on effects of clones or on accuracy
of clone detectors. The difﬁculty to reach a consensus on a
suitable deﬁnition, however, inevitably depends also on the
purpose of the clone detection. A deﬁnition of similarity will
include the “value” of a clone for the given task (e.g., bug
ﬁxing or refactoring). We do not foresee the advent of a uniﬁed
deﬁnition, we rather expect that task-speciﬁc taxonomies of
code similarity will emerge in the future and studies will
further differentiate contexts and purposes of clones.
Ongoing research also attempts to deal with clones in
software artifacts other than the source code [62], such
as clones in higher level code structure [9], clones in the
models of formal model based development [29], in UML
domain models [117], UML sequence diagrams [86], in the
graph based Matlab/Simulink models [100], duplication in re-
quirement speciﬁcation documents [62, 65], predicting clones
among domain entities [101], and even in Spreadsheets [46].
Deﬁnitions of clones must capture clones in all types of
artifacts, not just source code. However, this paper focuses
on the management of clones in the source code only.
B. Clone Management Activities
To manage clones, ﬁrst they have to be identiﬁed. The result
of clone detection forms clone documentation that records
the location of code segments and their clone relationship.
If the code base changes due to ongoing development, the
changes and locations of the clones need to be tracked, and
the documentation needs to be updated accordingly. The clone
documentation may be analyzed to determine justiﬁcation of
clones or to ﬁnd potential clones for removal. Visualization
techniques can aid such analysis. Clones that are found to have
justiﬁed reason to exist may be further documented and/or
annotated. The candidates for refactoring can be scheduled
for modiﬁcation and/or removal. Upon the application of
refactoring operations, a follow up veriﬁcation may examine if
the refactoring caused any change in program behaviour, and
in accordance, may initiate roll-back and re-refactoring. Upon
completion of refactoring the clone documentation needs to
be updated for consistency.
The workﬂow for a typical clone management system may
compose all these activities according to as summarized in
Figure 4. In the following sections, we describe the state of
the art in support for each of the clone management activities.
IV. C LONE DETECTION
Over more than a decade of code clone research a number
of techniques have been devised for the detection of code
clones and many clone detection tools have been developed.
In this section, we provide a brief summary of different
clone detection techniques. More detailed descriptions of those
techniques can be found in the corresponding papers and
elsewhere [104, 107].
Tracking Clipboard Operations: This technique of clone
detection is based on the assumption that programmers’ copy-
paste activities are the primary reason for the creation of code
clones. So, the technique [28, 51, 131] simply tracks clipboard
activities in the editor (inside IDEs such as Eclipse) when
a programmer copies a code segment and reuses by pasting
it. The copied and the pasted code segments are recorded as
clone-pairs.
Metrics Comparison: Metrics based techniques [83, 89]
are usually used to detect function clones. The techniques
are based on the assumption that similar code fragments
should yield very similar values for different software metrics
(e.g., cyclomatic complexity, fan-in, fan-out). Typically, for
the code segments a set of metrics are gathered into vectors.
The differences in the vectors are calculated, where close
vectors (e.g., measured by Euclidean distance) indicate that
their corresponding code fragments are clones.Texual Comparison: Text based techniques [32, 59] com-
pare program text, typically line by line, with or without
normalizing the text by renaming the identiﬁers, ﬁltering out
the comments and differences in the layout.
Token Based Comparison: In token based techniques
[5, 33], the entire program is transformed into a stream of
tokens (i.e., individual units/words of meaning) through lexical
analysis. Then the token stream is scanned to ﬁnd similar token
subsequences, and the original code portions corresponding to
those subsequences are reported as clones.
Syntax Comparison: Syntax comparison based techniques
[12, 56, 95] are developed on the fact that similar code
segments should also have similar syntactic structure. Thus,
the program is parsed to produce a syntax tree, where similar
subtrees indicate that their corresponding code segments are
clones.
PDG Based Comparison: For a given program, a set of
PDGs (Program Dependency Graphs) are produced based on
the data and control dependencies among the statements of the
program. The code segments corresponding to the isomorphic
subgraphs are identiﬁed and reported as clones [47, 49, 78].
Hash Based Comparison: Recently, hash based techniques
are getting attention for fast and scalable detection of near-
miss clones where hash values are generated from source code
and processed further for ﬁnding clones [116, 126].
Comparison of Low Level Form of Code: Instead of
analyzing and comparing textual source code, the techniques
analyze the lower level code (e.g., assembly code, Java Byte-
code or .Net intermediate language) as obtained from the
transformation by the compiler [2, 27, 74].
Other Techniques: Besides the aforementioned promi-
nent techniques for clone detection, other techniques, such
as formal methods [113], and combination of distinct tech-
niques [105] were also approached. Tracing of abstract mem-
ory states during the execution of the program was also
attempted to detect semantic clones [76].
As listed above there have been a great many state of the
art clone detectors available. However, still little is known
about the usefulness of the clones detected by different clone
detectors. Furthermore, evaluation of the clone detectors is
still an open challenge [104, 107] as we do not have reliable
benchmarks except the tool comparison experiment of Bellon
et al. [15] and the mutation based framework of Roy, Cordy
and Svajlenko [106, 119]. The parameter settings of the clone
detectors is another threat as shown by Wang et al. [129] as
confounding conﬁguration choice problem and conducted an
extensive study considering six clone detectors to ameliorate
the effects of the problem. Not to mention the issue of big data
clone detection is a growing challenge for clone management
and for many other related applications [118].
V. I NTEGRATED CLONE DETECTION
There are many clone detection tools out there, each has
its own strengths and weaknesses. However, for proactive
clone management, the support for clone detection should be
integrated with the development process. Therefore, we focus
DetectionDocumentationTrackingVisualizationAnalysisRecommendationRefactoring SchedulingRefactoring OperationRefactoring VeriﬁcationAnnotationPreventionFig. 4. Clone management workﬂow
on those tools that integrate clone detection with an IDE or a
version control system.
Juergens et al. developed CloneDetective [64], an open
source framework to facilitate implementation of customized
clone detectors. The framework itself is built on the infras-
tructure of ConQAT1, an integrated toolkit for software quality
assessment. Currently, CloneDetective is an integral part
ofConQAT , which applies a sufﬁx-tree-based technique to
detect Type-1 ,Type-2 , and Type-3 clones. However, beyond
the detection of clones and visualization of the clone detection
result, they offer no further support for clone management.
SimScan2, which is a parser-based tool available as plugin
to Eclipse, IDEA, or JBuilder, can detect Type-1 ,Type-2 , and
possibly a subset of Type-3 clones. The potential of SimScan
is also limited up to the detection code clones, not beyond that.
Giesecke [37] proposed a generic model for describing
clones. The model allowed separation of concerns among the
detection, description, and management of code clones. The
objective was to ease the implementation of tools to support
such activities. Based on the proposed model, they imple-
mented DupMan , a framework [38] integrated with the Eclipse
platform, and developed a prototype tool having SimScan as
the back-end clone detector. The model and implementation
is limited to the detection of clones and the representation of
the clone information for persistence.
CloneBoard [28] and CPC [131] are Eclipse plugins
similar to CloneScape that can detect and track clones
based on clip-board (copy-paste) activities of programmers.
Both CPC andCloneBoard support linked editing of clone
pairs as described by Toomim et al. [125]. However, CPC
was implemented as a framework to serve as a platform for
future clone management technology, whereas, the focus of
CloneScape was more on clone visualization and naviga-
tion, though their implementation remained incomplete. Hou
et al. are developing a toolkit named CnP [51] for clone man-
agement, which also detects clones based on programmers’
copy-paste activities. Indeed, the current implementation of
CnP offers very limited support for clone management, which
we address in Section X.
SHINOBI [73] is an add-on to the Microsoft Visual Stu-
dio 2005. For clone detection, it parses the source code,
extracts sequences of pre-processed tokens and creates an
1http://www.conqat.org/
2http://blue-edge.bg/download.htmlindex using sufﬁx-tree based technique. SHINOBI internally
usesCCFinderX ’s preprocessor, and thus it can detect Type-
1and Type-2 clones only, but not Type-3 [143]. It was
developed as a client(IDE)-server(CVS) application to mainly
relocate the clone detection overhead from the client to a
central server. It simply displays clones of a code fragment
underneath the mouse cursor, no further support for clone
management is offered. CodeRush3is a commercial add-in to
the Microsoft Visual Studio for providing assistance in coding
and refactoring. CodeRush recently introduced a new module
DDC for the detection and consolidation of duplicated code.
Bahtiyar developed JClone [4] as a plugin for Eclipse
for detecting code clones from Java projects. JClone applies
an AST based technique to detect Type-1 andType-2 clones
only. It enables the user to trigger the detection of clones from
one or more selected ﬁles or directories. It also offers a few
visualizations (i.e., TreeMap and CloneGraph views) for aiding
clone analysis to some extent, but no further support for clone
management beyond the detection and visualization of clones.
Nguyen et al. developed JSync [95] as a plugin to the SVN
version control system. Earlier prototypes of JSync appeared
asClever [98] and Cleman [96]. JSync detects clones
based on similarities among the feature vectors computed over
AST representation of the code fragments. JSync incorpo-
rates some useful features for clone management, which are
discussed in Sections VII and X.
CPD4is a part of the Java source code analyzer, PMD.
SDD [84] is a clone detection algorithm based on n-neighbour
distance, index and inverted index. An implementation of
SDD5is also freely available as a plugin to Eclipse. Simian6
is another clone detector available as a plugin to Eclipse.
Another Eclipse plugin, CloneDigger7, applies an approach
based on AST, sufﬁx tree, and anti-unifcation for detecting
clones in source code written in Java or Python. Tairas and
Gray [121] also developed a sufﬁx-tree based clone detector
as a plugin for the Microsoft Phoenix framework. Despite the
integration with IDEs all these tools offer no support for clone
management except for the detection of only Type-1 andType-
3http://devexpress.com/Products/Visual_Studio_Add-in/Coding_
Assistance/
4http://pmd.sourceforge.net/cpd.html
5http://wiki.eclipse.org/index.php/Duplicated_code_detection_tool_(SDD)
6http://www.harukizaemon.com/simian
7http://clonedigger.sourceforge.net/download.html
2clones [16].
Another Eclipse plugin, CloneDR8, is an AST-based clone
detector that can detect Type-1 and Type-2 clones. Besides
clone detection, CloneDR offers support for clone removal
as further discussed in Section X. CeDAR [122] can incor-
porate the results from different clone detection tools (e.g.,
CCFinder ,CloneDR ,DECKARD ,Simian , orSimScan )
and can display properties of the clones in an IDE. CeDAR
offers no further support for clone management, except that
those clone properties may be useful for clone analysis.
Moreover, it may suffer from the limitations of the underlying
clone detector used internally. Recently, Zibran and Roy [143]
developed an Eclipse plugin to facilitate focused search for
clones of a selected code fragment. They applied a sufﬁx-
tree-based k-difference hybrid approach to detect both exact
(Type-1 ) and near-miss ( Type-2 andType-3 ) clones. They are
also extending their tool towards a versatile clone management
tool [140].
While we see that there are a number of IDE-based clone
detection tools available, there are only a few that in fact
can deal with Type-3 clones. Furthermore, as we will see in
the following sections that there is still a marked lack for
different clone management features in these IDE-based tools.
Researchers possibly should ﬁrst conduct user studies of what
sort of features are needed for effective clone management
and then start building tools that would help developers
and maintenance engineers in dealing with different types of
clones.
VI. C LONE DOCUMENTATION
Different clone detectors report the results of clone detectors
in different formats such as XML, HTML, and plain text.
There are variations in the reported information as well. Some
clone detectors report clone pairs only, while some other tools
report clones in terms of clone groups. Such variations make it
difﬁcult for data exchange between clone detectors, which also
adds to the challenges in head-to-head empirical comparison
of clone detectors. To minimize the differences in the presen-
tation of clone information, Harder and Göde [44] recently
proposed the Rich Clone Format (RCF) , an extensible schema
based data format for storage, persistence, and exchange of
clone data.
Duala-Ekoko and Robillard [30] proposed clone region
descriptor (CRD) to describe clone regions within methods in
a way that is independent of the exact text of the clone region
or its absolute location in a ﬁle. However, such a scheme has a
number of limitations. First, small changes in the code corre-
sponding to the <anchor> (e.g., termination condition of loop,
branching predicate of conditional statements) will invalidate
the CRD. Second, the scheme is vulnerable to nesting levels,
and thus a simple addition or removal of nesting level will
invalidate the CRD. Third, the association of ‘else’ blocks with
the closest ‘if’ block prevents the CRD scheme differentiating
between the two types of blocks. Most importantly, the use
8http://www.semdesigns.com/Products/Clone/of the CRD scheme did not save CloneTracker [30] from
re-invoking the underlying clone detector to identify possible
changes in the clones, though the computational expense of
re-detection was indicated as one of the motivations behind
the design of CRD.
The above discussion indicates that the line and column
information, or the abstract level CRD based documentation
of clone regions are more or less vulnerable to changes in the
evolving code. To overcome such sensitivity to code change,
marker based tagging support in IDEs like Eclipse can be
used for clone documentation. Such tagging of clones can
provide built-in support for accommodating changes in the
source ﬁles [21]. Further investigation may be required to
verify this possibility.
Capturing the location of clones reliably is necessary for
tool comparisons and also for tracing clones over subsequent
versions. If tools are to be integrated from different vendors,
an agreed way to document clones is required. RCF is a step
towards a common format [44], but it does not address all
needs [72]. A common conceptual model for clone information
is a major challenge because of competing requirements (e.g.,
it should be both generic and efﬁcient) [42]. There has been
some progress towards a uniﬁed model [72]. We expect
real practical progress to happen, however, only if different
research teams actually start to exchange data – and not just
between two teams but among many teams. We do not see this
happening at the moment except for exchanging benchmark
data for clone detectors and for that use case, RCF seems to
be sufﬁcient.
VII. C LONE TRACKING
During the development of an evolving software system
frequent changes take place in the code base. Such changes
may introduce new code segments that might form new clones.
Moreover, changes in source ﬁles may invalidate the clone
regions necessitating corresponding updates in the recording
of clone information. Such updates can be accomplished in
two ways: Re-detection and incremental detection.
Re-detection: The detection of clones from the entire
system may be invoked every time the code changes. This
approach may incur too much overhead as the detection of
code clones in a fairly large system can be computationally
expensive. Hence, the approach might not be suitable for
proactive clone management.
Incremental Detection: A better approach can be incre-
mental detection, where only the source code in the modiﬁed
portion of the code base is examined for any clones and the
outcome is accumulated with the previously preserved clone
detection results. Not many attempts were made towards incre-
mental clone detection. The ﬁrst attempt was made by Göde
and Koschke [40]. They proposed a sufﬁx tree based detector
iClone for incremental detection of clones in subsequent
versions of a given system. It detects Type-1 ,Type-2 , and Type-
3clones.
Hummel et al. [53] proposed an index-based incremental
clone detection approach for Type-1 andType-2 clones. Higo
et al. [49] proposed an incremental one based on PDGs, where
PDGs are generated from the analysis of control and data
dependencies in the program code targeting even semantic
clones. However, PDG based techniques are computationally
expensive and they often report non-contiguous clones that
may not be perceived as clones by a human evaluator [15]. The
clone tracking approach of JSync [95, 97] appears to be com-
putationally elegant. JSync preserves the clone-groups and N
buckets obtained from the initial clone detection. Since JSync
is implemented as a plugin to SVN, the change information
of the source ﬁles are readily available, and based on that
information JSync can determine the fragments modiﬁed,
added to, or deleted from the code repository. JSync then
removes from the clone-groups those fragments that were
changed or deleted. Then the LSH technique is applied to the
newly added and modiﬁed code fragments to place them in
the buckets. Then the fragments in each bucket are compared
pair-wise to update the clone-groups. Thus, the clone detection
technique of JSync appears to be inherently incremental and
consequently computationally efﬁcient for tracking clones. We
envision that other classes of techniques (cf., Section IV) will
also have incremental variants as there is a clear need for
scalable, fast and near-miss incremental detection techniques
for efﬁcient clone management.
VIII. A NALYSIS OF CLONE EVOLUTION
Software development and maintenance in practice follow
a dynamic process. With the growth of the program source,
code clones also experience evolution from version to version.
Many studies have been conducted to date for understanding
the overall evolution [8, 40, 112, 145], stability of cloned
code [6, 45, 50, 81, 90, 91, 92], the relation of clone evolution
with software faults [8, 39, 132, 133], and other characteristics
of clone evolution. While such studies inform the characteristic
and impact of code cloning, further in-depth analyses that
investigate the change patterns in the evolution of individual
clone fragments can suggest techniques for optimizing clone
management including refactoring and removal. Because there
is already a recent survey on clone evolution [99], we keep this
section brief with speciﬁc focus on the evolution of individual
clone fragments and their change patterns.
Kim et al. [77] ﬁrst coined the term “clone genealogy" ,
which refers to a set of one of more lineage(s) originating
from the same clone-group. A clone lineage is a sequence
of clone-groups evolving over a series of versions of the
software system. To map clones across subsequent versions
of a program (i.e., extraction of clone genealogies) several
approaches have been proposed in the literature. While most
of these approaches [6, 8, 77, 108] focused on genealogies of
Type-1 andType-2 clone genealogies, gCad [110] is the only
Type-3 clone genealogy extractor to date released as a separate
tool [111].
Studies [6, 16] on clone change patterns revealed that
inconsistent changes in clones sometimes caused program
faults. Moreover, late propagation is reported to have even
more signiﬁcant correlation with software defects and thusconcluded to be “more risky than other clone genealogies" [8].
On the basis of clone genealogies, a number of studies [77,
108, 110, 112, 146] have been conducted to explore the change
patterns and characteristics in the evolution of individual
clone fragments. Some of the ﬁndings from those studies
compliment one another, while some of the results derived
from those studies appear to be contradictory. Therefore,
more studies in larger scale are still necessary to conﬁrm the
agreeing observations and to shed light on the contradictory
ﬁndings.
Studies on clone change patterns using a genealogy model
can suffer from a number of issues. First, due to the threshold
based similarity measure used in practice for Type-3 clones,
there remains an open question on the appropriate value for
the threshold. Moreover, for Type-3 clones, is it an appropriate
practice to group Type-3 clones into different disjoint classes?
If not, the traditional notion of genealogy cannot apply to
Type-3 clones. Can we devise a more appropriate alternative?
Second, a genealogy can be characterized as inconsistently
changed if only a single clone over the entire length of
the genealogy experiences even for very minor inconsistent
changes. To draw a better picture, we may capture information
such as, what portion of clones in clone groups change in
how many versions, and how large the changes are. Finally,
from the correlation between late propagation and software
defects, can we really derive a causal relationship concluding
that late propagation is riskier than other clone genealogies?
Inconsistent changes are believed to often cause defects, and
clones may disappear from a genealogy due to inconsistent
changes. Later modiﬁcations, which could be even bug ﬁxing
activities, may cause changes in the disappeared clone to sync
it to its original clone-group. In such a scenario, late propa-
gation actually contributes in repairing the defect introduced
from inconsistent changes. Thus, we believe, late propagation
can really play a dual role, and more studies are necessary to
distinguish them.
Visualization support can aid analysis of clone evolution,
and thus different techniques and tools have been proposed
for visualizing properties of clone evolution including the
genealogy model. Adar and Kim [1] developed SoftGuess ,
a system for clone evolution exploration that supports three
different views. The genealogy browser offers a simple vi-
sualization of clone evolution where nodes represent clones,
arranged from left to right, and those that belong to the same
class are arranged vertically in the same position. Thus, each
column represents a version. A link between a pair of node
reﬂects the predecessor and successor relationship during the
evolution of the software. The encapsulation browser shows
how clones within a clone group are distributed in different
parts of a system and how they ﬁt in the hierarchical organi-
zation of the software system by visualizing the containment
relationship through a tree structure. Finally, the dependency
graph describes how the nodes (package, class or method)
within a version are evolved from other nodes and how they
evolve in the next version. In addition, SoftGUESS also
supports charting and ﬁltering mechanisms based on Gython,
an SQL-like query language. However, SoftGUESS lacks
an ‘overview’ feature and requires user interaction for data
reduction through queries. Although a query is a powerful
mechanism to identify important patterns of cloning, formu-
lating queries could be difﬁcult as this requires more cognitive
effort from the developers.
Harder and Göde [44] developed a multi-perspective tool for
clone evolution analysis, called CYCLONE . It offers ﬁve differ-
ent views to analyze clone data stored in an RCF ﬁle, where
RCF is a binary format to encode clone data including the
evolutionary characteristics. The evolution view in CYCLONE
visualizes clone genealogies using simple rectangles and cir-
cles to denote software entities. Each circle represents a clone
fragment arranged in a set of rows where each row represents
a particular version of the software. The clones that belong to
the same clone class are packed within a rectangle. Finally,
lines represent the evolution of a clone fragment. In addition,
the view employs colors to distinguish types and the changes
of the clones. Although the view highlights many important
evolutionary characteristics, the volume of data produced by
the genealogy extractor still limits its usefulness, thus calls
for overview and ﬁltering mechanisms. A similar visualization
support is available in VisCad [3], with additional ﬂexibility
of metric-based ﬁltering of genealogies.
While there have been a good number of studies (c.f.,
Section XI) on visualization of clones in a single version
of a software system, we still need further studies to ﬁgure
out useful techniques for visualizing clone evolution from
management perspective. For example, what sort of visual-
izations are useful for clone management activities and what
are their implications in the context of real world software
development? We need to understand the claims and believes
about code clones [18] including empirical evidence from
developers’ perspective [20, 146] and then need to design the
visualization techniques appropriately. It is also important to
understand developers’ intent when designing such tools [19].
Recently, Saha et al. [109] presented an idea for clone
evolution visualization using the popular scatter plot. In their
proposed approach, scatter plots show the clone pairs associ-
ated within a pair of software unit (ﬁle, directory or package).
Based on the type of clone genealogies they are associated
with, clone pairs are rendered with different colours. Selecting
a clone pair through user interactions (double clicking on a
clone pair in the scatter plot) shows the associated genealogy
in a genealogy browser. The proposal facilitates developers or
maintenance engineers to identify evolutionary change patterns
of the clone classes in a particular version and then provide
a way to call for genealogy browser to dig deeper. However,
it does not provide overall characteristics of the genealogies.
Moreover, due to the large number of clone pairs, selection
and useful pattern identiﬁcation in such a scatter plot can
be difﬁcult, which is why different variants of the traditional
scatter plots appeared in the literature [24].IX. C LONE ANNOTATION
The developers often deliberately create clones, for exam-
ple, to enable independent evolution of similar implementa-
tions. During the clone management process, the developer
may not want to refactor/remove those clones, and may want
to mark those to indicate such decisions so that they will not
have to encounter those same sets of clones over and over.
Moreover, the decision needs to be documented and shared
among different programmers, and there should be facilities
for the developers to review those clones at a later time, in
case they want to re-evaluate their management decision. To
the best of our knowledge, such a feature is found only in
JSync [95], which allows the developer to annotate pairs of
clones for avoiding future encounters.
Although there are several ideas and implementations of
clone-evolution visualization, there is not enough empirical
assessment of these. We also believe that further progress
can be achieved by studying existing work in information
visualization.
X. T ECHNIQUES FOR REENGINEERING /REFACTORING OF
CLONES
The investigations of opportunities for clone based reengi-
neering and refactoring of clones for their removal have sug-
gested techniques such as generics, design patterns, software
refactoring patterns, and synchronized modiﬁcations of code
clones.
Generics and Templates: Basit el al. [10] investigated the
potential of generics in removing code clones. They carried
out two case studies on the Java Buffer Library and the C++
Standard Template Library (STL) . The Java Buffer Library
was found to have 68% redundant code, and using generics
they were able to remove only 40% of them. Though, they
performed little better for the C++ STL , they concluded that
the constraints of language constructs limit the applicability
of generics in clone removal. They further hypothesized that
meta level parameterizations might perform better as they are
relatively lesser restrictive than generics or templates.
The hypothesis on the potential of meta level parameteriza-
tions was addressed by Jarzabek and Li [55] in a later study.
They also used the Java Buffer Library for their case study.
They applied a generative programming technique using XVCL
(XML-based Variant Conﬁguration Language)9to represent
similar (but not necessarily identical) classes and methods in
generic and adaptable form. Using the technique they were
able to eliminate 68% of the code from the original Java Buffer
Library .
Consistent Renaming: Programmers often perform modiﬁ-
cations after copy-pasting a code fragment. Such modiﬁcation
typically include renaming of identiﬁers according to the
new context of the cloned code. IDEs like Eclipse provide
necessary support for consistently renaming an identiﬁer and
all its references within scope. Jablonski and Hou developed
CReN [54] as a plugin to Eclipse that can check for any
9http://xvcl.comp.nus.edu.sg/
inconsistencies in the renaming of identiﬁers within a code
fragment and suggest modiﬁcations for making the renaming
consistent.
Since JSync [95] is developed as a plugin to the SVN
version control system, it can exploit the change information
between versions of Java source ﬁles to determine whether
any changes occurred in cloned code regions.
Refactoring Patterns Fowler in his book [35] presented
72 patterns for refactoring source code in general for the
removal of code smells. Over time, the number of refactoring
patterns has increased to 93, and a refactoring catalog10is
maintained that lists and describes them all. Among those
general software refactoring patterns [35], Extract method ,
Move method ,Pull-up method ,Extract superclass ,Extract
utility-class , and Rename refactor patterns are found to be
suitable for clone refactoring, as suggested by earlier re-
search [48, 85, 114, 136, 141, 144]. Details about these
refactoring patterns can be found in the refactoring catalog
and elsewhere [35].
Besides these prominent refactoring patterns, other low level
refactoring operations such as identiﬁer renaming ,method
parameter re-ordering ,changes in type declarations ,splitting
of loops ,substitution of conditionals ,loops ,algorithms , and
relocation of methods or ﬁelds may be necessary to produce
generalized blocks of code from near-miss clones [141].
Kerievsky [75] proposed the chained constructor refactoring
pattern11, to eliminate duplicated code from the constructors
of the same class [94]. Other refactoring patterns that can be
found in the literature are some sort of variants or composi-
tions of the aforementioned object-oriented refactoring (OOR)
patterns. Other than the OOR patterns, Schulze et al. [115]
proposed three aspect oriented patterns described as extract
feature into aspect, extract fragment into advice , and move
method from class to interface .
Type-3 clones remain a challenge for automated clone refac-
toring because they have difference that cannot be eliminated
with a simple rename refactoring. Here, an additional step
is required to abstract from the difference in a way that
enables an extract-method refactoring. Anti-uniﬁcation used to
detect clones may help in refactoring, too, in certain situation.
We expect progress for some Type-3 clones at least. It is
an interesting question how far we can get. A couple of
recent studies [14, 82] also call for further studies on clone
refactoring including the refactoring of task speciﬁc near-miss
clones. Indeed, clone maintenance support could be increased
by unifying clone detection and refactoring activities [123] and
we need to focus more on such studies.
XI. A NALYSIS AND IDENTIFICATION OF POTENTIAL
CLONES FOR REFACTORING
For the purpose of ﬁnding and characterizing code clones
suitable for refactoring, reengineering, or removal, in depth
analysis of the various properties of the clones and their
10Catalog of OO refactoring patterns: http://refactoring.com/catalog/
11Catalog of 27 refactoring patterns from J. Kerievsky’s book: http://
industriallogic.com/xp/refactoring/catalog.htmlcontext is required. Clone visualization has been proven to be
effective in aiding such analysis. Therefore, we ﬁrst discuss
the tools and techniques for code clone visualization, and then
we present the ﬁndings from analysis of code clones in search
for clone based reengineering opportunities.
A. Visualization of Distribution and Properties of Clones
Almost all the clone detection tools report clone information
in the form of clone pairs and/or clone groups in a textual
format where only the basic information about the clones
such as the ﬁle name, line number, starting position, ending
position of clones are provided. The returned clones also differ
in several contexts such as types of clones, degree of similarity,
granularity and size.
Moreover, there is a huge amount of clones in large systems.
For example, CCFinder resulted 13,062 clone pairs for Apache
httpd [67]. Because of the insufﬁcient information on the
returned clones, their various contexts, and their sheer number,
the presentation of clones becomes difﬁcult. For the proper use
of the detected clones, especially for clone management, the
aid of suitable visualization is crucial. In the following, we list
some of the visualization approaches that have been proposed
in the literature.
A major challenge in identifying useful cloning information
is to handle the large volume of textual data returned by
the clone detectors. To mitigate the problem, a number of
visualization techniques, ﬁltering mechanisms and support
environments are proposed in the literature. Jiang et al. [58]
categorized the proposed clone presentation techniques based
on two dimensions. The ﬁrst dimension refers to the level
at which the entities are visualized (such as at the code
segment level or ﬁle level or subsystem level). The second
dimension refers to the type of clone relation addressed by the
presentation, that is, whether clones are shown at the clone pair
level or grouped into clone classes or super clones. A super
clone is an aggregated representation of multiple clone groups
between the same source entities (e.g., ﬁle).
Johnson [60] used the popular Hasse diagram to represent
textual similarity between ﬁles. Later, he also proposed hyper-
linked web pages to explore the ﬁles and clone classes [61].
Cordy et al. [25] used HTML for interactive presentation of
clones where overview of the clone classes is presented in a
web page with hyperlinks and users can browse the details
of each clone class by clicking on those links. Although such
representations offer quick navigation, they cannot reveal the
high level cloning relations.
A set of polymetric views [103] were also proposed in the
literature that permit encoding multiple code clone metrics in
visual attributes. Among various visualizations, scatter plot is
quite popular and capable of visualizing inter-system and intra-
system cloning [24, 87]. However, the size of the scatter plot
depends on the size of input rather than the amount of cloning.
Thus, using a scatter plot for visualizing cloning relation of
a large software system may become challenging due to the
large size of the plot.
Moreover, in scatter plot, non-contiguous sections that con-
tain the same clone cannot be grouped together. To overcome
this limitation, Tairas et al. [124] proposed a graphical view
of clones (also known as Visualizer view) that represents each
source ﬁle as a bar and clones within the ﬁles are represented
with stripes. Clones belong to the same class are encoded with
the same color.
Jiang et al. [57] extended the idea of cohesion and coupling
to code clones and proposed a visualization that uses shape
and color to encode the metric values. They also developed
a framework [57] for large scale clone analysis and proposed
another visualization, called a clone system hierarchical graph
that shows the distribution of clones in different parts (with
respect to the ﬁle-system hierarchy) of a system. Fukushima et
al. [36] developed another visualization using graph drawing
to identify diffused (scattered) clones. Here, nodes represent
the clones. Those nodes that are located in the same ﬁle are
connected with edges to form a clone set cluster. Nodes that
connect different clone set clusters are called diffused clones
(have cloning relation in different ﬁles implementing different
functions).
Gemini [127] is an example of a clone support environ-
ment that uses CCFinder for clone detection and can visualize
clone relationships using scatter plots and metric graphs.
Kapser and Godfrey developed CLICS [70, 71], another tool
for clone analysis. CLICS can categorize clones based on
their previously developed clone taxonomy [69] and support
query based ﬁltering. Tairas et al. [124] developed an Eclipse
plug-in that works with CloneDR as a clone detector and
implements the visualizer view along with general information
and detected clones list views.
Clone Visualizer [139] is an Eclipse plugin that
works with Clone Miner to detect clones. In addition to
supporting clone visualization through stacked bar charts and
line graphs, it supports query based ﬁltering. CYCLONE12[44]
is another clone visualizer that supports single and multi-
version program analysis and uses RCF (Rich Clone For-
mat) [44] ﬁle as an input. A separate viewer application named
RCFVIEWER13is also developed for the visualization of clone
information stored in RCF. Recently, Xing et al. [134] pro-
posed CloneDifferentiator that identiﬁes contextual differences
of clones and allows developers to formulate queries to distill
candidate clones that are useful for a given refactoring task.
As can be noted, all the visualization techniques focus on
visualization of clone pairs or clone groups with respect to
their dispersion in the ﬁle-system hierarchy only. However, the
cost-beneﬁt analysis of code clone refactoring (Section XI-B)
takes into account the distribution of clones in the inheritance
hierarchy. Therefore, from the perspective of clone removal
or refactoring, the visualization of the clones with respect to
the inheritance hierarchy can offer useful insights, and future
work in clone visualization should address this possibility.
For visualization of clone evolution, the proposed tech-
12http://softwareclones.org/cyclone.php
13http://www.softwareclones.org/niques for visualizing clones of one version of a system
lacks empirical assessment mostly. We possibly need use-
case speciﬁc visualizations with empirical support as of Live
Scatterplots [23]. We thus expect to have more empirical user
studies as the ﬁeld matures. Furthermore, clone visualization
from big data is also badly needed [34].
B. Cost-beneﬁt Analysis and Scheduling of Refactoring
Not much research has been done towards cost-beneﬁt anal-
ysis of code clone refactoring and their scheduling. Bouktif et
al. [17] ﬁrst proposed a simple effort model for the refactoring
of clones in procedural code. Zibran and Roy [141, 142, 144]
proposed a more comprehensive effort model for estimating
clone refactoring efforts. They formulated scheduling of code
clone refactoring as a constraint satisfaction optimization
problem and applied constraint programming (CP) technique
to compute an optimal solution of the problem.
Lee et al. [85] applied ordering messy GA (OmeGA)
to schedule refactoring of code clones. Mondal et al. [93]
proposed an automatic way of ranking clones for refactor-
ing through mining association rules of the evolving clones.
Juergens and Deissenboeck [63] described a detailed analytic
cost model based on potential effects of clones on different
maintenance activities. The existing models make several
implicit and explicit assumptions and do not give concrete
values for weights included in the formulae.
Overall, we know too little about the real costs incurred
by clones and the risks and beneﬁts of refactorings and other
measures to compensate the negative effects of clones for a
realistic cost model. We hardly know the factors inﬂuencing
the costs. Only through a series of empirical ﬁeld studies and
experiments will we ever get closer to such a cost model. We
remain skeptical as to whether we will ever get close enough
given the many variables inﬂuencing the costs and gains of
clones.
XII. R OOT CAUSES FOR CODE DUPLICATION
Code clones do not occur in software systems by them-
selves. They are created. There are several factors that might
force or inﬂuence the developers and/or maintenance engineers
in cloning code in a system. In order to manage clones
properly, we need to study the root causes for their creation.
In the following we list some of the potential root causes.
Development Strategy Clones can be introduced in soft-
ware systems due to the different reuse and programming
approaches. Reusing code, logic, design and/or an entire
system (as in product lines [31]) are the prime reasons of code
duplication. Reusing existing code by copying and pasting
(with or without minor modiﬁcations) is the simplest form of
reuse mechanism in the development process which results in
code duplication. It is a fast way of reusing reliable semantic
and syntactic constructs.
The term Forking is used by Kapser and Godfrey [68] to
mean the reuse of similar solutions with the hope that they
will diverge signiﬁcantly with the evolution of the system.
For example, when creating a driver for a hardware family, a
similar hardware family may already have a driver, and thus
can be reused with slight modiﬁcations. Similarly, clones can
be introduced when porting software to new platforms and
functionality and logic can be reused if there is already a
similar solution available.
Maintenance Beneﬁts Clones are also introduced in the
systems to obtain several maintenance beneﬁts. One of pri-
mary factors could be reducing risk in developing new code.
Cordy [22] reports that clones do frequently occur in ﬁnancial
software as there are frequent updates/enhancements of the
existing system to support similar kinds of new functionalities.
Financial products do not change that much from the existing
one, especially within the same ﬁnancial institutions. The
developer is often asked to reuse the existing code by copying
and adapting to the new product requirements because of
the high risk (monetary consequences of software errors can
run into the millions in a single day) of software errors in
new fragments and because existing code is already well
tested (70% of the software effort in the ﬁnancial domain is
spent on testing). Introduction of new bugs can be avoided
in critical system functionality by keeping the critical piece
of code untouched [41]. For keeping the software architecture
clean and understandable sometimes clones are intentionally
introduced to the system [68].
Overcoming Underlying Limitations Clones can be in-
troduced due to limitations of the programming language,
especially when the language in question does not have
sufﬁcient abstraction mechanisms such as inheritance, generic
types (called templates in C++) or parameter passing (missing
from, e.g., assembly language and COBOL) and consequently,
the developers are required to repeatedly implement these as
idioms. Such repeating activities may create possibly small
and potentially frequent clones [11].
There are also several limitations associated with the pro-
grammers for which clones are introduced in the system. For
example, it is generally difﬁcult to understand a large software
system. This forces the developers to use the example-oriented
programming by adapting existing code developed already.
Furthermore, often developers are assigned short time frames
in completing tasks. Due to such time limits, developers look
for an easy way of solving the problems at hand and conse-
quently look for similar existing solutions and consequently
clones are introduced in software. Sometimes the productivity
of a developer is measured by the number of lines he/she
produces per hour. In such circumstances, the developer’s
focus is to increase the number of lines of the system and
hence tries to reuse the same code again and again by copying
and pasting with adaptations instead of following a proper
development strategy. Sometimes the developer is not familiar
with the problem domain at hand and hence looks for existing
solutions of similar problems.
Cloning By Accident Clones may be introduced into soft-
ware even by accidents. The use of a particular API normally
needs a series of function calls and/or other ordered sequences
of commands. For example, when creating a button using
the Java SWING API, a series of commands is to create thebutton, add it to a container, and assign the action listeners.
Similar orderings are common with libraries as well [68].
Thus, the uses of similar APIs or libraries may introduce
clones. Coincidentally implementing the same logic by dif-
ferent developers may also cause cloning. Programmers may
unintentionally repeat a common solution for similar kinds
of problems using the common solution pattern of his/her
memory to such similar problems. Therefore, several clones
may unknowingly be created in the software systems.
As can be seen from the above discussion, we need to dig
deeper into each of the root causes so that we can either avoid
clones or can keep track of the clones during development
making clone management easier in the maintenance as also
noted by Zhang et al. [137]. We can also think of bet-
ter programming languages design keeping more abstraction
mechanisms for different types of clones at the ﬁngers end of
the developers.
XIII. C LONE MANAGEMENT STRATEGIES
For dealing with code clones, Mayrand et al. [88] pro-
posed two concrete activities namely “problem mining" and
“preventive control", which were further supported by a later
study of Lague et al. [83]. Giesecke [37] categorized them into
compensatory and preventive clone management, respectively.
Giesecke [37] suggested that all clone management activities
can be associated with one or more of the three categories:
corrective, preventive, and compensatory management.
Corrective clone management aims for removal of existing
clones from the system. The objective of Preventive clone
management is to prevent creation of new clones in the
system. Compensatory clone management deals with applying
techniques (such as annotation, documentation) for avoiding
the negative impacts of clones that are not removed from the
system for some valid reasons. In practical settings, avoiding
clones may be impossible at times, and the expectation of a
clone-free system can be unrealistic. Thus, preventive clone
management actually refers to proactive management [51,
52] that aims to deal with the clones during their creation
or soon after they are introduced. An opposite strategy,
retroactive clone management [21] adopts the post-mortem
approach [143], where clone management activities initiate
after the development process is complete up to a milestone.
Clone management in legacy systems can be the most
appropriate for the post-mortem strategy. Indeed, prevention
is better than cure. Therefore, proactive clone management is
preferable to post-mortem approach. While, ideally, all clones
should be managed proactively, in practical settings, proactive
treatment for all clones may not be feasible or possible.
Therefore, a versatile clone management system should focus
on support for proactive management, while at the same
time, should also facilitate retroactive clone management [21].
Recently, Zhang et al. [138] proposed, CCEvents that provides
timely notiﬁcations about relevant code cloning events for
different stakeholders through continuous monitoring of code
repositories. This is one of the ﬁrst studies on contextual and
on-demand clone management that clearly shows we need
further studies on clone management as well.
XIV. D ESIGN SPACE FOR A CLONE MANAGEMENT
SYSTEM
Most clone detectors [47, 56, 66, 105] are implemented as
stand-alone tools separate from IDEs (Integrated Development
Environments) and typically search for all clones in a given
code base. While clone detection from such tools can help
clone management in a post-mortem approach, researchers
and practitioners [37, 43, 51, 52, 83, 95, 140, 143] believe
that clone management activities should be integrated with
the development process to enable proactive management.
Hou et al. [52], during the on-going development of their
clone management tool CnP [51], explored the design space
towards tool support for clone management. However, their
work was tightly coupled with the clone detection technique
based on the programmers’ copy-paste operations. Thus, their
ﬁndings are limited in scope to the management of copy-pasted
code, and most of the ﬁndings are not applicable to clone
management based on similarity based clone detection.
A. Architectural Alternatives of Integration
We identify three major alternatives and some sub-
alternatives in the design space for a versatile clone manage-
ment tool. These alternatives are inspired by our experience
and the different clone management scenarios reported by
Giesecke [37].
Architectural Centrality: The need for the integration of
clone management activities with the development process
suggests that the IDEs should include features to support clone
management activities during the actual development phase.
While a programmer typically works inside an IDE running on
her individual workstation, for fairly large projects, especially
in industrial settings, a team of developers collaboratively
works on a shared code base kept in a version control system
set up on a server. Hence, the supports for clone management
activities can be implemented as features augmenting the local
IDEs, or the functionalities can be implemented at a central
repository.
Decentralized Architecture: The clone management func-
tionalities, when augmenting the features in local IDEs, can
enable the individual programmers to exploit the beneﬁt of
clone management. In the decentralized scenario different
developers can use different tools, and some programmers can
get the ﬂexibility to completely or partially disregard clone
management at their respective situations. Apparently, such
a decentralized implementation may completely disregard the
existence of a central server, and enforces proactive clone
management before check-in to the shared repository. How-
ever, this necessitates additional requirements for establishing
means for communication between distributed developers, as
well as combining and synchronizing clone information across
all the developers.
Centralized Architecture: The centralized architecture in-
herently aims to support clone management in a distributeddevelopment process. The functionalities can be implemented
as a client-server application on top of central version control
systems. Such a centralized clone management system may
require greater effort and offer less ﬂexibility than a decen-
tralized implementation [37]. Indeed, a client-server imple-
mentation cannot support those individual programmers who
work alone on their stand-alone local machines [143]. But,
the centralized architecture may facilitate the integration of
clone detection features with the continuous or periodic (e.g.,
diurnal) build process [135].
We currently do not know what strategy works best un-
der which circumstances. Future research should compare
the different ways of integrating clone management in the
development process.
B. Triggering Actors in Clone Management
A clone management activity may be initiated by the
developer or by the system in response to certain events.
Human Triggered Initiative: A developer, after writing
or modifying a piece of code, may invoke the search for
clones in the system, upon ﬁnding the clones, she may
analyze and decide how to deal with them. In such an ad-
hoc triggering scenario, the developer, at times, may forget
to perform the necessary clone management. An instance of
clone management activity may also be periodically scheduled
in advance as part of a larger plan of process activities, and
clone management activities can be carried out following the
post-mortem approach on the current status of the code base.
System Triggered Initiative: The development environ-
ment can trigger clone management activities in response
to certain events, such as saving changes in the code, or
check-in of modiﬁed code to the central repository having the
clone detection capability integrated with the build process.
Such events may notify and suggest the developer to perform
the required clone management operations. However, care
must be taken so that those auto-generated notiﬁcations and
suggestions do not irritate the developer or hinder her normal
ﬂow of work.
Scope of Clone Management Activity: An instance of
clone management activity may be clone-focused orsystem-
focused . A clone-focused activity deals with a narrow set
of clones of a particular code segment of interest. On the
contrary, a system-focused clone management activity aims
to deal with a broad collection of clones in the entire code
base, or particular portions of the system.
We need to further investigate for which kind of events
clone management should be triggered by whom. For changes
in clones – in particular inconsistent ones – likely a system
should notify a developer. The challenge for all actions trig-
gered by a system must be to avoid false alarms. Otherwise
developers will soon give up using a clone management tool.
For general quality assurance, a quality manager might observe
trends in clones and take initiatives when she sees a increase
of redundancy. The challenge for human triggered actions is
to provide accurate data on demand and to ﬁnd signiﬁcant
indicators of problems.
DetectionDocumentation
Type-1Type-2Type-3Type-4
Core informationAdditionalinformationInteroperabilityAnalysis
Visualization
TrackingRecommendationAnnotationRefactoringoperationRefactoring SchedulingRefactoringveriﬁcation
dispersion in ﬁle-systemsimilaritydistribution in inheritance hierarchycost-beneﬁt analysisdiffdistribution in inheritance hierarchynavigationType-1Type-2Type-3Type-4compositerefactoringconsistentrenameclone-pair mergeextract methodbasic with persistencePersistence with tool supportautomationrecommendationconsistentrenameclone-pair mergeauthomatedschedulingauthomatedestimation of cost-beneﬁtverify renaming for consistencyautomated test casegeneration or adaptation
Done well enoughAttempted with some successYet to achieveLegendsdealing withgroups of 3 or more clonesdealing withgroups of 3 or more clonesFig. 5. Achievements and scopes along different dimensions of clone management activities
C. Scope and Point in Time of Clone Management
Clones are not restricted to source code. Finding clones in
earlier artifacts may avoid source code clones.
Clones in requirements documents may lead to duplicate
implementation of very similar features if, for example, sim-
ilar use cases are given to different development teams to
implement. In turn, this may result in semantic code clones,
or even code segments with very similar structure. Therefore,
the detection of clones in requirements speciﬁcation artifacts
could help avoiding clones in code, or to identify semantic
clones, which in turn could help to differentiate features from
sub-features.
Similarly, clones in design models, especially in model-
driven development, may also lead to clones in the source
code. Thus, the upfront detection of clones in design models
might help to reconsider architectural choices, and result in a
leaner, more abstract and essential design resulting in fewer
code clones.
For these reasons, clone management must consider all
types of software artifacts and should be part of early stages
in software development. There are initial studies in detecting
clones in other types of artifacts such as in requirements
documents [62, 65], in models [29, 117], in sequence diagrams
[86] or in Spreadsheets [46], which need to explore and deepenfurther. We envision clone management tools to broaden from
source code to other artifacts and as a consequence a good
chance to avoid source-code clones.
XV. I NDUSTRIAL ADOPTION OF CLONE MANAGEMENT
Despite the active research on software clones and their
impact on the development and maintenance of software
system, management of code clones is still far from wide
industrial adoption. A reason to this could be the unavailability
of integrated tool support for versatile clone management. Or
maybe industry is just not aware of the problem. Maybe clones
are even not a real problem in the ﬁrst place because the
advantages outweigh the disadvantages.
What we as researchers need to show ﬁrst is sufﬁcient
empirical evidence of real problems caused by clones. We have
made good progress in recent years here. Then we need to pro-
vide usable working solutions. We need to demonstrate their
beneﬁts in real case studies. Because beneﬁts are expected to
show up only in the long run, we need long-term studies in
realistic industrial settings. Such long-term industrial studies
are difﬁcult to conduct, however.
Despite these difﬁculties, we see signs that clone manage-
ment is gathering momentum in industry. There are several
clone detectors available as Eclipse plug-ins and only recently
Microsoft introduced a clone management feature in Microsoft
Visual Studio [26, 130]. There are several other industrial
attempts as well [128, 135] including a recent Dagstuhl
seminar on the topic [13].
XVI. C ONCLUSION
In Figure 5, we summarize the state of the art along the
different dimensions of code clone management and scopes
for further improvements. Although software clone research
matured over the last decade, the majority of the work focused
on the detection and analysis of code clones. Compared to
those, clone management has earned recent interest due to
its practical importance. Notably several surveys [80, 99,
102, 104, 107] appeared in the literature, none of which
focused on clone management, and thus a survey on clone
management was a timely necessity. This paper presents a
comprehensive survey on clone management and pin-points
research achievements and scopes for further work towards a
versatile clone management system.
At the fundamental level, the vagueness in the deﬁnition
of clones at times causes difﬁculties in formalization, gener-
alization, creation of benchmark data, as well as comparison
of techniques and tools. A set of task oriented deﬁnitions or
taxonomies can address these issues. Most of the integrated
tools have limitations in detecting Type-3 clones, and the
detection of Type-4 clones has still remained an open problem.
Moreover, most of the research on software clones so far
emphasized clone analysis at different levels of granularity.
A variety of techniques for the visualization of clones and
the evolution has been proposed. Surprisingly, while clone
analysis points to the importance of considering inheritance
hierarchy for extracting clone reengineering candidates, there
is still not enough visualization support to analyze clones with
respect to their existence in the inheritance hierarchy.
Research on clone management beyond detection has
mostly been limited to devising techniques to identify clones.
While detection is a necessity for clone management and many
improvements have been achieved here, ﬁltering and ranking
relevant ﬁndings is still a major challenge. It is not yet clear
what constitutes a bad clone that requires treatment. Neither
is it sufﬁciently known what kind of treatment (refactoring or
other types of compensation) works best under which circum-
stances. For the bad clones, we need to conduct root-cause
analysis to better understand why they came into existence
and how they could be avoided.
The state of the art demands more research in semi-
automated tool support for clone refactoring and cost-beneﬁt
analysis of clone removal/refactoring. For integrated clone
management, JSync [95] offers a relatively wide set of
features compared to others. But, we see that the state of
the art is still far from integrated tool support, and more
is to be done towards a versatile clone management system.
Perhaps, due to the unavailability of such tools, there is not
much developer-centric ethnographic studies on the patterns
of clone management in practice, as well as on the usability
and effectiveness of tool support. This survey exposes suchpotential avenues for further research to create a better impact
in the community.
Acknowledgement: We would like to thank our anonymous
reviewers for their useful suggestions and critiques.
REFERENCES
[1] E. Adar and M. Kim. SoftGUESS: Visualization and exploration of
code clones in context. In ICSE , pages 762 –766, 2007.
[2] F. Al-Omari, I. Keivanloo, C. K. Roy, and J. Rilling. Detecting clones
across microsoft .net programming languages. In WCRE , pages 405–
414, 2012.
[3] M. Asaduzzaman, C. K. Roy, and K. A. Schneider. VisCad: Flexible
code clone analysis support for NiCad. In IWSC , pages 77–78, 2011.
[4] M. Bahtiyar. JClone: Syntax tree based clone detection for Java.
Master’s thesis, Linnaeus University, 2010.
[5] B. Baker. On ﬁnding duplication and near-duplication in large software
systems. In WCRE , pages 86 –95, 1995.
[6] T. Bakota, R. Ferenc, and T. Gyimothy. Clone smells in software
evolution. In ICSM , pages 24–33, 2007.
[7] M. Balazinska, E. Merlo, M. Dagenais, B. Lague, and K. Kontogiannis.
Measuring clone based reengineering opportunities. In METRICS ,
pages 292 –303, 1999.
[8] L. Barbour, F. Khomh, and Y . Zou. An empirical study of faults in
late propagation clone genealogies. Journal of Soft.: Evol. and Proc. ,
pages –, 2013 (in press). doi: 10.1002/smr.1597.
[9] H. Basit and S. Jarzabek. Detecting higher-level similarity patterns in
programs. SIGSOFT Softw. Eng. Notes , 30:156–165, 2005.
[10] H. Basit, D. Rajapakse, and S. Jarzabek. An empirical study on limits
of clone uniﬁcation using generics. In SEKE , pages 109–114, 2005.
[11] H. A. Basit, D. C. Rajapakse, and S. Jarzabek. Beyond templates: a
study of clones in the STL and some general implications. In ICSE ,
pages 451–459, 2005.
[12] I. Baxter, A. Yahin, L. Moura, M. Sant’Anna, and L. Bier. Clone
detection using abstract syntax trees. In ICSM , pages 368–377, 1998.
[13] I. D. Baxter, M. Conradt, J. R. Cordy, and R. Koschke. Software clone
management towards industrial application (dagstuhl seminar 12071).
Dagstuhl Reports , 2(2):21–57, 2012.
[14] S. Bazrafshan and R. Koschke. An empirical study of clone removals.
InICSM , pages 50–59, 2013.
[15] S. Bellon, R. Koschke, G. Antoniol, J. Krinke, and E. Merlo. Com-
parison and evaluation of clone detection tools. IEEE Trans. on Softw.
Engg. , 33(9):577–591, 2007.
[16] N. Bettenburg, W. Shang, W. Ibrahim, B. Adams, Y . Zou, and A. Has-
san. An empirical study on inconsistent changes to code clones at the
release level. Science of Comp. Prog. , 77(6):760 – 776, 2012.
[17] S. Bouktif, G. Antoniol, M. Neteler, and E. Merlo. A novel approach
to optimize clone refactoring activity. In GECCO , pages 1885–1892,
2006.
[18] D. Chatterji, J. C. Carver, and N. A. Kraft. Claims and beliefs about
code clones: Do we agree as a community? a survey. In IWSC , pages
15–21, 2012.
[19] D. Chatterji, J. C. Carver, and N. A. Kraft. Cloning: The need to
understand developer intent. In IWSC , pages 14–15, 2013.
[20] D. Chatterji, J. C. Carver, N. A. Kraft, and J. Harder. Effects of cloned
code on software maintainability: A replicated developer study. In
WCRE , pages 112–121, 2013.
[21] A. Chiu and D. Hirtle. Beyond clone detection. CS846 Course Project
Report, University of Waterloo, 2007.
[22] J. R. Cordy. Comprehending reality: Practical barriers to industrial
adoption of software maintenance automation. In IWPC , pages 196–
206, 2003.
[23] J. R. Cordy. Exploring large-scale system similarity using incremental
clone detection and live scatterplots. In ICPC , pages 151–160, 2011.
[24] J. R. Cordy. Live scatterplots. In IWSC , pages 79–80, 2011.
[25] J. R. Cordy, T. R. Dean, and N. Synytskyy. Practical language-
independent detection of near-miss clones. In CASCON , pages 1–12,
2004.
[26] Y . Dang, D. Zhang, S. Ge, C. Chu, Y . Qiu, and T. Xie. XIAO: tuning
code clones at hands of engineers in practice. In ACSAC , pages 369–
378, 2012.
[27] I. Davis and M. Godfrey. Clone detection by exploiting assembler. In
IWSC , pages 77–78. ACM, 2010.
[28] M. de Wit, A. Zaidman, and A. van Deursen. Managing code clones
using dynamic change tracking and resolution. In ICSM , pages 169–
178, 2009.
[29] F. Deissenboeck, B. Hummel, E. Jürgens, B. Schätz, S. Wagner,
J. Girard, and S. Teuchert. Clone detection in automotive model-based
development. In ICSE , pages 603–612. ACM, 2008.
[30] E. Duala-Ekoko and M. Robillard. Clone region descriptors: Repre-
senting and tracking duplication in source code. ACM Trans. Softw.
Eng. Methodol. , 20:3:1–3:31, 2010.
[31] Y . Dubinsky, J. Rubin, T. Berger, S. Duszynski, M. Becker, and
K. Czarnecki. An exploratory study of cloning in industrial software
product lines. In CSMR , pages 25–34, 2013.
[32] S. Ducasse, M. Rieger, and S. Demeyer. A language independent
approach for detecting duplicated code. In ICSM , pages 109 –118,
1999.
[33] R. Falke, P. Frenzel, and R. Koschke. Empirical evaluation of clone
detection using syntax sufﬁx trees. Empirical Software Engineering ,
13:601–643, 2008.
[34] C. Forbes, I. Keivanloo, and J. Rilling. Doppel-Code: A clone
visualization tool for prioritizing global and local clone impacts. In
COMPSAC , pages 366–367, 2012.
[35] M. Fowler, K. Beck, J.Brant, W. Opdyke, and D. Roberts. Refactoring:
Improving the Design of Existing Code . Addison Wesley, 1999.
[36] Y . Fukushima, R. Kula, S. Kawaguchi, K. Fushida, M. Nagura, and
H. Iida. Code clone graph metrics for detecting diffused code clones.
InAPSEC , pages 373 –380, 2009.
[37] S. Giesecke. Generic modelling of code clones. In DRSS , pages 1–23,
2007.
[38] S. Giesecke. Dupman - Eclipse duplication management framework,
last access: Dec 2011. URL http://sourceforge.net/projects/dupman/.
[39] N. Göde and R. Koschke. Frequency and risks of changes to clones.
InICSE , pages 311–320, 2011.
[40] N. Göde and R. Koschke. Studying clone evolution using incremental
clone detection. J. of Soft.: Evol. and Proc. , 25(2):165–192, 2013.
[41] T. L Graves, A. F. Karr, J. S. Marron, and H. Siy. Predicting fault
incidence using software change history. IEEE Tran. on Soft. Engg. ,
26(7):653–661, 2000.
[42] J. Harder. The limits of clone model standardization. In IWSC , pages
10–11, 2013.
[43] J. Harder and N. Göde. Quo vadis, clone management? In IWSC ,
pages 85–86, 2010.
[44] J. Harder and N. Göde. Efﬁciently handling clone data: RCF and
cyclone. In IWSC , pages 81–82. ACM, 2011.
[45] J. Harder and N. Göde. Cloned code: stable code. Journal of Soft.:
Evol. and Proc. , 25(10):1063–1088, 2013.
[46] F. Hermans, B. Sedee, M. Pinzger, and A. van Deursen. Data clone
detection and visualization in Spreadsheets. In ICSE , pages 292–301,
2013.
[47] Y . Higo and S. Kusumoto. Enhancing quality of code clone detection
with program dependency graph. In WCRE , pages 315 –316, 2009.
[48] Y . Higo, T. Kamiya, S. Kusumoto, and K. Inoue. Refactoring support
based on code clone analysis. PROFES , pages 220–233, 2004.
[49] Y . Higo, U. Yasushi, M. Nishino, and S. Kusumoto. Incremental code
clone detection: A PDG-based approach. In WCRE , pages 3 –12, 2011.
[50] K. Hotta, Y . Sano, Y . Higo, and S. Kusumoto. Is duplicate code more
frequently modiﬁed than non-duplicate code in software evolution?:
an empirical study on open source software. In IWPSE-EVOL , pages
73–82, 2010.
[51] D. Hou, P. Jablonski, and F. Jacob. CnP: Towards an environment for
the proactive management of copy-and-paste programming. In ICPC ,
pages 238–242, 2009.
[52] D. Hou, F. Jacob, and P. Jablonski. Exploring the design space of
proactive tool support for copy-and-paste programming. In CASCON ,
pages 188–202, 2009.
[53] B. Hummel, E. Juergens, L. Heinemann, and M. Conradt. Index-based
code clone detection: incremental, distributed, scalable. In ICSM , pages
1 –9, 2010.
[54] P. Jablonski and D. Hou. CReN: a tool for tracking copy-and-paste
code clones and renaming identiﬁers consistently in the IDE. In ETX,
pages 16–20, 2007.
[55] S. Jarzabek and S. Li. Unifying clones with a generative programming
technique: a case study. Journal of Software: Evolution and Process ,
18(4):267–292, 2006.
[56] L. Jiang, G. Misherghi, Z. Su, and S. Glondu. DECKARD: Scalableand accurate tree-based detection of code clones. In ICSE , pages 96–
105, 2007.
[57] Z. Jiang and A. Hassan. A framework for studying clones in large
software systems. In SCAM , pages 203 – 212, 2007.
[58] Z. Jiang, A. Hassan, and R. Holt. Visualizing clone cohesion and
coupling. In APSEC , pages 467–476, 2006.
[59] J. Johnson. Substring matching for clone detection and change tracking.
InICSM , pages 120 –126, 1994.
[60] J. Johnson. Visualizing textual redundancy in legacy source. In
CASCON , pages 32–41. IBM Press, 1994.
[61] J. Johnson. Navigating the textual redundancy web in legacy source.
InCASCON , pages 16–25. IBM Press, 1996.
[62] E. Juergens. Research in cloning beyond code: a ﬁrst roadmap. In
IWSC , pages 67–68, 2011.
[63] E. Juergens and F. Deissenboeck. How much is a clone? In SQM ,
2010.
[64] E. Juergens, F. Deissenboeck, and B. Hummel. CloneDetective - a
workbench for clone detection research. In ICSE , pages 603–606, 2009.
[65] E. Juergens, F. Deissenboeck, M. Feilkas, B. Hummel, B. Schaetz,
S. Wagner, C. Domann, and J. Streit. Can clone detection support
quality assessments of requirements speciﬁcations? In ICSE , pages 79
–88, 2010.
[66] T. Kamiya, S. Kusumoto, and K. Inoue. CCFinder: a multilinguistic
token-based code clone detection system for large scale source code.
IEEE Trans. Softw. Eng. , 28(7):654–670, 2002.
[67] C. Kapser. Toward an Understanding of Software Code Cloning as a
Development Practice . PhD thesis, University of Waterloo, 2009.
[68] C. Kapser and M. Godfrey. Cloning considered harmful” considered
harmful: patterns of cloning in software. Empirical Software Engineer-
ing, 13:645–692, 2008.
[69] C. Kapser and M. W. Godfrey. Aiding comprehension of cloning
through categorization. In IWPSE , pages 85–94, 2004.
[70] C. Kapser and M. W. Godfrey. Improved tool support for the
investigation of duplication in software. In ICSM , pages 305–314,
2005.
[71] C. Kapser and M. W. Godfrey. Supporting the analysis of clones in
software systems: A case study. J. Softw. Maint. Evol. , 18:61–82, 2006.
[72] C. Kapser, J. Harder, and I. Baxter. A common conceptual model for
clone detection results. In IWSC , pages 72–73, 2012.
[73] S. Kawaguchi, T. Yamashina, H. Uwano, K. Fushida, Y . Kamei,
M. Nagura, and H. Iida. SHINOBI: A tool for automatic code clone
detection in the IDE. In WCRE , pages 313–314, 2009.
[74] I. Keivanloo, C. K. Roy, and J. Rilling. SeByte: Scalable clone and
similarity search for bytecode. Science of Comp. Prog. , pages –, 2013
(in press). doi: http://dx.doi.org/10.1016/j.scico.2013.10.006.
[75] J. Kerievsky. Refactoring to Patterns . Addison Wesley, 2004.
[76] H. Kim, Y . Jung, S. Kim, and K. Yi. MeCC: memory comparison-based
clone detector. In ICSE , pages 301–310, 2011.
[77] M. Kim, V . Sazawal, D. Notkin, and G. C. Murphy. An empirical study
of code clone genealogies. In FSE, pages 187–196, 2005.
[78] R. Komondoor and S. Horwitz. Using slicing to identify duplication
in source code. In SAS, pages 40–56, 2001.
[79] K. Kontogiannis. Evaluation experiments on the detection of program-
ming patterns using software metrics. In WCRE , pages 44 –54, 1997.
[80] R. Koschke. Survey of research on software clones. In DRSS , pages
1–24, 2006.
[81] J. Krinke. Is cloned code more stable than non-cloned code? SCAM ,
0:57–66, 2008.
[82] G. P. Krishnan and N. Tsantalis. Uniﬁcation and refactoring of clones.
InCSMR-18/WCRE-21 Software Evolution Week , page 10, 2014 (to
appear).
[83] B. Lague, D. Proulx, J. Mayrand, E. Merlo, and J. Hudepohl. Assessing
the beneﬁts of incorporating function clone detection in a development
process. In ICSM , pages 314–321, 1997.
[84] S. Lee and I. Jeong. SDD: high performance code clone detection
system for large scale source code. In OOPSLA , pages 140–141, 2005.
[85] S. Lee, G. Bae, H. Chae, D. Bae, and Y . Kwon. Automated scheduling
for clone-based refactoring using a competent ga. Softw. Pract. Exper. ,
41(5):521–550, 2010.
[86] H. Liu, Z. Ma, L. Zhang, and W. Shao. Detecting duplications in
sequence diagrams based on sufﬁx trees. In APSEC , pages 269 –276,
2006.
[87] S. Livieri, Y . Higo, M. Matushita, and K. Inoue. Very-large scale
code clone analysis and visualization of open source programs using
distributed CCFinder: D-CCFinder. In ICSE , pages 106–115, 2007.
[88] J. Mayrand, B. Lague, and J. Hudepohl. Evaluating the beneﬁts of
clone detection in the software maintenance activities in large scale
systems. In WESS , 1996.
[89] J. Mayrand, C. Leblanc, and E. Merlo. Experiment on the automatic
detection of function clones in a software system using metrics. In
ICSM , pages 244 –253, 1996.
[90] M. Mondal, C. K. Roy, M. Rahman, R. K. Saha, J. Krinke, and K. A.
Schneider. Comparative stability of cloned and non-cloned code: An
empirical study. In ACM-SAC , pages 1227–1234, 2012.
[91] M. Mondal, C. K. Roy, and K. A. Schneider. An empirical study on
clone stability. ACM Applied Comp. Review , 12(3):20–36, 2012.
[92] M. Mondal, C. K. Roy, and K. A. Schneider. An insight into the
dispersion of changes in cloned and non-cloned code: A genealogy
based empirical study. Sci. of Comp. Prog. , pages –, 2013 (in press).
[93] M. Mondal, C. K. Roy, and K. A. Schneider. Automatic ranking of
clones for refactoring through mining association rules. In CSMR-
18/WCRE-21 Software Evolution Week , page 10, 2014 (to appear).
[94] S. Nasehi, G. Sotudeh, and M. Gomrokchi. Source code enhancement
using reduction of duplicated code. In IASTED , pages 192–197, 2007.
[95] H. Nguyen, T. Nguyen, N. Pham, J. Al-Kofahi, and T. Nguyen. Clone
management for evolving software. IEEE Trans. on Softw. Engg. , 1(1):
1–19, 2011.
[96] T. Nguyen, H. Nguyen, N. Pham, J. Al-Kofahi, and T. Nguyen. Cleman:
Comprehensive clone group evolution management. In ASE, pages
451–454, 2008.
[97] T. Nguyen, H. Nguyen, J. Al-Kofahi, N. Pham, and T. Nguyen. Scalable
and incremental clone detection for evolving software. In ICSM , pages
491–494, 2009.
[98] T. Nguyen, H. Nguyen, N. Pham, J. Al-Kofahi, and T. Nguyen. Clone-
aware conﬁguration management. In ASE, pages 123–134, 2009.
[99] J. Pate, R. Tairas, and N. Kraft. Clone evolution: a systematic review.
Journal of Soft.: Evol. and Proc. , pages 1–23, 2011.
[100] N. Pham, H. Nguyen, T. Nguyen, J. Al-Kofahi, and T. Nguyen.
Complete and accurate clone detection in graph-based models. In ICSE ,
pages 276–286, 2009.
[101] M. S. Rahman, A. Aryani, C. K. Roy, and F. Perin. On the relationships
between domain-based coupling and code clones: an exploratory study.
InICSE , pages 1265–1268, 2013.
[102] D. Rattan, R. Bhatia, and M. Singh. Software clone detection: A
systematic review. Infor. and Soft. Tech. , 55(7):1165 – 1199, 2013.
[103] M. Rieger, S. Ducasse, and M. Lanza. Insights into system-wide code
duplication. In WCRE , pages 100–109, 2004.
[104] C. K. Roy and J. R. Cordy. A survey on software clone detection
research. Tech Report TR 2007-541, Queens University, 2007.
[105] C. K. Roy and J. R. Cordy. NICAD: Accurate detection of near-miss
intentional clones using ﬂexible pretty-printing and code normalization.
InICPC , pages 172–181, 2008.
[106] C. K. Roy and J. R. Cordy. A mutation/injection-based automatic
framework for evaluating code clone detection tools. In ICSTW , pages
157–166, 2009.
[107] C. K. Roy, J. R. Cordy, and R. Koschke. Comparison and evaluation
of code clone detection techniques and tools: A qualitative approach.
Sci. Comput. Program. , 74:470–495, 2009.
[108] R. K. Saha, M. Asaduzzaman, M. F. Zibran, C. K. Roy, and K. A.
Schneider. Evaluating code clone genealogies at release level: An
empirical study. In SCAM , pages 87–96, 2010.
[109] R. K. Saha, C. K. Roy, and K. A. Schneider. Visualizing the evolution
of code clones. In IWSC , pages 71–72. ACM, 2011.
[110] R. K. Saha, C. K. Roy, and K. A. Schneider. An automatic framework
for extracting and classifying near-miss clone genealogies. In ICSM ,
pages 293 –302, 2011.
[111] R. K. Saha, C. K. Roy, and K. A. Schneider. gcad: A near-miss clone
genealogy extractor to support clone evolution analysis. In ICSM , pages
488–491, 2013.
[112] R. K. Saha, C. K. Roy, K. A. Schneider, and D. E. Perry. Understanding
the evolution of type-3 clones: an exploratory study. In MSR , pages
139–148, 2013.
[113] A. Santone. Clone detection through process algebras and Java
bytecode. In IWSC , pages 73–74. ACM, 2011.
[114] S. Schulze and M. Kuhlemann. Advanced analysis for code clone
removal. In WSR , pages 1–2, 2009.
[115] S. Schulze, M. Kuhlemann, and M. Rosenmüller. Towards a refactoring
guideline using code clone classiﬁcation. In WRT , pages 6:1–6:4, 2008.[116] N. Schwarz, M. Lungu, and R. Robbes. On how often code is cloned
across repositories. In ICSE-NIER , pages 1289–1292, 2012.
[117] H. Störrle. Towards clone detection in UML domain models. In ECSA ,
pages 285–293, 2010.
[118] J. Svajlenko, I. Keivanloo, and C. K. Roy. Scaling classical clone
detection tools for ultra-large datasets: An exploratory study. In IWSC ,
pages 16–22, 2013.
[119] J. Svajlenko, C. K. Roy, and J. R. Cordy. A mutation analysis based
benchmarking framework for clone detectors. In IWSC , pages 8–9,
2013.
[120] R. Tairas. Code clones literature, (last access: Dec. 2013). URL http:
//students.cis.uab.edu/tairasr/clones/literature/.
[121] R. Tairas and J. Gray. Phoenix-based clone detection using sufﬁx trees.
InACM-SE , pages 679–684, 2006.
[122] R. Tairas and J. Gray. Get to know your clones with CeDAR. In
OOPSLA , pages 817–818, 2009.
[123] R. Tairas and J. Gray. Increasing clone maintenance support by
unifying clone detection and refactoring activities. Info. & Soft. Tech. ,
54(12):1297–1307, 2012.
[124] R. Tairas, J. Gray, and I. Baxter. Visualizing clone detection results.
InASE, pages 549–550. ACM, 2007.
[125] M. Toomim, A. Begel, and S. Graham. Managing duplicated code with
linked editing. In VLHCC , pages 173–180, 2004.
[126] M. Uddin, C. K. Roy, K. A. Schneider, and A. Hindle. On the
effectiveness of simhash for detecting near-miss clones in large scale
software systems. In WCRE , pages 13 –22, 2011.
[127] Y . Ueda, T. Kamiya, S. Kusumoto, and K. Inoue. Gemini: Maintenance
support environment based on code clone analysis. In METRICS , pages
67–76. IEEE Computer Society Press, 2002.
[128] R. D. Venkatasubramanyam, S. Gupta, and H. K. Singh. Prioritizing
code clone detection results for clone management. In IWSC , pages
30–36, 2013.
[129] T. Wang, M. Harman, Y . Jia, and J. Krinke. Searching for better conﬁg-
urations: a rigorous approach to clone evaluation. In ESEC/SIGSOFT
FSE, pages 455–465, 2013.
[130] X. Wang, Y . Dang, L. Zhang, D. Zhang, E. Lan, and H. Mei. Can i
clone this piece of code here? In ASE, pages 170–179, 2012.
[131] V . Weckerle. CPC: an eclipse framework for automated clone life
cycle tracking and update anomaly detection. Master’s thesis, Freie
Universität Berlin, Germany, 2008.
[132] S. Xie, F. Khomh, and Y . Zou. An empirical study of the fault-
proneness of clone mutation and clone migration. In MSR , pages 149–
158, 2013.
[133] S. Xie, F. Khomh, Y . Zou, and I. Keivanloo. An empirical study on
the fault-proneness of clone migration in clone genealogies. In CSMR-
18/WCRE-21 Software Evolution Week , page 10, 2014 (to appear).
[134] Z. Xing, Y . Xue, and S. Jarzabek. Distilling useful clones by contextual
differencing. In WCRE , pages 102–111, 2013.
[135] Y . Yamanaka, E. Choi, N. Yoshida, K. Inoue, and T.i Sano. Apply-
ing clone change notiﬁcation system into an industrial development
process. In ICPC , pages 199–206, 2013.
[136] N. Yoshida, Y . Higo, T. Kamiya, S. Kusumoto, and K. Inoue. On
refactoring support based on code clone dependency relation. In
METRICS , pages 16–25, 2005.
[137] G. Zhang, X. Peng, Z. Xing, and W. Zhao. Cloning practices: Why
developers clone and what can be changed. In ICSM , pages 285–294,
2012.
[138] G. Zhang, X. Peng, Z. Xing, S. Jiang, H. Wang, and W. Zhao. Towards
contextual and on-demand code clone management by continuous
monitoring. In ASE, pages 497–507, 2013.
[139] Y . Zhang, H. Basit, S. Jarzabek, D Anh, and M. Low. Query-based
ﬁltering and graphical view generation for clone analysis. In ICSM ,
pages 376 –385, 2008.
[140] M. F. Zibran and C. K. Roy. Towards ﬂexible code clone detection,
management, and refactoring in IDE. In IWSC , pages 75–76, 2011.
[141] M. F. Zibran and C. K. Roy. A constraint programming approach to
conﬂict-aware optimal scheduling of prioritized code clone refactoring.
InSCAM , pages 105–114, 2011.
[142] M. F. Zibran and C. K. Roy. Conﬂict-aware optimal scheduling of
code clone refactoring: A constraint programming approach. In ICPC ,
pages 266 – 269, 2011.
[143] M. F. Zibran and C. K. Roy. IDE-based real-time focused search for
near-miss clones. In ACM-SAC , pages 1235–1242, 2012.
[144] M. F. Zibran and C. K. Roy. Conﬂict-aware optimal scheduling of
prioritized code clone refactoring. IET Software , 7(3), 2013.
[145] M. F. Zibran, R. K. Saha, M. Asaduzzaman, and C. K. Roy. Analyzing
and forecasting near-miss clones in evolving software: An empirical
study. In ICECCS , pages 295–304, 2011.
[146] M. F. Zibran, R. K. Saha, C. K. Roy, and K. A. Schneider. Evalu-
ating the conventional wisdom in clone removal: a genealogy-based
empirical study. In SAC, pages 1123–1130, 2013.


“Cloning Considered Harmful” Considered Harmful
Cory Kapser and Michael W. Godfrey
Software Architecture Group (SWAG)
David R. Cheriton School of Computer Science, University of Waterloo
{cjkapser, migod }@uwaterloo.ca
Abstract
Current literature on the topic of duplicated (cloned)
code in software systems often considers duplication
harmful to the system quality and the reasons commonly
cited for duplicating code often have a negative
connotation. While these positions are sometimescorrect, during our case studies we have found that this is
not universally true, and we have found several situations
where code duplication seems to be a reasonable oreven beneﬁcial design option. For example, a method of
introducing experimental changes to core subsystems is to
duplicate the subsystem and introduce changes there in akind of sandbox testbed. As features mature and become
stable within the experimental subsystem, they can then
be introduced gradually into the stable code base. In this
way risk of introducing instabilities in the stable version is
minimized. This paper describes several patterns of cloningthat we have encountered in our case studies and discusses
the advantages and disadvantages associated with using
them.
1. Introduction
It is believed that most large software systems contain
a non-trivial amount of redundant code. Often referred to
as code clones, these segments of code typically involve
10–15% of the source code [24, 25]. Code clones can
arise through a number of different activities. For example,
intentional clones may be introduced through direct “copy-
and-pasting” of code. Unintentional clones on the other
hand may be the manifestation of programming idioms
related to the language or libraries the developers are using.
In much of the literature on the topic [2, 7, 12, 21, 22,
27, 28], cloning is considered harmful to the quality of the
source code. Code clones can cause additional maintenanceeffort. Changes to one segment of code may need to
be propagated to several others, incurring unnecessary
maintenance costs [15]. Locating and maintaining theseclones pose additional problems if they do not evolve
synchronously. With this in mind, methods for automaticrefactoring have been suggested [4, 7], and tools speciﬁcally
to aid developers in the manual refactoring of clones have
also been developed [19].
There is no doubt that code cloning is often an indication
of sloppy design and in such cases should be considered tobe a kind of development “bad smell”. However, we have
found that there are many instances where this is simply not
the case. For example, cloning may be used to introduceexperimental optimizations to core subsystems without
negatively effecting the stability of the main code. Thus,
a variety of concerns such as stability, code ownership, anddesign clarity need to be considered before any refactoring
is attempted; a manager should try to understand the reason
behind the duplication before deciding what action (if any)
to take.
1
This paper introduces eight cloning patterns that we have
uncovered during case studies on large software systems,
some of which we reported in [23, 24, 25]. These
patterns present both good and bad motivations for cloning,
and we discuss both the advantages and disadvantages of
these patterns of cloning in terms of development andmaintenance. In some cases, we identify patterns of cloning
that we believe are beneﬁcial to the quality of the system.
From our observations we have found that refactoring maynot be the best solution in all patterns of cloning. Tools
need to be developed to aid the synchronous maintenance
of clones within a software system, such as Linked Editingpresented by Toomim et al. [29].
This paper introduces the notion of categorizing high
level patterns of cloning in a similar fashion to the
cataloging of design patterns [14] or anti-patterns [8].
There are several beneﬁts that can be gained fromthis characterization of cloning. First, it provides a
ﬂexible framework on top of which we can document
our knowledge about how and why cloning occurs in
1A simple (but trivial) example is the title of this paper. Although there
is a kind of duplication in the wording, no ”refactoring” of the title would
carry the same connotations as the original statement.
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
software. This documentation crystallizes a vocabulary
that researchers and practitioners can possibly use to
communicate about cloning.
As a second contribution, this categorization is a
ﬁrst step towards formally deﬁning these patterns to
aid in automated detection and classiﬁcation. Theseclassiﬁcations can then be used to deﬁne metrics concerning
code quality and maintenance efforts. Automatic
classiﬁcations will also provide us with better measuresof code cloning in software systems and severity of the
problem in general.
The rest of this paper is organized as follows:
Section 2 provides a brief background concerning code
cloning, Section 3 introduces a template to describecode cloning patterns and then discusses eight patterns
we found in software systems, Section 4 discusses the
implications of code cloning patterns on maintenanceand tool requirements, Section 5 describes work that has
contributed to the understanding of code cloning, and in
Section 6 we discuss our conclusions and future work.
2. Code Cloning
Code cloning is considered a serious problem in
industrial software [1, 2, 7, 9, 12, 21, 22, 27, 28]. It
is suspected that approximately 10%–15% of many large
systems is part of duplicated code [2, 12, 24, 25], and
it has been documented to exist at rates of over 50% ofthe effective lines of code (ELOC) in a particular COBOL
system [12]. The literature on the topic has described many
situations that can lead to the duplication of code withina software system [2, 7, 21, 22, 27, 28]. Many of these
can be considered ill intentioned cloning. For example,
developers may duplicate code because the short term costof forming the proper abstractions may outweigh the cost of
duplicating code. Developers may also duplicate code when
they do not fully understand the problem, or the solution,
but they are aware of code that can provide some or all of
the required functionality. Clones can also be introduced asa side effect of programmers’ memories; programmers may
repeat a common solution, unknowingly introducing clones
into the software system [7].
Duplicates can also be introduced with good intentions.
Duplicating code can, in some situations, be used tokeep software architectures clean and understandable.
Duplicates can also be used to keep unreadable,
complicated abstractions from entering the system. Lackof expressiveness of a given programming language may
lead to the use of “boiler-plated” solutions for particular
problems [30], or even source code generation. This kindof technique is common in COBOL development, for
example. In these cases, the use of cloning is typically well
understood by the developers, and the aim is to preventerrors by re-using trusted solutions in new contexts.
There are several problems associated with cloning.
Code cloning can lead to unnecessary increase in code size
[2, 21]. Cloning code can lead to unused, or “dead”, code
in the system that left unchecked can cause problems with
code comprehensibility, readability, and maintainabilityover the life time of the software system [21]. Maintenance
efforts can be increased when bugs have to be ﬁxed
multiple times, and these changes could be prone to errors.Clones of code that is not well understood can introduce
bugs. For example, variables may be shared and modiﬁed
unknowingly [21]. Program comprehensibility can be
affected by the increased code size, as well as the need to
understand the differences between the duplicates.
Code clones can have beneﬁcial effects on the source
code. Code clones can be used to reduce complexity insource code in the cases where abstractions are difﬁcult to
form. As a result, duplicates may be easier to understand
and modify than a solution that employs abstraction, as thestudy performed by Toomim et al. [29] suggests. Also,
risk to the the stability of the code can be avoided by
cloning rather than creating a new abstraction. Cordy notes
that ﬁnancial institutions consider code quality the most
important concern when maintaining software [11]. The
cost of errors in software can dwarf software maintenancecosts. Fixing or modifying an abstraction can introduce
risks of breaking existing code and requires that any
dependent code be extensively tested, a process that is bothcostly and time consuming. Cloning is a common method
of risk minimization that allows code to be maintained
and modiﬁed separately, containing the risk of introducing
errors to a single system or module [11]. Cloning can
be useful in exploratory development, where the reuse ofbehavior can be used to fast track development of a new
feature but the eventual path of evolution is too unknown to
use abstractions.
3. Patterns of Cloning
During our investigations of cloning in large software
systems [23, 24, 25], we found several recurring patterns
of cloning, or rather ways in which developers duplicated
behavior. These patterns are deﬁned by what is duplicated
and why, and to some extent how the duplication is
done. More speciﬁcally, the patterns we consider are both
cloning of large architectural artifacts, such as ﬁles or
subsystems, and ﬁner grained cloning, such as functionsor code snippets. The reasons why developers use these
patterns range from difﬁculty in abstracting the code to
minimizing the risk of breaking a working software system.When we discuss how the duplication is performed, we
describe what the new artifacts will be rather than the tools
that are used to perform the duplication. The information
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
described in these patterns is drawn from the case studies we
have performed and have not yet been formally validated.
To describe our patterns, we use the following template:
Name. Describes the pattern in a few words.
Motivation. Why developers might use this cloning
pattern rather than an appropriate abstraction.
Advantages. Description of the beneﬁts of this pattern
of cloning compared to other methods of reusing
behavior.
Disadvantages. Description of the negative impacts of
this pattern of cloning.
Management. Advice on how this type of cloning can
be managed.
Long term issues. Issues to be aware of when
deciding to use a cloning pattern as a long term
solution.
Structural manifestations. How this type of cloning
pattern occurs in the system. Describes the scope andtype of code copied, as well as the types of changes
that are expected to be made.
Examples. Examples in real systems. In this paper,
the examples are drawn from the GNU spreadsheet
application Gnumeric 1.2.12, the relational database
management system Postgresql 8.0.1, the web serverApache httpd 2.0.49, and the Java mail client Columba
1.2.
We have divided the eight patterns into three related
groups: Forking ,Templating , and Customization .T h i s
partitioning is done based on the high level motivation forthe cloning pattern. Forking is cloning used to bootstrap
development of similar solutions, with the expectation that
evolution of the code will occur somewhat independently,
at least in the short term. A major motivation for forking
is to protect system stability. In these types of cloning,the original code is copied to a new source ﬁle and then
independently developed. Templating is used as a method
to directly copy behavior of existing code but appropriateabstraction mechanisms are unavailable. Templating is used
when there is a common set of requirements shared by
the clones, such as behavior requirements or the use of
a particular library. When these requirements change, all
clones must be maintained together. Customization occurs
when currently existing code does not adequately meet a
new set of requirements. The existing code is cloned and
tailored to solve this new problem.3.1. Forking
Forking patterns often involve larger portions of code
with the intention that the resulting duplicates will need to
evolve independently. The duplication is often used as a
“springboard” from which to start development and works
well in situations where the commonalities and difference
of the end solutions are not clear. At a later time when thenew code has matured, it may be reasonable to refactor any
remaining duplicates. This section describes three examples
offorking patterns that we have seen in our case studies.
3.1.1. Hardware variations.
Name. Hardware variations
Motivation. When creating a new driver for a hardware
family, a similar hardware family may already have an
existing driver. However, there are often non trivialdifferences in the functionality/features between families
of hardware, making it difﬁcult and risky to modify the
existing code while preserving compatibility for the originaltarget.
Advantages. The risk of changing the existing driver is
especially high in this situation as testing the driver on
older hardware devices can be difﬁcult and time consuming.Cloning the existing driver prevents the need for this type of
testing.
Disadvantages. In addition to the general maintenance
issues such as propagating bug ﬁxes, cloned drivers may
introduce unexpected feature interactions, in particular in
the realm of resource management. Code growth can be a
particular issue with this pattern of cloning because entireﬁles or subsystems are copied.
Management. Groups of cloned drivers should be clearly
identiﬁed, and potential bug ﬁxes should be investigated
within the group.
Long term issues. Dead code can slowly creep into the
system unless care is taken to monitor which drivers are still
actively supported.
Structural manifestations. Drivers are commonly
packaged into a single ﬁle for simplicity of use within the
system. Developers usually copy the entire ﬁle, and the
duplicate is then modiﬁed to match the new device.
Examples. The Linux SCSI driver subsystem has
several examples of this pattern of cloning [16]. In
one example, the ﬁle NCR5380.c was copied to the
ﬁleatari
NCR5380.c and adapted for the Atari
hardware device. This new ﬁle was then cloned as
sun3 NCR5380.c to be adapted to the Sun 3 platform.
Another example of driver cloning is the ﬁle esp.c which
has been duplicated and modiﬁed in NCR53C9x.c . What
is interesting in the Linux SCSI drivers is that the authors
duplicating the new ﬁle explicitly reference the ﬁle they
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
have duplicated, making the chain of replications easily
veriﬁed.
3.1.2. Platform variation.
Name. Platform variation
Motivation. When porting software to new platforms,
low level functionality responsible for interaction with the
platform will need to change. Rather than writing portable
code such as a virtualization layer, it is sometimes easier,
faster, and safer to clone the code and make a small number
of platform speciﬁc changes. In addition, the complexityof the possibly interleaved platform speciﬁc code may be
much higher than several versions of the cloned code,
making code cloning a better choice for maintenance.
Advantages. Code complexity that is inherent to platform
optimized code that is interleaved is avoided. Additionally,
stability for currently supported platforms is maintained. As
platforms are likely to evolve independently, maintainingsupport for one platform will not effect the stability of the
code for other platforms.
Disadvantages. The code will evolve along two
dimensions: the requirements of the software and the
support of the platform. Bug ﬁxes may be difﬁcult to
propagate as it may not be clear how or if the bugs are
present in each version of the code. Changes to the interfaceof the platform speciﬁc code become more problematic
because these changes will need to be performed across
several versions of the library.
Management. The platform speciﬁc interaction should be
factored out as much as possible in order to minimize the
amount of cloning necessary. When cloning the code the
variations should be well documented in order to facilitatebug ﬁx propagation.
Long term issues. As groups of platform speciﬁc code
clones grow, the interface that they support will become
more rigid and difﬁcult to change because of the numberof places where changes will need to be made. In order
to guarantee consistent behavior on supported platforms it
will be vital to ensure that visible behavior from each of theclones remains consistent.
Structural manifestations. Platform speciﬁc variations
often exist in the same subsystem. They often manifest as
either cloned ﬁles or subsystems.
Examples. Platform variation cloning is apparent in
several subsystems within Apache’s portable library, the
Apache Portable Runtime (APR). This subsystem is a
portable implementation of functionality that is typicallyplatform dependent, such as ﬁle and network access. Two
examples of this type of cloning are the fileio and
threadproc subsystems. In these two subsystems, there
are four directories: netware ,os2,unix , and win32 .
threadproc has an additional subsystem beos .A l l o f
these directories share some cloning that is easily detectedby a clone detection tool, but there are also duplicates that
are sufﬁciently different that clone detection tools do not
detect the similarity. In these cases, changes are typically
characterized as insertions of additional error checking orAPI calls. With these changes, overall structure remains
the same, and in several cases cloned documentation exists
providing further information about the cloning.
3.1.3. Experimental variation.
Name. Experimental variation
Motivation. Developers may wish to optimize or extend
pre-existing code but do not want to risk system stability.
By forking the existing code, users can have the choice to
run the experimental optimized code or the trusted stablecode.
Advantages. System stability is protected while still
allowing users access to leading edge development.
Changes made to the experimental fork can be merged with
or replace the stable version at a later time.
Disadvantages. Merging code at a later point may
be difﬁcult if the stable version continues to evolve
independently.
Management. Care should be taken to maintain the
experimental version closely with the stable version.
Changes to the external behavior of the existing stablemodule will need to be monitored and introduced in
the duplicated experimental code in order to maintain a
consistent interface.
Long term issues. As the original and duplicate
code evolves, consistent maintenance may become more
difﬁcult. Documentation of the differences should bemaintained in order to aid program comprehension.
Structural manifestations. The cloning pattern will appear
as a cloned ﬁle, subsystem or class. It may even be labeled
as an experimental development effort, as in the case ofseveral Apache modules [25].
Examples. An example of experimental variation can
be found in the Apache httpd web server. In the multi-
process management subsystem, the subsystem worker
was cloned multiple times as threadpool andleader
[25]. The cloned subsystems are experimental variations onworker designed to provide better performance. Because
they are separated from worker , the web server remains
stable while optimizations are being developed.
3.2. Templating
Templating occurs when the desired behavior is already
known and an existing solution closely satisﬁes this need.
Often templating is a matter of parametrization, as opposed
to the complex control ﬂow that might be required for
abstraction when forking patterns are used instead. For
example, one might use this pattern of cloning to achieve
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
the same behavior for floats andshorts in the C
programming language. In this case, the expected changes
to the code are only the types. When developers use cloning
patterns of this type, the evolution of the clones is oftenexpected to be closely related, especially in the case of
boiler-plating . In the subsections that follow we describe
three examples of templating patterns.
3.2.1. Boiler-plating due to language in-expressiveness.
Name. Boiler-plating due to language in-expressiveness
Motivation. Due to language constraints, reusing trusted
and tested code may be difﬁcult to achieve. This can occur
for example when polymorphism cannot be used. This
form of cloning is common in software systems that are
developed in the COBOL language.
Advantages. Can make reuse of trusted code possible.
Allows for consistent behavior for related concepts,
improving program comprehensibility.
Disadvantages. Increased maintenance effort. These code
clones will be expected to evolve very closely, and any
maintenance efforts will very likely require ntimes the
effort for nclones.
Management. Documentation that makes an explicit link
to all duplicates is important. Tools and methodologies suchas Linked Editing [29] should be used to ensure consistent
changes are made to all duplicates. Another approach tomanaging these clones is to use generated code at build time
[20], making the duplicate exist only when the source code
is compiled.
Long term issues. If maintenance is not performed
rigorously, the duplicated code may become unintentionally
different making debugging and testing difﬁcult.
Structural manifestations. Typically these duplicates are
closely located in the software system, either in the same
ﬁle or in the same subsystem, with names that are also very
similar.
Examples. Boiler-plating can be readily found in most
software systems. An example of where this pattern
was used in Postgresql is the contrib/btree
gist
subsystem where there is a great deal of duplication
whose only modiﬁcation is the data type of the procedure
parameters.
3.2.2. API/Library protocols.
Name. API/Library protocols
Motivation. Often the use of particular application program
interfaces (APIs) require ordered series of procedure calls
to achieve desired behaviors. For example, when creating
a button using the Java SWING API, a common order of
activities is to create the button, add it to a container, andassign the action listeners. Similar orderings are common
with libraries as well. The order of activities to successfully
set up a network socket in C on Unix systems is wellestablished. Developers will often copy-and-paste these
sequences of communication and then parametrize them
appropriately to be used for their particular problem.
Advantages. Novice users of the API or library can learn
from other code. Experienced users can reduce coding
effort by quickly duplicating and modifying the code. The
duplicated code can ﬂexibly be changed, and often the size
of the duplication may not warrant further abstractions.
Disadvantages. Developers may be duplicating buggy or
fragile code, degrading the quality of their own code.Management. Locate prevalent cloning of this type
and extend the API or library in use with appropriate
abstractions. For code clones of this type, rigorously review
the duplicates to ensure the duplicated code is high quality.
Long term issues. Changes to the API will require
changes in multiple sites, and these changes may be
problematic in terms of consistency and testing. Using
the appropriate abstractions may decrease the maintenanceeffort by centralizing the required changes.
Structural manifestations. These duplicates are typically
scattered throughout the source code, and are small in size.Examples. In the mail client Columba, this pattern is
readily found in the GUI code where buttons are added.
This sequence of three operations that create a button, set
its action listener, and set its action command is presentthroughout the system where GUI code is present.
3.2.3. General language or algorithmic idioms.
Name. General language or algorithmic idioms
Motivation. Programming idioms are clear and concise
implementations of particular solutions. These idioms
tend to be self documenting for language experts as theyprovide information as to how and why the implementation
is done in this way. Idioms are commonly discussed,
books have been written on this speciﬁc topic [10], and
there is a no shortage of web discussions either. They can
be conventional wisdom in the programming community,such as checking the return after allocating memory in C
programming, or personal dialects of individual developers.
Advantages. Idioms provide structured, standardized
solutions to common problems. These solutions become
self documenting, improving program comprehensibility.
Disadvantages. Inconsistencies or faulty implementations
of programming idioms may be easily overlooked.
Incorrect or inefﬁcient idioms (or anti-idioms) can also be
duplicated, degrading the quality of the code.
Management. Anti-idioms should be located and removed.
Correct idioms should be located and veriﬁed for consistent
implementation.
Long term issues. None.
Structural manifestations. These idioms tend to be
distributed throughout the code, as code snippets.
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
Examples. A common idiom in Apache is how a pointer to
a platform speciﬁc data structure is set in the memory pool.
At least 15 occurrences of this idiom can be found in the
APR subsystem. First, the code checks if the data structurecontaining the pointer exists in the memory pool, and if not
space is allocated for it, then the platform speciﬁc pointer
is assigned. This idiom exists because the APR library uses
similarly deﬁned data structures to point to platform speciﬁc
ones, pthreads for example. These structures also store
platform speciﬁc data that is relevant to the concept, such
as the exit status of the thread. A slight variation to this
idiom is that in some cases the code checks if the memory
pool exists, and returns an error if it does not. This is an
interesting variation as we would expect all copies to behave
in this way.
3.3. Customization
Customization often arises when code solving a very
similar problem to the current problem exists, but additional
or differing requirements create the need for extension or
modiﬁcation. For a variety of reasons, such as concerns
about system stability or code ownership, the existing code
can not be modiﬁed to encompass this additional problem.In these cases, code may be cloned and customized to suit
the speciﬁc development task. In this section we describe
two examples of customization patterns.
3.3.1. Bug workarounds.
Name. Bug workarounds
Motivation. Due to code ownership issues or unacceptable
exposure to risk, it may be difﬁcult to ﬁx a bug at the source,
so work arounds may be necessary. Copying the code and
ﬁxing the bug in order to overload the broken code maybe the only available solution. In other situations, it may
be possible to guard the points where the buggy code is
used. This guard is then copied as part of the usage of theprocedure.
Advantages. The problem can be solved without requiring
retesting of other code. This solution can allow for progress
in development, although it should only be a temporarymeasure.
Disadvantages. Source of the bug is not addressed, causing
further replication of code or, even worse, new code may
not even address the existence of the bug. Also, changes
to the behavior of the buggy code may cause confusion in
the maintenance process if this pattern of duplication is not
made explicit.
Management. Once the original bug is ﬁxed, remove any
duplicates. Planning for this will minimize issues for clone
removal.
Long term issues. The code clone may not be removed
when bug is ﬁxed. This forgotten ﬁx may confusemaintenance efforts later on.
Structural manifestations. These clones can appear as
locally overloaded procedures or methods, or as procedures
with very similar names to the original source. Cloned
guarding statements will be duplicated at points where the
buggy source code is used.
Examples One of the authors (Godfrey) wrote a Java fact
extractor that was built around the internals of Sun’s javac
compiler. On ﬁnding a small bug in the javac source code,
he cloned the offending code into a descendant class andﬁxed the bug there. Because he didn’t have write access to
the class that contained the offending method, he could not
make bug ﬁx directly in the javac code-base (he created abug report instead).
In Postgresql, we see an example of duplication of a
guard for the event of an error due to bugs. In this case,the source code is dependent on MinGW, an external
set of libraries required for platform compatibility. This
library has a bug in it that has not been ﬁxed for the
current release. Because of this, the Postgresql developersduplicated a three line solution three times in three different
ﬁles: src/backend/commands/tablespace.c ,
src/port/copydir.c ,
src/backend/access/transam/xlog.c .
3.3.2. Replicate and specialize.
Name. Replicate and specialize
Motivation. As developers implement solutions, they may
ﬁnd code in the software system that solves a similar
problem to the one they are solving. However, this code
may not be the exact solution, and modiﬁcations may be
required. While the developer could generalize the originalcode, this may have a high cost in testing and refactoring
in the short term. Code cloning may appear to be a more
attractive alternative, and is commonly used in practice tominimize costs associated with risk [11].
Advantages. Reduces immediate costs in testing and
refactoring. Additionally, the high cognitive cost of
developing the abstraction is avoided [29].
Disadvantages. Long term costs of ﬁnding and maintaining
these duplicates could out-weigh the short term gains.Management. If an appropriate abstraction can be made,
deprecating the original code and transitioning to the
abstraction may defer testing costs and protect system
stability. If the appropriate abstractions can not be made,
explicitly linking the code clones through documentation ortool support will ensure consistent maintenance.
Long term issues. Duplicated code can over time
become more entrenched, with more of the software system
dependent upon it. Over time, the cost of refactoring thecode may rise. Differences in the code may make locating
duplicates difﬁcult, making maintenance of clones more
costly.
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
Structural manifestations. These code clones are often
snippets or procedures located near each other, but can be
more widely distributed as well. In some cases these clones
can be particularly hard to detect due to the changes thathave been made. Often the copied code contains control
structures, suggesting that developers use duplication to
reuse complex logic, an observation also noted by Kim et
al. [26].
Examples This pattern is the most common type of
cloning. In one example in Gnumeric, we see this
pattern in use for developing the procedures that
build the locale and character encoding selectionmenus. The procedures can be found in the ﬁles
src/widgets/widget-charmap-selector.c
andsrc/widgets/widget-locale-selector.c .
The control ﬂow of both procedures is very similar.
However, how the items are chosen to be added to the menu
differs, causing a minor change and addition of severallines. Another small difference is the way in which the
menu title is made near the end of the procedure. In addition
to these customizations, the data type containing the list of
entities is also different, performed as a parametric change.
4. Discussion
In describing the patterns of code cloning, we see
different management strategies that should be considered.
For example, experimental variation requires developers
to monitor changes to the external interface of a cloned
subsystem to make decisions on whether or not to propagate
changes to the duplicated code. On the other hand, boiler-
plating requires close synchronization of the maintenance
effort, preferably through an automated approach such
as source code generation. These varying maintenancestrategies require a variety of different tools.
In the case of templating patterns, as mentioned above,
it is clear that there is a need for synchronous editing,
such as that suggested in [29], to manage clones where
evolution between the duplicates should be tightly coupledbut abstraction is not possible. Even in the cases where
abstractions are possible, such as in the case of API
and Library Protocols , Toomim et al. [29] provides some
evidence to suggest that there is less cognitive loadto manage the duplicated code, rather than the proper
abstraction, if Linked Editing is used.
In cases of duplication where the evolution of the
duplicates may not be so tightly coupled, as in thecases of forking patterns, architectural and historical
dependencies of cloning can guide developers to relatedpoints in the software system that should be taken intoconsideration during a maintenance operation. In [23, 24,
25] the authors used cloning relationships visualized as
architectural relationships as aids to locate several examplesof these forking patterns.
In addition to locating forking cloning patterns, it is
important that development tools also explicitly outline the
similarities and difference in the code. During our case
studies, we noted that while it was easy to see similarities
in code, it was far more difﬁcult to ﬁnd and understand the
differences in the code. Identifying the differences in the
code clones is very important as it effects the decisions ofhow and when to propagate changes to duplicated code.
In the cases of the customization patterns, the tool
requirements are a combination of the forking and
templating patterns. In extreme cases of customization,
automated tool support may not be possible for editing,and may not be desirable. Semi-automated approaches
for “patching” code clones may be necessary, especially in
cases of large groups of duplicated code. Such a tool would
iterate over all candidate code clones and selectively patch
clones according to human (expert) decisions.
While we believe that not all clones require refactoring
of abstractions, we also believe there are situations that
warrant the effort. In cases where code is directly copied
to duplicate behavior, such as in sibling classes of an
object-oriented program, refactorings should be performedif the language supports this. In situations where the
behavior of the clones is similar but not the same, the
effect of the costs of refactoring, such as effects on programcomprehension and exposure to risk, should be measured
against the expected gain in maintainability or extendability
of the system.
5. Related Work
Cataloging of software engineering principles and
behaviors is not a new idea. Other works have cataloged
common scenarios that arise in software development and
maintenance. Zou et al. [18] describe several scenarios
in which maintenance activities lead to new functions in asoftware system. Fowler et al. documented approximately
70 refactorings [13]. Refactorings are patterns of behavior
preserving restructuring of source code used to eliminatebad design or source code entities, including duplicated
code. Gamma et al. have described many design patterns
to aid in making more ﬂexible and reusable code [14].
Clone classiﬁcation schemes have been previously
suggested, usually based on the degree of similarity of
segments of code and also the type of differences [3, 28]. In
the work presented by Mayrand et al. [28] and Balazinksaet al. [3] these classiﬁcations are limited to function clones
only. In previous work [23, 24, 25] the authors present
a classiﬁcation scheme based on locality, size, code type,and similarity. The classiﬁcation includes clones varying
in scope from functions down to code blocks. This
classiﬁcation scheme was used to aid the analysis of cloning
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
in large software systems. Balazinska et al. [5] used a
classiﬁcation of function clones to produce software aided
re-engineering systems for code clone elimination.
The classiﬁcation of cloning presented here differs from
the above categorizations in both the type of categorization
and the goal of the work. In this paper, cloning is
categorized primarily from motivational perspective, while
other categorizations focus on the structural properties of
the clones. The goal of this paper is not to categorize
clones for purposes of refactoring but to document the
types of cloning that occur in software to aid the general
understanding of how cloning is done in practice.
Several case studies on cloning in software systems
have contributed to the source of information for compiling
these cloning patterns. Clone detection case studies on
the Linux kernel have been reported in [1, 9, 16]. In [9],
Casazza et al. use metrics based clone detection to detectcloned functions within the Linux kernel. The conclusions
of this study were that in general the addition of similar
subsystems was done through code reuse rather than codecloning, and more recently introduced subsystems tended
to have more cloning activity. Antoniol et al. [1] did
a similar study, evaluating the evolution of code cloningin the Linux, concluding that the structure of the Linux
kernel did not appear to be degrading due to code cloning
activities. In [17] a preliminary investigation of cloningamong Linux SCSI drivers was performed. The authors
recently investigated cloning in several large software
systems [23, 24, 25]. These studies provide insight into
the types of code that are cloned and why, in particular
[25] describes an in-depth investigation into the sources ofduplication in the Apache httpd web server.
Cordy reports on the use of code cloning as a method
of minimizing and containing risk during maintenance andextensions of ﬁnancial software [11]. Often occurring inthe form of customization, developers may use cloning to
reuse the design of an existing application. Cloning is also
used to separate the dependencies of custom views on datathat several modules or applications may have. Cloning
in this way prevents the introduction of bugs into working
code, and conﬁnes testing to a smaller subset of sourcecode. Cordy also suggests that developers may not want
to universally propagate bug ﬁxes across clones as this may
break dependent code [11].
Jarzabek et al. [20] and Basit et al. [6] performed case
studies for reducing duplication in on the Java buffer classesand the STL. In their studies, they used a meta-languageXVCL to reconstruct the code at compile time. In [20]
many clones existed because of language limitations and
were removed using templates. In [6] the STL made heavyuse of generics to reduce redundant code but redundant
code still existed in a form analogous to customization
andboiler-plating patterns where operators were modiﬁed.Balazinska et al. [3] measured the number of clones
with various degrees of similarity, and found that exact
duplicates were the most common followed by duplication
with larger changes. The third and forth most prominentgroups appeared to be clones where the called methods have
been changed or a global variable has been changed. These
last two types are similar to a templating pattern.
Kim et al. studied how developers used copy-and-paste
features of the Eclipse IDE [26]. In this study, Kim et al.
noted that developers often use copy-and-paste to structureand guide the task of extending a software system. For
example, they noted that developers will sometimes copy
a parent or sibling class to use as a template for writing a
new sibling class. Kim et al. also observed usage patterns
similar to the templating pattern noted here. Kim et al.
observed that developers used copy-and-paste to duplicate
control structures, similar to our Replicate and Specialize
pattern. The work presented here differs in that it focuses
on how duplicated code that persists in the source code is
used as part of a design decision.
6. Conclusions
Code cloning is often presented as a negative design
characteristic in software systems, usually attributed to the
limitations of the developers. Often referred to as a bad
“code smell”, many negative effects of code cloning have
been cited as reasons to remove code duplicates from sourcecode. During our case studies of large software systems, we
found that code cloning can often be used in a positive way.
In this paper we list several patterns of cloning that
are used in real software systems. In our descriptions of
these cloning patterns we discuss the pros and cons of
using cloning and suggest methods of managing these codeclones. We also discuss long term issues that may arise
and provide concrete examples of these cloning patterns in
real software systems. These insights provide evidence tosupport the notion that clones can be a reasonable design
decision and that tools should be developed with long term
maintenance of duplicates in mind.
In the future we would like to identify more patterns
of cloning, and automatically identify these patterns inorder to aid developers in maintenance and refactoring
decisions. We would also like to identify the degree to
which these patterns exist in software systems as well asoccasions where using the cloning pattern was a successful
development method and when it was not.
References
[1] G. Antoniol, U. Villano, E. Merlo, , and M. D. Penta.
Analyzing cloning evolution in the linux kernel. In
Information and Software Technology 44(13) , 2002.
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
[2] B. S. Baker. On ﬁnding duplication and near-duplication
in large software systems. In WCRE ’95: Proceedings of
the Second Working Conference on Reverse Engineering ,
page 86, Washington, DC, USA, 1995. IEEE Computer
Society.
[3] M. Balazinska, E. Merlo, M. Dagenais, B. Lague, and
K. Kontogiannis. Measuring clone based reengineering
opportunities. In Proceedings of the Sixth International
Software Metrics Symposium , pages 292–303, 1999.
[4] M. Balazinska, E. Merlo, M. Dagenais, B. Lague, and
K. Kontogiannis. Partial redesign of java software systems
based on clone analysis. In The Proceedings of the 6th.
Working Conference on Reverse Engineering , pages 326–
336, 1999.
[5] M. Balazinska, E. Merlo, M. Dagenais, B. Lague, and
K. Kontogiannis. Advanced clone analysis to support object-oriented system refactoring. In Proceedings of the 7th.
Working Conference on Reverse Engineering , pages 98–107,
2000.
[6] H. A. Basit, D. C. Rajapakse, and S. Jarzabek. Beyond
templates: a study of clones in the STL and some general
implications. In ICSE ’05: Proceedings of the 27th
international conference on Software engineering , pages
451–459, New York, NY , USA, 2005. ACM Press.
[7] I. D. Baxter, A. Yahin, L. Moura, M. Sant’Anna, and L. Bier.
Clone detection using abstract syntax trees. In ICSM ’98:
Proceedings of the International Conference on Software
Maintenance , page 368, Washington, DC, USA, 1998. IEEE
Computer Society.
[8] W. J. Brown, R. C. Malveau, H. W. M. (III), and
T. J. Mowbray. AntiPatterns: Refactoring Software,
Architectures, and Projects in Crisis . Wiley, 1st edition,
1998.
[9] G. Casazza, G. Antoniol, U. Villano, E. Merlo, and M. D.
Penta. Identifying clones in the linux kernel. In First
IEEE International Workshop on Source Code Analysis and
Manipulation , pages 92–100. IEEE Computer Society Press,
2001.
[10] J. O. Coplien. Advanced C++ Programming Styles and
Idioms . Addison Wesley Professional, 1st edition, 1992.
[11] J. R. Cordy. Comprehending reality - practical barriers to
industrial adoption of software maintenance automation. In
IWPC , pages 196–206. IEEE Computer Society, 2003.
[12] S. Ducasse, M. Rieger, and S. Demeyer. A language
independent approach for detecting duplicated code.
InProceedings ICSM’99: International Conference on
Software Maintenance , pages 109–118. IEEE, 1999.
[13] M. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts.
Refactoring: Improving the Design of Existing Code .
Addison-Wesley Professional, 1st edition, 1999.
[14] E. Gamma, R. Helm, R. Johnson, and J. Vlissides. Design
Patterns: Elements of Reusable Object-Oriented Software .
Addison-Wesley Professional, 1st edition, 1995.
[15] R. Geiger, B. Fluri, H. Gall, and M. Pinzger. Relation
of code clones and change couplings. In Fundamental
Approaches to Software Engineering, 9th International
Conference, FASE 2006 , volume 3922 of Lecture Notes in
Computer Science , pages 411–425. Springer, 2006.[16] M. W. Godfrey, D. Svetinovic, and Q. Tu. Evolution,
growth, and cloning in Linux: A case study. A
presentation at the 2000 CASCON workshop on
’Detecting duplicated and near duplicated structures
in largs software systems: Methods and applications’, on
November 16, 2000, chaired by Ettore Merlo; available at
http://plg.uwaterloo.ca/˜migod/ papers/cascon00-linuxcloning.pdf .
[17] M. W. Godfrey and Q. Tu. Evolution in open source
software: A case study. In Proceedings of the 2000
International Conference on Software Maintenance , 2000.
[18] M. W. Godfrey and L. Zou. Using origin analysis to
detect merging and splitting of source code entities. IEEE
Transactions on Software Engineering , 31(2), 2005.
[19] Y . Higo, T. Kamiya, S. Kusumoto, and K. Inoue. Aries:
Refactoring support environment based on code clone
analysis. In The 8th IASTED International Conference on
Software Engineering and Applications(SEA 2004) , pages
222–229, 2004.
[20] S. Jarzabek and L. Shubiao. Eliminating redundancies
with a ”composition with adaptation” meta-programmingtechnique. In ESEC/FSE-11: Proceedings of the 9th
European software engineering conference held jointly
with 11th ACM SIGSOFT international symposium on
Foundations of software engineering , pages 237–246, New
York, NY , USA, 2003. ACM Press.
[21] J. H. Johnson. Substring matching for clone detection
and change tracking. In Proceedings of the International
Conference on Software Maintanence , pages 120–126,
1994.
[22] T. Kamiya, S. Kusumoto, and K. Inoue. Ccﬁnder: A
multilinguistic token-based code clone detection system
for large scale source code. In Transactions on Software
Engineering 8(7) , pages 654–670. IEEE Computer Society
Press, 2002.
[23] C. Kapser and M. W. Godfrey. Toward a taxonomy of clones
in source code: A case study. In Evolution of Large Scale
Industrial Software Architectures , 2003.
[24] C. Kapser and M. W. Godfrey. Aiding comprehension
of cloning through categorization. In Proc. of 2004
International Workshop on Principles of Software Evolution(IWPSE-04) , pages 85–94, 2004.
[25] C. J. Kapser and M. W. Godfrey. Supporting the analysis
of clones in software systems. Journal of Software
Maintenance and Evolution: Research and Practice ,
18(2):61–82, 2006.
[26] M. Kim, L. Bergman, T. Lau, and D. Notkin. An
ethnographic study of copy and paste programming
practices in oopl. In ISESE ’04: Proceedings of the
2004 International Symposium on Empirical Software
Engineering (ISESE’04) , pages 83–92, Washington, DC,
USA, 2004. IEEE Computer Society.
[27] K. Kontogiannis, R. DeMori, E. Merlo, M. Galler, and
M. Bernstein. Pattern matching for clone and concept
detection. Autom. Softw. Eng. , 3(1/2):77–108, 1996.
[28] J. Mayrand, C. Leblanc, and E. Merlo. Experiment on
the automatic detection of function clones in a software
system using metrics. In Proceedings of the International
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 
Conference on Software Maintenance , pages 244–253. IEEE
Computer Society Press, 1996.
[29] M. Toomim, A. Begel, and S. L. Graham. Managing
duplicated code with linked editing. In VLHCC ’04:
Proceedings of the 2004 IEEE Symposium on Visual
Languages - Human Centric Computing (VLHCC’04) ,
pages 173–180, Washington, DC, USA, 2004. IEEE
Computer Society.
[30] A. Walenstein, N. Jyoti, J. Li, Y . Yang, and A. Lakhotia.
Problems creating task-relevant clone detection reference
data. In Proceedings of the 10th Working Conference on
Reverse Engineering (WCRE-03) , pages 285–294. IEEE
Computer Society Press, 2003.
Proceedings of the 13th Working Conference on Reverse Engineering (WCRE'06)
0-7695-2719-1/06 $20.00  © 2006
Authorized licensed use limited to: Universiteit van Amsterdam. Downloaded on November 26,2025 at 13:27:05 UTC from IEEE Xplore.  Restrictions apply. 


ScienceofComputerProgramming74(2009)470495
Contents lists available at ScienceDirect
ScienceofComputerProgramming
journal homepage: www.elsevier.com/locate/scico
Comparisonandevaluationofcodeclonedetectiontechniquesand
tools:Aqualitativeapproach
ChanchalK.Roya,,JamesR.Cordya,RainerKoschkeb
aSchoolofComputing,Queen'sUniversity,Canada
bUniversityofBremen,Germany
a r t i c l e i n f o
Articlehistory:
Received9November2008
Receivedinrevisedform19February2009
Accepted20February2009
Availableonline10March2009
Keywords:
Softwareclone
Clonedetection
Comparison
Scenario-basedevaluationa b s t r a c t
Overthelastdecademanytechniquesandtoolsforsoftwareclonedetectionhavebeen
proposed.Inthispaper,weprovideaqualitativecomparisonandevaluationofthecurrent
state-of-the-artinclonedetectiontechniquesandtools,andorganizethelargeamountof
informationintoacoherentconceptualframework.Webeginwithbackgroundconcepts,
agenericclonedetectionprocessandanoveralltaxonomyofcurrenttechniquesand
tools.Wethenclassify,compareandevaluatethetechniquesandtoolsintwodifferent
dimensions.First,weclassifyandcompareapproachesbasedonanumberoffacets,eachof
whichhasasetof(possiblyoverlapping)attributes.Second,wequalitativelyevaluatethe
classifiedtechniquesandtoolswithrespecttoataxonomyofeditingscenariosdesigned
tomodelthecreationof Type-1,Type-2,Type-3andType-4clones.Finally,weprovide
examplesofhowonemightusetheresultsofthisstudytochoosethemostappropriate
clonedetectiontoolortechniqueinthecontextofaparticularsetofgoalsandconstraints.
Theprimarycontributionsofthispaperare:(1)aschemaforclassifyingclonedetection
techniquesandtoolsandaclassificationofcurrentclonedetectorsbasedonthisschema,
and(2)ataxonomyofeditingscenariosthatproducedifferentclonetypesandaqualitative
evaluationofcurrentclonedetectorsbasedonthistaxonomy.
'2009ElsevierB.V.Allrightsreserved.
1. Introduction
Reusingcodefragmentsbycopyingandpastingwithorwithoutminoradaptationisacommonactivityinsoftware
development.Asaresultsoftwaresystemsoftencontainsectionsofcodethatareverysimilar,called codeclones.Previous
researchshowsthatasignificantfraction(between7%and23%)ofthecodeinatypicalsoftwaresystemhasbeencloned
[8,99].Whilesuchcloningisoftenintentional[ 64]andcanbeusefulinmanyways[ 3,61],itcanbealsobeharmfulin
softwaremaintenanceandevolution[ 56].Forexample,ifabugisdetectedinacodefragment,allfragmentssimilarto
itshouldbecheckedforthesamebug[ 84].Duplicatedfragmentscanalsosignificantlyincreasetheworktobedone
whenenhancingoradaptingcode[ 87].Manyothersoftwareengineeringtasks,suchasprogramunderstanding(clones
maycarrydomainknowledge),codequalityanalysis(fewerclonesmaymeanbetterqualitycode),aspectmining(clones
mayindicatethepresenceofanaspect),plagiarismdetection,copyrightinfringementinvestigation,softwareevolution
analysis,codecompaction(forexample,inmobiledevices),virusdetection,andbugdetectionmayrequiretheextraction
ofsyntacticallyorsemanticallysimilarcodefragments,makingclonedetectionanimportantandvaluablepartofsoftware
analysis[102].
Correspondingauthor.Tel.:+16135444810.
E-mailaddresses: croy@cs.queensu.ca (C.K.Roy),cordy@cs.queensu.ca (J.R.Cordy),koschke@informatik.uni-bremen.de (R.Koschke).
0167-6423/$seefrontmatter '2009ElsevierB.V.Allrightsreserved.
doi:10.1016/j.scico.2009.02.007
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 471
Fortunately,several(semi-)automatedtechniquesfordetectingcodecloneshavebeenproposed,andtherehavebeen
anumberofcomparisonandevaluationstudiestorelatethem.Themostrecentstudy,byBellonetal.[ 18],providesa
comprehensivequantitativeevaluationofsixclonedetectorsindetectingknownobservedclonesinanumberofopen
sourcesoftwaresystemswritteninCandJava.Otherstudieshaveevaluatedclonedetectiontoolsinothercontexts[ 72,
22,105,106].Thesestudieshavenotonlyprovidedsignificantcontributionstotheclonedetectionresearch,buthavealso
exposedhowchallengingitistocomparedifferenttools,duetothediversenatureofthedetectiontechniques,thelackof
standardsimilaritydefinitions,theabsenceofbenchmarks,thediversityoftargetlanguages,andthesensitivitytotuning
parameters[4].Todatenocomparativeevaluationhasconsideredallofthedifferenttechniquesavailable.Eachstudyhas
chosenanumberofstate-of-the-arttoolsandcomparedthemusingprecision,recall,computationalcomplexityandmemory
use.Thereisalsoasyetnothirdpartyevaluationofthemostrecenttools,suchas CP-Miner[84],Deckard[52],cpdetector
[72],RTF[12],Asta[42]andNICAD[104].
Inthispaper,weprovideacomprehensivequalitativecomparisonandevaluationofallofthecurrentlyavailableclone
detectiontechniquesandtoolsinthecontextofaunifiedconceptualframework.Beginningwithabasicintroductionto
clonedetectionbackgroundandterminology,weorganizethecurrenttechniquesandtoolsintoataxonomybasedona
genericclonedetectionprocessmodel.Wethenclassify,compareandevaluatethetechniquesandtoolsintwodifferent
dimensions.
First,weperformaclassificationandoverallcomparisonwithrespecttoanumberoffacets,eachofwhichhasaset
of(possiblyoverlapping)attributes.Second,wedefineataxonomyofeditingscenariosdesignedtocreate Type-1,Type-2,
Type-3,andType-4clones,whichweusetoqualitativelyevaluatethetechniquesandtoolswehavepreviouslyclassified.In
particular,weestimatehowwellthevariousclonedetectiontechniquesmayperformbasedontheir publishedproperties
(eitherinthecorrespondingpublishedpapersoronlinedocumentation).Inordertoestimatemaximalpotential,wehave
assumedthemostlenientsettingsofanytunableparametersofthetechniquesandtools.Thus,thisisnotanactual
evaluation,ratheritprovidesanoverallpictureofthepotentialofeachtechniqueandtoolinhandlingclonesresulting
fromeachofthescenarios.Ourcomparisonisnotintendedtobeaconcreteexperiment,andcouldnotbecomprehensive
ortrulypredictiveandqualitativeifitwerecastasone,boundtotargetlanguages,platformsandimplementations.Finally,
weprovidetwoexamplesofhowonemightusetheresultsofthisstudytoidentifyoneormoreappropriateclonedetectors
givenasetofconstraintsandgoals.
Incontrasttopreviousstudies,whichconcentrateonempiricallyevaluatingtools,weaimtoidentifytheessential
strengthsandweaknessesofbothindividualtoolsandtechniquesandalternativeapproachesingeneral.Ourgoalisto
provideacompletecatalogueofavailabletechnologyanditspotentialtorecognize``real''clones,thatis,thosethatcouldbe
createdbytheeditingoperationstypicalofactualintentionalcodereuse.
Tothebestofourknowledge,thispaperisthefirststudyofthearea,otherthanKoschke'srecentoverview[ 70,69,73]
andourownshortconferencepaper[ 103],thatprovidesacompletecomparisonofallavailableclonedetectiontechniques.
Foranevenmorecompletein-depthoverviewofthearea,readersarereferredtoourrecenttechnicalreport[ 102].
Ourworkparticularlydiffersfromprevioussurveysinouruseofeditingscenariosasabasisforestimatingtheabilityof
techniquestodetectintentionalratherthanobservedclones,intheevaluationoftechniquesforwhichnorunnabletools
asyetexist,intheinclusionofanumberofnewtechniquesandtoolsthathavenotbeenpreviouslyreviewed,andinthe
comparisonoftechniquesindependentofenvironmentandtargetlanguage.Ourgoalisnotonlytoprovidethecurrent
comparativestatusofthetoolsandtechniques,butalsotomakeanevaluationindicativeoffuturepotential(e.g.,whenone
aimstodevelopanewhybridtechnique)ratherthansimplypresentimplementation.
Therestofthispaperisorganizedasfollows.AfterintroducingsomebackgroundtermsinSection 2,weprovideageneral
overviewoftheclonedetectionprocessinSection 3.Wepresenttheavailableclonedetectiontechniquesintheformofa
taxonomyinSection 4,andbasedonthetaxonomy,Section 5presentsanoverallcomparisonofthetechniquesandtoolsin
termsofseveralgeneralcriteriaorganizedintofacets.Section 6introducesourtaxonomyofhypotheticaleditingscenarios
andpresentsourqualitativeevaluationresult,ananalysisofthetechniquesandtoolsintermsoftheirestimatedabilityto
detectclonescreatedbyeachscenario.Anexamplediscussiononhowtheresultsofthisstudycanbeusefultoapotential
userortoolbuilderispresentedinSection 7.Section8relatesourworktothatofothers,andfinally,Section 9concludes
thepaperandsuggestsdirectionsforfuturework.
2. Background
Webeginwithabasicintroductiontoclonedetectionterminology.
Definition 1(CodeFragment).Acodefragment(CF)isanysequenceofcodelines(withorwithoutcomments).Itcanbeof
anygranularity,e.g.,functiondefinition,beginendblock,orsequenceofstatements.A CFisidentifiedbyitsfilenameand
beginendlinenumbersintheoriginalcodebaseandisdenotedasatriple (CF.FileName,CF.BeginLine,CF.EndLine) .
Definition 2(CodeClone).Acodefragment CF2isacloneofanothercodefragment CF1iftheyaresimilarbysomegiven
definitionofsimilarity,thatis, f(CF1)Df(CF2)wherefisthesimilarityfunction(see clonetypesbelow).Twofragmentsthat
aresimilartoeachotherforma clonepair .CF1;CF2/,andwhenmanyfragmentsaresimilar,theyforma cloneclassorclone
group.
472 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Definition 3(CloneTypes).Therearetwomainkindsofsimilaritybetweencodefragments.Fragmentscanbesimilarbased
onthesimilarityoftheirprogramtext,ortheycanbesimilarbasedontheirfunctionality(independentoftheirtext).Thefirst
kindofcloneisoftentheresultofcopyingacodefragmentandpastingintoanotherlocation.Inthefollowingweprovide
thetypesofclonesbasedonboththetextual(Types1to3)[ 18]andfunctional(Type4)[ 46,65]similarities:
Type-1:Identicalcodefragmentsexceptforvariationsinwhitespace,layoutandcomments.
Type-2:Syntactically identical fragments except for variations in identifiers, literals, types, whitespace, layout and
comments.
Type-3:Copiedfragmentswithfurthermodificationssuchaschanged,addedorremovedstatements,inadditionto
variationsinidentifiers,literals,types,whitespace,layoutandcomments.
Type-4:Twoormorecodefragmentsthatperformthesamecomputationbutareimplementedbydifferentsyntactic
variants.
3. Clone detection process
Aclonedetectormusttrytofindpiecesofcodeofhighsimilarityinasystem'ssourcetext.Themainproblemisthatit
isnotknownbeforehandwhichcodefragmentsmayberepeated.Thusthedetectorreallyshouldcompareeverypossible
fragmentwitheveryotherpossiblefragment.Suchacomparisonisprohibitivelyexpensivefromacomputationalpointof
viewandthus,severalmeasuresareusedtoreducethedomainofcomparisonbeforeperformingtheactualcomparisons.
Evenafteridentifyingpotentiallyclonedfragments,furtheranalysisandtoolsupportmayberequiredtoidentifytheactual
clones.Inthissection,weprovideanoverallsummaryofthebasicstepsinaclonedetectionprocess.Thisgenericoverall
pictureallowsustocompareandevaluateclonedetectiontoolswithrespecttotheirunderlyingmechanismsforthe
individualstepsandtheirlevelofsupportforthesesteps.
Fig.1showsthesetofstepsthatatypicalclonedetectormayfollowingeneral(althoughnotnecessarily).Thegeneric
processshownisageneralizationunifyingthestepsofexistingtechniques,andthusnotalltechniquesincludeallthesteps.
Inthefollowingsubsections,weprovideashortdescriptionofeachofthephases.
3.1. Pre-processing
Atthebeginningofanyclonedetectionapproach,thesourcecodeispartitionedandthedomainofthecomparisonis
determined.Therearethreemainobjectivesinthisphase:
Remove uninteresting parts: Allthesourcecodeuninterestingtothecomparisonphaseisfilteredoutinthisphase.
Forexample,partitioningisappliedtoembeddedcodetoseparatedifferentlanguages(e.g.,SQLembeddedinJavacode,or
AssemblerinCcode).Thisisespeciallyimportantifthetoolisnotlanguageindependent.Similarly,generatedcode(e.g.,
LEX-andYACC-generatedcode)andsectionsofsourcecodethatarelikelytoproducemanyfalsepositives(suchastable
initialization)canberemovedfromthesourcecodebeforeproceedingtothenextphase[ 96].
Determine source units: Afterremovingtheuninterestingcode,theremainingsourcecodeispartitionedintoasetof
disjointfragmentscalledsourceunits.Theseunitsarethelargestsourcefragmentsthatmaybeinvolvedindirectclone
relationswitheachother.Sourceunitscanbeatanylevelofgranularity,forexample,files,classes,functions/methods,
beginendblocks,statements,orsequencesofsourcelines.
Determine comparison units/granularity: Sourceunitsmayneedtobefurtherpartitionedintosmallerunitsdepending
onthecomparisontechniqueusedbythetool.Forexample,sourceunitsmaybesubdividedintolinesoreventokens
forcomparison.Comparisonunitscanalsobederivedfromthesyntacticstructureofthesourceunit.Forexample,an if-
statementcanbefurtherpartitionedintoa conditionalexpression,thenandelseblocks.Theorderofcomparisonunitswithin
theircorrespondingsourceunitmayormaynotbeimportant,dependingonthecomparisontechnique.Sourceunitsmay
themselvesbeusedascomparisonunits.Forexample,inametrics-basedtool,metricsvaluescanbecomputedfromsource
unitsofanygranularityandtherefore,subdivisionofsourceunitsisnotrequiredinsuchapproaches.
3.2. Transformation
Oncetheunitsofcomparisonaredetermined,ifthecomparisontechniqueisotherthantextual,thesourcecodeofthe
comparisonunitsistransformedtoanappropriateintermediaterepresentationforcomparison.Thistransformationofthe
sourcecodeintoanintermediaterepresentationisoftencalled extractioninthereverseengineeringcommunity.
Sometoolssupportadditionalnormalizingtransformationsfollowingextractioninordertodetectsuperficiallydifferent
clones.Thesenormalizationscanvaryfromverysimplenormalizations,suchasremovalofwhitespaceandcomments[ 6],
tocomplexnormalizations,involvingsourcecodetransformations[ 104].Suchnormalizationsmaybedoneeitherbeforeor
afterextractionoftheintermediaterepresentation.
3.2.1. Extraction
Extractiontransformssourcecodetotheformsuitableasinputtotheactualcomparisonalgorithm.Dependingonthe
tool,ittypicallyinvolvesoneormoreofthefollowingsteps.
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 473
Fig. 1.Agenericclonedetectionprocess.
Tokenization:Incaseoftoken-basedapproaches,eachlineofthesourceisdividedintotokensaccordingtothelexical
rulesoftheprogramminglanguageofinterest.Thetokensoflinesorfilesthenformthetokensequencestobecompared.All
whitespace(includinglinebreaksandtabs)andcommentsbetweentokensareremovedfromthetokensequences. CCFinder
[59]andDup[6]aretheleadingtoolsthatusethiskindoftokenizationonthesourcecode.
Parsing:Incaseofsyntacticapproaches,theentiresourcecodebaseisparsedtobuildaparsetreeor(possiblyannotated)
abstractsyntaxtree(AST).ThesourceunitstobecomparedarethenrepresentedassubtreesoftheparsetreeortheAST,
andcomparisonalgorithmslookforsimilarsubtreestomarkasclones[ 15,113,116].Metrics-basedapproachesmayalso
useaparsetreerepresentationtofindclonesbasedonmetricsforsubtrees[ 66,87].
Control and data flow analysis: Semantics-awareapproachesgenerateprogramdependencegraphs(PDGs)fromthe
sourcecode.ThenodesofaPDGrepresentthestatementsandconditionsofaprogram,whileedgesrepresentcontroland
datadependencies.SourceunitstobecomparedarerepresentedassubgraphsofthesePDGs.Thetechniquesthenlook
forisomorphicsubgraphstofindclones[ 65,75].Somemetrics-basedapproachesusePDGsubgraphstocalculatedataand
controlflowmetrics[ 66,87].
474 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
3.2.2. Normalization
Normalizationisanoptionalstepintendedtoeliminatesuperficialdifferencessuchasdifferencesinwhitespace,
commenting,formattingoridentifiernames.
Removal of whitespace: Almostallapproachesdisregardwhitespace,althoughline-basedapproachesretainlinebreaks.
Somemetrics-basedapproacheshoweveruseformattingandlayoutaspartoftheircomparison.Daveyetal.[ 31]usethe
indentationpatternofpretty-printedsourcetextasoneofthefeaturesoftheirattributevectors,andMayrandetal.[ 87]use
layoutmetricssuchasthenumberofnon-blanklines.
Removal of comments: Mostapproachesremoveandignorecommentsintheactualcomparison.However,Marcusand
Maletic[86]explicitlyusecommentsaspartoftheirconceptsimilaritymethod,andMayrandetal.[ 87]usethenumberof
commentsasoneoftheirmetrics.
Normalizing identifiers: Mostapproachesapplyanidentifiernormalizationbeforecomparisoninordertoidentify
parametricType-2clones.Ingeneral,allidentifiersinthesourcecodearereplacedbythesamesingleidentifierinsuch
normalizations.However,Baker[ 6]usesanorder-sensitiveindexingschemetonormalizefordetectionofconsistently
renamedType-2clones.
Pretty-printing of source code: Prettyprintingisasimplewayofreorganizingthesourcecodetoastandardformthat
removesdifferencesinlayoutandspacing.Prettyprintingisnormallyusedintext-basedclonedetectionapproachestofind
clonesthatdifferonlyinspacingandlayout.Cordyetal.[ 28]useanislandgrammar[ 91]togenerateaseparatepretty-
printedtextfileforeachpotentiallyclonedsourceunit.
Structural transformations: Othertransformationsmaybeappliedthatactuallychangethestructureofthecode,sothat
minorvariationsofthesamesyntacticformmaybetreatedassimilar[ 59,92,104].Forinstance,Kamiyaetal.[ 59]remove
keywordssuchas staticfromCdeclarations.
3.3. Matchdetection
Thetransformedcodeisthenfedintoacomparisonalgorithmwheretransformedcomparisonunitsarecomparedto
eachothertofindmatches.Oftenadjacentsimilarcomparisonunitsarejoinedtoformlargerunits.Fortechniques/toolsof
fixedgranularity(thosewithapredeterminedcloneunit,suchasafunctionorblock),allthecomparisonunitsthatbelongto
thetargetgranularitycloneunitareaggregated.Forfreegranularitytechniques/tools(thosewithnopredeterminedtarget
cloneunit)aggregationiscontinuedaslongasthesimilarityoftheaggregatedsequenceofcomparisonunitsisaboveagiven
threshold,yieldingthelongestpossiblesimilarsequences.
Theoutputofmatchdetectionisalistofmatchesinthetransformedcodewhichisrepresentedoraggregatedtoform
asetofcandidateclonepairs.Eachclonepairisnormallyrepresentedasthesourcecoordinatesofeachofthematched
fragmentsinthetransformedcode.
Inadditiontosimplenormalizedtextcomparison,popularmatchingalgorithmsusedinclonedetectionincludesuffix-
trees[68,88,6,59],dynamicpatternmatching(DPM)[ 41,66]andhash-valuecomparison[ 15,87].
3.4. Formatting
Inthisphase,theclonepairlistforthetransformedcodeobtainedbythecomparisonalgorithmisconvertedtoa
correspondingclonepairlistfortheoriginalcodebase.Sourcecoordinatesofeachclonepairobtainedinthecomparison
phasearemappedtotheirpositionsintheoriginalsourcefiles.
3.5. Post-processing/Filtering
Inthisphase,clonesarerankedorfilteredusingmanualanalysisorautomatedheuristics.
Manual analysis: Afterextractingtheoriginalsourcecode,clonesaresubjectedtoamanualanalysiswherefalsepositive
clonesorspuriousclones[ 72]arefilteredoutbyahumanexpert.Visualizationoftheclonedsourcecodeinasuitableformat
(e.g.,asanHTMLwebpage[ 104])canhelpspeedupthismanualfilteringstep.
Automated heuristics: Oftenheuristicscanbedefinedbasedonlength,diversity,frequency,orothercharacteristicsof
clonesinordertorankorfilteroutclonecandidatesautomatically[ 59,58].
3.6. Aggregation
Whilesometoolsdirectlyidentifycloneclasses,mostreturnonlyclonepairsastheresult.Inordertoreducetheamount
ofdata,performsubsequentanalysesorgatheroverviewstatistics,clonesmaybeaggregatedintocloneclasses.
4. Overview of clone detection techniques and tools
Manyclonedetectionapproacheshavebeenproposedintheliterature.Basedonthelevelofanalysisappliedtothe
sourcecode,thetechniquescanroughlybeclassifiedintofourmain categories: textual,lexical,syntactic, andsemantic.In
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 475
thissectionwesummarizethestate-of-the-artinautomatedclonedetectionbyintroducingandclusteringavailableclone
detectiontoolsandtechniquesbycategory.
Thetechniquescanbedistinguishedprimarilybythetypeofinformationtheiranalysisisbasedonandthekindsof
analysistechniquesthattheyuse. Table1providesahigh-leveloverviewofthetechniquesandtoolsintheformofa
taxonomywherethefirstcolumnshowstheunderlyingapproachofthetools/techniques,thesecondcolumnshowstheir
onesentencedescription,thethirdcolumneithershowsthenameofthecorrespondingtoolor(ifnotoolnameisfound)
thelastnameofthefirstauthorhasbeenusedasthetoolname,andthefourthcolumnshowsthecorrespondingcitation(s).
4.1. Textualapproaches
Textualapproaches(or text-basedtechniques )uselittleornotransformation/normalizationonthesourcecodebefore
theactualcomparison,andinmostcasesrawsourcecodeisuseddirectlyintheclonedetectionprocess.Johnsonpioneered
text-basedclonedetection.Hisapproach[ 53,54]uses``fingerprints''onsubstringsofthesourcecode.First,codefragments
ofafixednumberoflines(thewindow)arehashed.Aslidingwindowtechniqueincombinationwithanincrementalhash
functionisusedtoidentifysequencesoflineshavingthesamehashvalueasclones.Tofindclonesofdifferentlengths,
theslidingwindowtechniqueisappliedrepeatedlywithvariouslengths.Manber[ 85]alsousesfingerprints,basedon
subsequencesmarkedbyleadingkeywords,toidentifysimilarfiles.
Oneofthenewertext-basedclonedetectionapproachesisthatofDucasseetal.[ 41,96].Thetechniqueisbasedondot
plots.Adotplotalsoknownasascatterplotisatwo-dimensionalchartwherebothaxeslistsourceentities.Inthecaseof
theapproachbyDucasseetal.,comparisonentitiesarethelinesofaprogram.Thereisadotatcoordinate .x;y/ifxandyare
equal.Twolinesmusthavethesamehashvaluetobeconsideredequal.Dotplotscanbeusedtovisualizecloneinformation,
whereclonescanbeidentifiedasdiagonalsindotplots.Thedetectionofclonesindotplotscanbeautomated,andDucasse
etal.usestring-baseddynamicpatternmatchingondotplotstocomparewholelinesthathavebeennormalizedtoignore
whitespaceandcomments.Diagonalswithgapsindicatepossible Type-3clones,andapatternmatcherisrunoverthematrix
tofinddiagonalswithholesuptoacertainsize.
AnextensionoftheDucasseetal.approachisusedbyWettel&Marinescu[ 114]tofindnear-missclonesusingdotplots.
Startingwithlineshavingthesamehashvalue,thealgorithmchainstogetherneighboringlinestoidentifycertainkindsof
Type-3clones.SDD[78]isanothersimilarapproachthatappliesann-neighborapproachinfindingnear-missclones.
NICAD[104,99]isalsotext-based,butexploitsthebenefitsoftree-basedstructuralanalysisbasedonlightweight
parsingtoimplementflexiblepretty-printing,codenormalization,sourcetransformationandcodefiltering.(ThusNICADis
essentiallyahybridtechnique.)
MarcusandMaletic[ 86]applylatentsemanticindexing(LSI)tosourcetextinordertofindhighlevelconceptclones,such
asabstractdatatypes(ADTs),inthesourcecode.Thisinformationretrievalapproachlimitsitscomparisontocomments
andidentifiers,returningtwocodefragmentsaspotentialclonesoraclusterofpotentialcloneswhenthereisahighlevel
ofsimilaritybetweentheirsetsofidentifiersandcomments.
4.2. Lexicalapproaches
Lexical approaches (or token-based techniques ) begin by transforming the source code into a sequence of lexical
``tokens''usingcompiler-stylelexicalanalysis.Thesequenceisthenscannedforduplicatedsubsequencesoftokensandthe
correspondingoriginalcodeisreturnedasclones.Lexicalapproachesaregenerallymorerobustoverminorcodechanges
suchasformatting,spacing,andrenamingthantextualtechniques.
Efficienttoken-basedclonedetectionwaspioneeredbyBrendaBaker.InBaker'stool Dup[8,6],linesofsourcefilesare
firstdividedintotokensbyalexicalanalyzer.Tokensaresplitintoparametertokens(identifiersandliterals)andnon-
parametertokens,withthenon-parametertokensofalinesummarizedusingahashing functor,andtheparametertokens
areencodedusingapositionindexfortheiroccurrenceintheline.Thisencodingabstractsawayfromconcretenamesand
valuesofparameters,butnotfromtheirorder,allowingforconsistentlyparameter-substituted Type-2clonestobefound.
Allprefixesoftheresultingsequenceofsymbolsarethenrepresentedbyasuffixtree,atreewheresuffixessharethesame
setofedgesiftheyhaveacommonprefix.Iftwosuffixeshaveacommonprefix,obviouslytheprefixoccursmorethanonce
andcanbeconsideredaclone.
Thetechniqueallowsonetodetect Type-1andType-2clones,andType-3clonescanbefoundbyconcatenating Type-1or
Type-2clonesiftheyarelexicallynotfartherthanauser-definedthresholdawayfromeachother.Thesecanbesummarized
usingadynamic-programmingtechnique[ 9].Kamiyaetal.laterextendedthistechniquein CCFinder[59],usingadditional
sourcenormalizationstoremovesuperficialdifferencessuchaschangesinstatementbracketing(e.g., if(a) b=2;vs.
if(a) {b=2;} ).CCFinderisitselfusedasthebasisofothertechniques,suchas Gemini[112],whichvisualizesnear-miss
clonesusingscatterplots,and RTF[12],whichusesamorememory-efficientsuffix-arrayinplaceofsuffixtreesandallows
theusertotailortokenizationforbetterclonedetection.
CP-Miner[84]isanotherstate-of-the-arttoken-basedtechnique,whichusesfrequentsubsequencedataminingtofind
similarsequencesoftokenizedstatements.Atoken-andline-basedtechniquehasalsobeenusedbyCordyetal.[ 28,110]
todetectnear-missclonesinHTMLwebpages.Anislandgrammarisusedtoidentifyandextractallstructuralfragments
476 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Table 1
Taxonomyofclonedetectiontechniquesandtools.
Onesentencedescription Tool/1stauthor ReferencesText-basedHashingofstringsperline,thentextualcomparison Johnson [ 54,53,55]
Hashingofstringsperline,thenvisualcomparisonusingdotplots Duploc [ 41]
Findssimilarfileswithapproximatefingerprints sif [ 85]
Composessmallerisolatedfragmentsofduplicationusingascatterplot DuDe [ 114]
Datastructureofaninvertedindexandanindexwithn-neighbordistanceconcept SDD [ 78]
Latentsemanticindexingforidentifiersandcomments Marcus [ 86]
Syntacticpretty-printing,thentextualcomparisonwiththresholds BasicNICAD [ 99]
Syntactic pretty-printing with flexible code normalization and filtering, then textual
comparisonwiththresholdsFullNICAD [ 104]
Transformationtoamiddleformatofatomicinstructionsandeditdistancealgorithm Nasehi [ 92]
Textualcomparisonwithflexibleoptions(e.g.,ignoreallidentifiers) Simian [ 107]Token-basedSuffixtreesfortokensperline Dup [ 8,7,6]
Tokennormalizations,thensuffix-tree-basedsearch CCFinder(X) [ 59,58]
Distributedimplementationof CCFinderforverylargesystems D-CCFinder [83]
UsesCCFinder'snon-gappedclonestofindgappedclonesininteractiveandvisualwayusing
agap-and-clonescatterplotGeX/Gemini [ 112,58]
Flexibletokenizationandsuffix-arraycomparison RTF [ 12]
Dataminingforfrequenttokensequences CP-Miner [ 84]
Real-timetokencomparisoninIDEswithsuffix-array SHINOBI [ 115]
KarpRabinstringmatchingalgorithmwithfrequencytableoftokens CPD [ 29]
NormalizedtokencomparisonintegratedwithVisualStudio CloneDetective [ 37]
Normalizedtokencomparisonwithsuffix-tree clones [ 14,72]
clonesisadaptedtodetectclonesovermultipleversionsatatime iClones [ 48]Tree-basedHashingofsyntaxtreesandtreecomparison CloneDr [ 15]
Derivationofsyntaxpatternsandpatternmatching Asta [ 42]
Hashingofsyntaxtreesandtreecomparison cdiff [ 116]
Serializationofsyntaxtreesandsuffix-treedetection cpdetector [ 72,43]
Metricsforsyntaxtreesandmetricvectorcomparisonwithhashing Deckard [ 52]
Suffix-treecomparisonofAST-nodes Tairas [ 111]
XMLrepresentationofASTswithfrequentitemsetstechniquesofdatamining CloneDetection [ 113]
XMLrepresentationofASTsandanti-unification/codeabstraction CloneDigger [ 20]
TokensequenceofCodeDOMgraphswithlevenshteindistance C2D2 [ 74]
Token-sequenceofAST-nodesandlosslessdatacompressionalgorithm Juillerat [ 57]
SubtreecomparisonobtainedfromANTLR SimScan [ 108]
Likecpdetectorbutworksonthenodesofparse-trees clast [ 14]
LikeCloneDrwithadifferentintermediaterepresentation[ 71]ofASTs ccdiml [ 16,14]
ASTtoFAMIXandthentreematching Coogle [ 109]Metrics-
basedClusteringfeaturevectorofprocedureswithneuralnet Davey [ 31]
Comparingmetricsforfunctions/begin-endblocks [ 66,87,93,67,30,89,90,1,2]
Comparingmetricsforwebsites [ 23,38]Graph-
basedApproximativesearchforsimilarsubgraphsinPDGs Duplix[ 75],GPLAG[81]
SearchingsimilarsubgraphsinPDGswithslicing Komondoor [ 65]
MappingPDGsubgraphstostructuredsyntaxandreuse Deckard Gabel [ 46]
ofcloninginterest,usingpretty-printingtoeliminateformattingandisolatedifferencesbetweenclonestoasfewlinesas
possible.Extractedfragmentsarethencomparedtoeachotherline-by-lineusingtheUnix diffalgorithmtoassesssimilarity.
Becausesyntaxisnottakenintoaccount,clonesfoundbytoken-basedtechniquesmayoverlapdifferentsyntacticunits.
However,usingeitherpre-processing[ 28,47,104]orpost-processing[ 50],clonescorrespondingtosyntacticblockscanbe
foundifblockdelimitersareknownorlightweightsyntacticanalysissuchasislandparsing[ 91]isadded.
4.3. Syntacticapproaches
Syntacticapproachesuseaparsertoconvertsourceprogramsintoparsetreesorabstractsyntaxtrees(ASTs)whichcan
thenbeprocessedusingeithertreematchingorstructuralmetricstofindclones.
Tree matching approaches: Treematchingapproaches(or tree-basedtechniques )findclonesbyfindingsimilarsubtrees.
Variablenames,literalvaluesandotherleaves(tokens)inthesourcemaybeabstractedinthetreerepresentation,allowing
formoresophisticateddetectionofclones.OneofthepioneeringtreematchingclonedetectiontechniquesisBaxteretal.'s
CloneDr[15].Acompilergeneratorisusedtogenerateaconstructorforannotatedparsetrees.Subtreesarethenhashed
intobuckets.Onlywithinthesamebucket,subtreesarecomparedtoeachotherbyatoleranttreematching.Thehashingis
optionalbutreducesthenumberofnecessarytreecomparisonsdrastically.
ThisapproachhasbeenadaptedbytheAST-basedclonedetectorsofBauhaus[ 14]asccdiml.Themaindifferencesfrom
CloneDrareccdiml'sexplicitmodelingofsequences,whicheasesthesearchforgroupsofsubtreesthattogetherformclones,
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 477
anditsexactmatchingoftrees.Yang[ 116]hasproposedadynamicprogrammingapproachforhandlingsyntacticdifferences
incomparingsimilarsubtrees.( cdiffisnotaclonedetectiontoolinitselfbuttheunderlyingtechniquecouldbeusedinclone
detection.)Wahleretal.[ 113]findexactandparameterizedclonesatamoreabstractlevelbyconvertingtheASTtoXML
andusingadataminingtechniquetofindclones.Structuralabstraction,whichallowsforvariationinarbitrarysubtrees
ratherthanjustleaves(tokens),hasbeenproposedbyEvansetal.[ 42]forhandlingexactandnear-misscloneswithgaps.
Toavoidthecomplexityoffullsubtreecomparison,recentapproachesusealternativetreerepresentations.Inthe
approachofKoschkeetal.[ 72,43],ASTsubtreesareserializedasASTnodesequencesforwhichasuffixtreeisthen
constructed.Thisideaallowstofindsyntacticclonesatthespeedoftoken-basedtechniques.Afunction-levelclonedetection
approachbasedonsuffixtreeshasbeenproposedbyTairasandGraybasedonMicrosoft'snewPhoenixframework[ 111].
AnovelapproachfordetectingsimilartreeshasbeenpresentedbyJiangetal.[ 52]intheirtoolDeckard.Intheirapproach,
certaincharacteristicvectorsarecomputedtoapproximatethestructureofASTsinaEuclideanspace.Localitysensitive
hashing(LSH)isthenusedtoclustersimilarvectorsusingtheEuclideandistancemetric(andthuscanalsobeclassifiedas
ametrics-basedtechniques)andthusfindscorrespondingclones.
Metrics-based approaches: Metrics-basedtechniquesgatheranumberofmetricsforcodefragmentsandthencompare
metricsvectorsratherthancodeorASTsdirectly.Onepopulartechniqueinvolves fingerprintingfunctions ,metricscalculated
forsyntacticunitssuchasaclass,function,methodandstatementthatyieldvaluesthatcanbecomparedtofindclonesof
theseunits.Inmostcases,thesourcecodeisfirstparsedtoanASTorcontrolflowgraph(CFG)onwhichthemetricsarethen
calculated.Mayrandetal.[ 87]useseveralmetricstoidentifyfunctionswithsimilarmetricsvaluesascodeclones.Metrics
arecalculatedfromnames,layout,expressions,and(simple)controlflowoffunctions.Afunctioncloneisidentifiedasapair
ofwholefunctionbodieswithsimilarmetricsvalues.Patenaudeetal.useverysimilarmethod-levelmetricstoextendthe
BellCanadaDatrixtooltofindJavaclones[ 93].
Kontogiannisetal.[ 66]haveproposedtwodifferentwaysofdetectingclones.Oneapproachusesdirectcomparisonof
metricsvaluesasasurrogateforsimilarityatthegranularityof beginendblocks.Fivewell-knownmetricsthatcapture
dataandcontrolflowpropertiesareused.Thesecondapproachusesadynamicprogramming(DP)techniquetocompare
beginendblocksonastatement-by-statementbasisusingminimumeditdistance.Thehypothesisisthatpairswithasmall
editdistancearelikelytobeclonescausedbycut-and-pasteactivities.AsimilarapproachisappliedbyBalazinskaetal.[ 10]
intheirtoolSMC(similarmethodsclassifier),usingahybridapproachthatcombinescharacterizationmetricswithdynamic
matching.
Daveyetal.[31]detectexact,parameterized,andnear-missclonesbyfirstcomputingcertainfeaturesofcodeblocks
andthentrainingneuralnetworkstofindsimilarblocksbasedonthefeatures.Metrics-basedapproacheshavealsobeen
appliedtofindingduplicatewebpagesandclonesinwebdocuments[ 23,38].
4.4. Semanticapproaches
Semantics-awareapproacheshavealsobeenproposed,usingstaticprogramanalysistoprovidemorepreciseinformation
thansimplysyntacticsimilarity.
Insomeapproaches,theprogramisrepresentedasaprogramdependencygraph(PDG).Thenodesofthisgraphrepresent
expressionsandstatements,whiletheedgesrepresentcontrolanddatadependencies.Thisrepresentationabstractsfrom
thelexicalorderinwhichexpressionsandstatementsoccurtotheextentthattheyaresemanticallyindependent.The
searchforclonesisthenturnedintotheproblemoffindingisomporphicsubgraphs(forwhichonlyapproximateefficient
algorithmsexist)[ 65,75,81].OneoftheleadingPDG-basedclonedetectiontoolsisproposedbyKomondoorandHorwitz
[65],whichfindsisomorphicPDGsubgraphsusing(backward)programslicing.Krinke[ 75]usesaniterativeapproach(k-
lengthpatchmatching)fordetectingmaximallysimilarsubgraphsinthePDG.Liuetal.[ 81]havedevelopedaplagiarism
detectorbasedonPDGs.AnotherrecentstudybyGabeletal.[ 46]mapsPDGsubgraphstorelatedstructuredsyntaxand
thenfindsclonesusing Deckard.
4.5. Hybrids
Inadditiontotheabove,therearealsoclonedetectiontechniquesthatuseacombinationofsyntacticandsemantic
characteristics.Leitao[ 79]providesahybridapproachthatcombinessyntactictechniquesbasedonASTmetricsand
semantictechniques(usingcallgraphs)incombinationwithspecializedcomparisonfunctions.
5. Comparison of tools
Clonedetectiontoolsaremultivariate,andthereforetheirstudyrequiresasystematicschemefordescribingtheir
properties.Inthiscomparison,wewilldescribethepropertiesofclonedetectiontoolsaccordingtosuchasystematic
classification.Ourclassificationschemeisoutlinedfirst,andthenweclassifyandcomparethetechniquesandtoolsusingit.
Thepropertiesareorganizedinto facets,eachofwhichmayhavedifferent,butnotnecessarilydisjoint attributevalues.
Relatedfacetsaregroupedinto categories.Wefirstintroducethecategories,facets,andattributesandthenclassifythetools
andtechniquesinthisscheme.
478 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Table 2
Usagefacets.
Abb.Facet Attr. Description
P PlatformP.a ThetoolisplatformindependentT[ 78],L[29],S[20]
P.b ThetoolhasbeenrunonLinux/UnixT[ 104,99],L[8],S[52],M[93]
P.c ThetoolhasbeenrunonWindowsL[ 12,76,37,115],LS[74],S[111,113],G[65,81,46]
P.d ThetoolhasbeenrunonbothWindowsandLinux/UnixT[ 107],L[59,112],S[14,72,15,108]
P.e Others/InformationnotavailableT[ 55,41,86,85,114,92],L[84],S[42,116,57],M[66,87,31,67],G[75]
D ExternalDependenciesD.a PossiblythetoolhasnoexternaldependenciesT[ 99,41,107,104,55,85,114,78],L[59,12,112,58,8,115],S[52,116]
D.b ThetoolseemstohaveexternaldependenciesortobeapartofalargertoolsetT[ 86](PROCSSI),T[92](recoder),
L[29](PMD),L[84](CloSpan),L[37](ConQAT),S[15](DMS[13]),S[14](Bauhaus),[20](CPython,ANTLR),S[ 111]
(MicrosoftPhoenixFramework),LS[ 74](CodeDOMof.Net),S[ 113](JAML),LS[72](Bauhaus),S[42](JavaMLand
lcsc),S[108](ANTLR),M[87,93](Datrix),G[75](VALSOFT),G[65,81,46](CodeSurfer),G[ 75](KrinkeandSnelting
validationframework)
D.c Others/InformationnotavailableS[ 57],M[66,31,67]
A AvailabilityA.a ThetoolisopensourceT[ 78],L[29,37],S[20]
A.b ThetoolisfreelyavailableforresearchinbinaryformT[ 41,107],L[59,112,58,37],S[108]
A.c ThetooliscommerciallyavailableS[ 15]
A.d ThereisafreeevaluationlicenseS[ 15,14]
A.e ProbablyevaluationversionisavailableonrequestT[ 104,99,114],L[8,12,84],S[72,52],G[65,81,46,75]
A.f Others/Informationnotavailable/PossiblynotavailableT[ 55,85,86,92],L[115],S[42,116,111,113,74,57],M[66,66,
31,93,67]
Table 3
Interactionfacets.
Abb. Facet Attr. Description
U UserInterfaceU.a MaybeusedascommandlinetoolT[ 104,114,107],L[59],S[20]
U.b ProvidesagraphicaluserinterfaceT[ 78,92],L[115](CloneListandFileInfoViews),L[ 112,37],S[42],M[31]
U.c Bothcommandlinetoolandgraphicaluserinterface(U.a)&(U.b)L[ 58,59,29,14],S[15,72,108]
U.d Notpreciselymentioned: SeeTable12fortheremaininglist
O NatureofOutputO.a Emitsresultstextuallyprovidingonlythesourcecoordinatesoftheclonedfragments(e.g.,filenameandbeginend
linenumbersoftheclonedfragments)T[ 85,86,107],L[12],S[52,72],M[24,66,67]
O.b Emitsresultsgraphicallyprovidingtheoriginalsourceoftheclonedfragmentsinasuitableformat(e.g.,HTML)or
providesoverallabstractedvisualrepresentation(e.g.,dot-plot).T[ 25,78,92],L[28,112,115,37],S[116,42,20,47,111],
M[23]
O.c Bothtextualsourcecoordinatesoftheclonedfragmentsandoriginalsourceinsuitableformatorabstractedvisual
representation(bothO.aandO.b)T[ 41,104,99,114,54,55],L[58,59,8,29,14],S[15,20,108,14,16]
O.d Notpreciselymentioned: SeeTable12fortheremaininglist
I IDESupportI.a IsaPlug-inforEclipseT[ 78,39,108,51],S[20]
I.b Integrated/DependentinotherIDES[ 111](MSPhoenixframework),L[ 115,76](VisualStudio2005),[ 108](several
IDEs)
I.c Others: Allothertools(Table12)exceptlistedherepossiblyhavenoIDEsupport
Inordertoprovideacomparisonofbothgeneraltechniquesandindividualtools,wegathercitationsofthesamecategory
togetherusingacategoryannotation, Tfortext-based,Lforlexical(token-based), Sforsyntactic(tree-based), Mformetrics-
basedandGforgraph(PDG)-based,withcombinationsforhybrids.Whilethecitationsforthedifferentfacetsandattributes
inTables211maynotbecomplete,weprovidethevaluesforallfacetsandattributesoftheindividualtoolsandtechniques
inTable12.
5.1. Usagefacets
ThecategoryUsagegroupsfacetsrelevanttotheusageofatechniqueortool. Table2liststheusagefacets.Thesecond
columninthetablegivesthefullnameofthefacet,andthefirstcolumngivesthemnemonicabbreviationweusetoreferto
it.Uniqueidentifiersforthefacet'sattributevaluesarefoundinthethirdcolumn.Thelastcolumngivesshortdescriptions
oftheattributevaluesalongwiththecitationsofthecorrespondingtechniquesandtools.
Platform:ThefacetPlatformdescribestheexecutionplatformforwhichthetoolisavailable.
External Dependencies: TheExternalDependencies facetstateswhetherthetoolrequiresaspecialenvironmentor
additionalothertoolstowork.
Availability:TheAvailabilityfacetdescribesthekindoflicenseunderwhichthetoolismadeavailable.
5.2. Interactionfacets
Theinteractioncategorydealswithhowauserinteractswiththeclonedetectiontool(cf. Table3),animportant
considerationwhenadoptingatool.
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 479
Table 4
Languagefacets.
Abb. Facet Attr. Description
LP LanguageParadigmLP.a AppliedtoonlyprocedurallanguagesT[ 55,54,85,86,104],S[116,47,111],M[24,31,66,67,87],G[65,75]
LP.b Appliedtoonlyobject-orientedlanguagesT[ 92],L[37],S[42,20,113,74,57,108],M[93,10],
LP.c Appliedtobothproceduralandobject-orientedlanguagesT[ 41,78,99,114,107],L[8,59,12,58,112,84,115,29],S[15,
52,14,43],G[81,46]
LP.d AppliedtoweblanguagesT[ 107],[38,36,35,95,28,23,94,77,62,49]
LP.e Appliedtoonlyfunctionallanguages[ 80]
LP.f AppliedtomodelinglanguagesL[ 82](SequenceDiagram),G[ 33](Simulink)
LP.g AppliedtoLisp-likelanguagesSMG[ 79](hybrid)
LP.h Appliedtoassemblercode[ 26,34,32,45]
LP.i AppliedtoJavaByteCode[ 5]
LP.j ApplicableacrossdifferentlanguagesLS[ 74](currentlyC#andVisualBasic.NET)
LS LanguageSupportLS.a IslanguageindependentT[ 78],T[107](hasseveralotherlanguage-specificlexicaloptionstoo)L[ 37](hasseveral
otherlanguage-specificlexicaloptionstoo)
LS.b Experimentedwith``C''T[ 55,41,114,54,78,86,85,104,99],L[59,8,12,58,112,84,29],S[15,116,47,52,72,14,111],M[87,
66,24,31,67],G[65,75,81,46]
LS.c Experimentedwith``C CC''T[41],L[59,58,112,84,115,29],S[14,15,113],G[81,46]
LS.d Experimentedwith``C#''T[ 97]L[115,37],L[59,58,112],S[42],LS[74]
LS.e Experimentedwith``Java''T[ 41,114,78,99,92],L[59,8,12,29],S[15,42,52,14,20,43,113,57,108],M[93,10],G[81]
LS.f Experimentedwith``COBOL''T[ 41],L[59,58,112],S[14,15]
LS.g Experimentedwith``Python''S[ 20]
LS.h Experimentedwith``HTML''L[ 28,110]
LS.i Experimentedwith``VisualBasic''L[ 59,58,112,115],S[74]
User Interface: Thisfacetdescribeswhetherthetoolsupportsinteractivityorwhetheritisusedinbatchmode.
Output:TheOutputfacetindicatesthekindofoutputsupportedbytheparticulartool.Sometoolsprovidecloning
informationtextuallywithfilenameandbeginendlinenumbersoftheclonedfragments,someprovidetheoriginalsource
oftheclonedfragmentsinasuitableformat,someshowtheabstractedviewoftheclonedcode(e.g.,scatterplotview)and
someprovideacombinationofthese.
IDE Support:ThePlug-inSupportfacetindicateswhetherthetoolispartofanintegrateddevelopmentenvironment
(IDE).OnlyafewtoolsprovidedirectIDEsupport.
5.3. Languagefacets
Thelanguagecategorydealswiththeprogramminglanguagesthatcanbeanalyzedusingthetool. Table4summarizes
thesefacetsandtheirattributevalues.
Language Paradigm: TheLanguageParadigm facetindicatestheprogrammingparadigmtargetedbythetool.
Language Support: FacetLanguageSupport refinesLanguageParadigm tothesetofparticularlanguages.
5.4. Cloneinformationfacets
Thecloneinformationcategorygathersfacetsthatcharacterizethekindsofcloneinformationthetoolisabletoemit(cf.
Table5).Thericherthisinformationandmorerefineditsstructure,themoreusefulitisforfurtherprocessing.
Clone Relation: TheCloneRelationfacetconcernshowclonesarereportedasclonepairs,cloneclasses,orboth.Clone
classescanbemoreusefulthanclonepairs,forexamplereducingthenumberofcasestobeinvestigatedforrefactoring.
Techniquesthatprovidecloneclassesdirectly(e.g., RTF[12])maythereforebebetterformaintenancethanthosethatreturn
onlyclonepairs(e.g., Dup[8])orrequirepost-processingtogroupclonesintoclasses(e.g., CCFinder[59]).
Clone Granularity: ThefacetCloneGranularity indicatesthegranularityofthereturnedclones free(i.e.,nosyntactic
boundaries),fixed(i.e.,withinpredefinedsyntacticboundariessuchasmethodorblock)orboth.Bothgranularitieshave
advantagesanddisadvantages.Forexample,techniquesthatreturnonlyfunctionclonesareusefulforarchitectural
refactoring,butmaymissopportunitiestointroducenewmethodsforcommonstatementsequences.Atoolthathandles
multiplegranularitiesmaybemoreusefulforgeneralreengineering.
Clone Type:TheCloneTypefacetconsidersthetypesofclonesthatatechniquecandetect.Whilealltechniquescan
detectexactclones,onlyfewtools(e.g., Dup[8])canfindparameterized Type-2clones.Thisissueisdiscussedindetailin
thecontextofedit-basedscenarioslaterinthepaper.
5.5. Technicalaspectfacets
Thetechnicalaspectfacetscategoryrelatestothecomparisonalgorithms,theircomplexity,andtheirunitofcomparison
(cf.Table6).
480 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Table 5
Clonefacets.
Abb. Facet Attr. Description
R CloneRelationR.a YieldsclonepairsT[ 41,114,78,92],L[8,59,58,29],S[15,72,14,20,42,111,74,108],M[87,23,24,66,93,67],G[65,75,81]
R.b YieldscloneclassesT[ 104,99,55,54,85,86,107]L[12,28,115,84,37],S[52,113],M[10,31],G[81,33,46]
R.c Yieldsbothclonepairsandcloneclassesdirectlybythecomparisonalgorithm(note: Nonecandirectlyfindbothclone
pairsandcloneclasses. )
R.d Groupsclonepairsinclassesinpost-processingT[ 41],L[59,58],S[15,111,108,14],M[10],G[65]
R.e OthersS[ 116,57]
G CloneGranularityG.a FreeT[41,54,55,114,78,86,107],L[59,58,8,12,115,29,37],S[15,42,47,52,72,14,20,113,108],G[75,65]
G.b Fixed,Function/MethodT[ 99,104],S[111,74],M[87,10,31,23,24,66,67],G[65,81,46]
G.c Fixed,begin-endblockT[ 99,104],L[28],M[66]
G.d Fixed,anystructuredblockT[ 99,104],L[28]
G.e. Fixed,ClassS[ 109]
G.f Fixed,FileT[ 85],S[116]
G.g OthersL[ 84](BasicBlock),S[ 57](sub-statement)
CT CloneTypesCT.aType-1orsubsetofType-1:Allthetools/techniqueslistedin Table12candetectsuchclones(orasubset)withsome
limitations.
CT.bType-2orsubsetofType-2:Exceptsometext-basedtechniques/tools[ 55,41,114,78]andonetree-based[ 57],allothersare
abletodetectsuchclones(orasubset)withsomelimitations.
CT.cType-3(near-miss)orsubsetof Type-3.Sometechniques/toolsmighthavesomelimitationsT[ 41,114,78,85,104,99,55,
86],L[84,112],S[15,52,42,47,14,20,108],M[87,10,66,92,23,24],G[65,75,81,46]
CT.dType-4orsubsetofType-4.Sometechniques/toolsmighthavesomelimitationsT[ 86],G[65,75,81,46]
CT.e OthersT[ 86](ADT),T[25](Visualizationonly),S[ 116](Visualizationonly)
Comparison Algorithm: TheComparisonAlgorithm facetidentifiesthedifferentalgorithmsusedinclonedetection.For
example,thesuffix-treealgorithmfindsallequalsubsequencesinasequencecomposedofafixedalphabet(e.g.,characters,
tokens,hashvaluesoflines)inlineartimeandspace,butcanhandleonlyexactsequences.Ontheotherhand,datamining
algorithmsarewellsuitedtohandlearbitrarygapsinthesubsequences.
Comparison Granularity: Differenttechniquesworkatdifferentlevelsofcomparisongranularity,fromsingletokens
andsourcelinestoentireASTsubtreesandPDGsubgraphs.Thefacet ComparisonGranularity referstothegranularityofthe
techniqueinthecomparisonphase.Thechoiceofgranularityiscrucialtothecomplexityofthealgorithmandthereturned
clonetypesanddeterminesalsothekindsoftransformationandcomparisonrequired.Forexample,atoken-basedtechnique
maybemoreexpensiveintermsoftimeandspacecomplexitythanaline-basedonebecauseasourcelinegenerallycontains
severaltokens.Ontheotherhand,atokenrepresentationiswellsuitedtonormalizationandtransformation,sominor
differencesincodingstyleareeffectivelyremoved,yieldingmoreclones.Similarly,althoughsubgraphcomparisoncanbe
verycostly,PDG-basedtechniquesaregoodatfindingmoresemantics-awareclones.
Worst case Computational Complexity: Theoverallcomputationalcomplexityofaclonedetectiontechniqueisamajor
concern,sinceapracticaltechniqueshouldscaleuptodetectclonesinlargesoftwaresystemswithmillionsoflinesofcode.
Thecomplexityofanapproachdependsonthekindsoftransformations,thecomparisonalgorithmused,andthegranularity
ofitsuse.Thefacet ComputationalComplexity indicatestheoverallcomputationalcomplexityofaparticulartechnique/tool.
5.6. Adjustmentfacets
Theadjustmentscategoryrelatestowaysthetoolallowsausertomakeadjustmentstothesearch.Adjustmentsare
offeredbywayofheuristicsthatmaybeturnedonandoff,thresholdsthatmaybeset,andvariouskindsofpre-andpost-
processing(cf.Table7).
Pre-/Post-Processing: ThefacetPre-/Post-Processing referstoanyspecialpre-orpost-processing(e.g.,prettyprinting)
asoutlinedinSections 3.1and3.5thatarerequiredotherthantheusualfilteringofwhitespaceandcommentswithlight-
weightparsingorregularexpressions[ 41,114].
Heuristics/Thresholds: TheHeuristics/Thresholds facetindicateswhetherthereareanythresholdsorheuristicsusedby
aparticulartechnique/toolthatmaybemanipulatedbyauser.
5.7. Processingfacets
Theprocessingcategoryincludesfacetsthatcharacterizethewaysatoolanalyzes,represents,andtransformsthe
programforthecomparison.
Basic Transformation/Normalization: Noise(e.g.,comments)filtering,normalizationandtransformationofprogram
elementsareimportantstepsinclonedetectiontools,helpingbothinremovinguninterestingclones(filtering),andin
findingnear-missclones(normalizationandtransformation).The BasicTransformation/Normalization facetdealswiththis
issue(cf.Table8).
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 481
Table 6
Technicalfacets.
Abb. Facet Attr. Description
CA ComparisonAlgorithmsCA.a SuffixtreeL[ 59,8,37],S[20,72,111],G[82]
CA.b SuffixarrayL[ 115,12]
CA.c AST-basedSuffixtreeS[ 72,111]
CA.d dotplot/scatterplotT[ 114,25],L[112]
CA.e DynamicpatternmatchingT[ 41],M[10,24,66]
CA.f DataMiningL[ 84](FrequentSubSequence),S[ 113](FrequentItemset)
CA.g Informationretrieval[ 86](LatentSemanticIndexing)
CA.h Hash-valuecomparisonS[ 15,52,14]
CA.i FingerprintingT[ 55,85,54]
CA.j NeuralNetworksM[ 31]
CA.k GraphmatchingG[ 75,81],G[65](slicing),G[33](model)
CA.l Sub-treematchingS[ 15](hashing),S[14]
CA.m EuclideandistanceM[ 67,38]
CA.n LevenshteindistanceLS[ 74]
CA.o OthersequencematchingT[ 78](n-neighbor),T[ 104](similartoUnix diff),T[92](Editdistance),L[ 28](diff),
S[116,47](dynamicprogramming),
CA.p HybridSMG[ 79]
CA.q OthersT[ 107],L[29](KarpRabinstringmatching),S[ 57](losslessdatacompression),S[ 42,108],M[87]
(discretecomparison),[ 93],G[46](Localitysensitivehashing)
CU ComparisonGranularityCU.a LineT[ 41,114,25,104,107],L[28],L[8](p-tokensofline)
CU.b Substring/fingerprintT[ 54,55,85](multi-line),T[ 78](multi-word)
CU.c IdentifiersandCommentsT[ 86]
CU.d TokensL[ 59,12,8,115,29,37,14],S[72,111](tokensofsuffixtrees),S[ 74](TokensofcodeDOMgraph),S[ 57]
(TokensofASTs)
CU.e StatementsL[ 84],S[113]
CU.f SubtreeS[ 15,14,116,42,52,14,20,108]
CU.g SubgraphG[ 65,75,81]
CU.h Begin-EndBlocksM[ 66]
CU.i MethodsS[ 111],M[87,10,23,93,24,66,67]
CU.j FilesT[ 85],S[116]
CU.k OthersT[ 92](Atomicinstructions)L[ 112](usesnon-gappedclones),
CCCC.a LinearT[ 78],L[59,8,12,115,37,14],S[72],[72,43]
Worstcase
ComputationalCC.b QuadraticT[ 41,104](wrt.nooflines/potentialclones),L[ 112](wrt.no.ofnon-gappedclones),S[ 15,14,52,
116,47,111,20,113],M[10,23,24,66,87,31,93,67],(wrt.no.ofmethods/begin-endblocks)
Complexity CC.c PolynomialG[ 75,65,81,33]
CC.d Others/NotpreciselydefinedT[ 55,85,114,86,92,107],L[84,29],S[42,74,57,108]
Table 7
Adjustmentfacets.
Abb. Facet Attr. Description
PPPP.a Pre-processingT[ 114,78],L[28,104,99,41,92],S[47,116]
Pre-/Post- PP.b Post-processingT[ 85],L[8,59,112,84,115],S[72,52],G[65,46]
Processing PP.c Others/PossiblynoneT[ 55,86,107],L[12,29,37,14],S[15,42,111,113,20,74,57,108,14],M[10,23,24,66,87,31,93,
67],G[75,81]
HH.a OnclonelengthT[ 41,114,14],T[78](4words),T[54,55](50lines),L[8](15lines),L[59,58,112,12,115,37](e.g.,30
tokens),LS[72]
Heuristics/H.b OncodesimilarityT[ 99,104,114,86,92],L[8,59,84,12,28,115],S[15,52,14,42,20,108],LS[74],M[10,23,24,66,87,
31,93,67],G[81,46]
Thresholds H.c OngapsizeT[ 41,78,114,99,104,85],L[84,112,29],S[52,42,47,113],M[10],G[75,46]
H.d OnpruningT[ 41,54,55,114],L[59,12]*,L[84],S[72],G[81,46]
H.e Others/PossiblynoneT[ 107],S[116,111,57],G[65]
Code Representation: TheCode Representation facet refers to the internal code representation after filtering,
normalizationandtransformation(cf. Table9).Thecomplexityofthedetectorimplementation,thebulkofwhichisthe
normalization,transformationandcomparison,dependsagreatdealonthecoderepresentation.Oneshouldnotethatwe
havealreadygenerallyclassifiedthetechniquesbasedonoveralllevelofanalysisinSection 4.Hereweattemptafiner-
grainedclassificationbasedontheactualrepresentationusedinthecomparisonphase.Forexample,althoughatree-based
technique,theactualcoderepresentationof cpdetector[72]isaserializedtoken-sequenceofAST-nodes,improvingthe
computationalandspacecomplexitiesofthetoolfromquadratictolinearusingasuffix-tree-basedalgorithm.
Program Analysis: ThefacetProgramAnalysis indicatesthekindofprogramanalysisrequiredforaparticulartechnique
inordertoproducetheintermediaterepresentation(cf. Table10).Whilemosttext-basedtechniquesworkdirectlyon
sourcecodeandtoken-basedtechniquesgenerallyrequireonlylexicalanalysis,othertechniques/toolscanbeverylanguage-
dependent(e.g.,requiringafullparser).
482 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Table 8
BasicTransformation/Normalizationfacet.
Attr. Description
T.a NonormalizationofsourcecodeT[ 78,86,85,114](whitespaceandsinglebrackets)M[ 23]
T.b Removecommentsandwhitespacewithregularexpressionsorlight-weightparsingT[ 41,54,114],L[8,12]
T.c Removecommentsandwhitespaceinparsingandapplysomekindofpretty-printing/text-processingtoremoveformatting
differencesbetweensimilarfragments.T[ 104,99]
T.d CommentsarenotremovedbutalsotakenintoconsiderationforcomparisonT[ 86,54]*,M[87]
T.e Applynormalizaitionofidentifiers,typesandliteralvaluesT[ 107],L[59,58,112,84,115,37]
T.f Identifiernames(andcomments)arekeptandcomparedforfindingclonesT[ 86]
T.g Thereisflexiblenormalizationoftheidentifiers(differentoptionsareprovidedtotheuser)T[ 104],L[12,29],S[52]
T.h SeverallanguagedependenttransformationrulesareappliedT[ 104](ExamplelikeTXLtransformationrules),T[ 92](Semantic
preservingtransformationrulestogetsequenceofatomicinstructions),L[ 59](Tokentransformationrules)
T.i CommentsandwhitespaceareignoredinparsingorwhilegeneratinggraphsT[ 104,99],S[15,52,116,42,47,14,72,111,113],M[10,
24,66,67,93],G[65,75,81,46]
Table 9
CodeRepresentationfacet.
Attr. Description
CR.a Rawsourcewithoutanychanges: Possiblynone
CR.b FilteredStrings:Effectivelinesofcodeafterremovingcommentsandwhitespace(possiblylinebreaksarenotremoved)T[ 41,114,
78,55,54],L[28]
CR.c Linebreaksarealsoremovedinfilteredstrings: Mosttoken-basedtoolsdothis
CR.d Filteredsubtringswithcomments,whitespaceandlinebreaksmayormaynotberemovedT[ 54,85](fingerprint),L[ 115]
CR.e Fingerprintingofsubstringswithcomments,whitespaceandlinebreaksmayormaynotberemovedT[ 107]
CR.f Normalizedstrings/Tokensequencewithcomments,whitespaceandlinebreaksmayormaynotberemovedT[ 41,40],L[59,58,
112,12,115,37,14](tokensequence)
CR.g Parameterizedstrings/Tokensequencewithcomments,whitespaceandlinebreaksmayormaynotberemovedL[ 8,6],(p-token
sequence),L[14]
CR.h WordsincontextT[ 86]
CR.i Metrics/VectorsS[ 52](characteristicvector),M[ 87](IRL),M[66,10,93,23,24,67,31],G[46]
CR.j AbstractSyntaxTree(AST)orAnnotatedASTorASTnodesareinanotherformS[ 15,116,108],S[14](IML),S[42](XML),S[47](string
alignment),S[72,111](suffix-trees)
CR.k PDGorvariantsofPDGG[ 65,81](PDG),G[75](PDG+AST)
CR.l AST/Parse-treeisinanotherformS[ 20,113](XML),LS[74](CodeDOM),S[ 57](TokensofAST-nodes),M[ 87](IRL)
CR.m Pretty-printedtextwithoutcommentsT[ 99],
CR.n Normalized/transformedTextT[ 104](alsopretty-printed),L[ 84](Mappingstatementstonumbers)
CR.o HybridSMG[ 79](AST+Metrics+callgraph)
CR.p OthersT[ 92](sequenceofatomicinstructions),L[ 29](Frequencytableoftokens)G[ 33](normalizedgraph*),
Table 10
ProgramAnalysisfacet.
Attr. Description
PA.a Nothing,completelylanguageindependentT[ 85],T[107](hasseveralotherlanguage-specificoptionstoo)
PA.b OnlyneedssomeregularexpressionsforremovingcommentsandwhitespaceorsoT[ 114]
PA.c Onlyneedslightweightparsingforremovingcomments,whitespaceandpretty-printing(orso)ofthecodeT[ 41,54,55,78,86],M
[23]
PA.d Needsalexeratleastforremovingcomments/whitespaceandtotokenizethesourceL[ 59,58,112,6,8,12,115,29,37,14],
PA.e Needsafull-fledgedparserorIDEtogenerateparsetree/ASTortofindanotherrepresentationofthesourceL[ 84],S[15,116,42,47,
72,14,20,111,113,74,57,108,16,14],M[87,10,24,66,67,31,93],
PA.f NeedsspecializedtooltogenerateCallGraphs,traditionalPDGsorannotatedspecialPDGsG[ 65,75,81],SMG[79](callgraph)
PA.g NeedslanguagedependenttransformationrulesalsoT[ 104](fullNICAD),T[ 92],L[59](lexical)
PA.h Needsonlyacontext-freegrammarforthelanguagedialectofinterestT[ 99](BasicNICAD)(inTXL),L[ 28](inTXL),S[52]
5.8. Evaluationfacets
Empirical validation of tools is important, especially in terms of precision, recall, and scalability. The evaluation
categorydealswithevaluationaspects(cf. Table11).Thesefacetscanassistinchoosingawell-validatedtool/technique,
incomparinganewtoolwithonethathasexistingempiricalresults,orinchoosingacommonlyusedsubjectsystemas
abenchmark.Theymayalsoencourageempiricalstudiesonpromisingtoolsandtechniquesthatareasyetinadequately
validated.
Empirical Validation: Thisfacethintsatthekindofvalidationthathasbeenreportedforeachtechnique.
Availability of Empirical Results: ThefacetAvailabilityofEmpiricalResults noteswhethertheresultsofthevalidationare
available.Iftheresultsareavailable,otherresearchersmaybeabletoreplicate,compareandextendthemwithadditional
studies.
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 483
Table 11
Evaluationfacet.
Abb. Facet Attr. Description
EE.a Yes,validatedempiricallyintermsofprecision,recall,memoryandtimeandcomparedwithothertoolsS[ 72,43]
E.b ValidatedenoughinsupportoftheclaimT[ 41,114,86,92,104],L[8,6,83,84],S[42,15,52],M[10,66,87,67],G[81,46]
Empirical
ValidationE.c ValidatedbyothermeansorthirdpartycomparisonstudyT[ 104,99](withanautomaticvalidationframework[ 98,
101]),T[41](withBellon'sexperiment[ 18]),L[6](withBellon'sexperiment[ 18]),L[59](withBellon'sexperiment
[18]),S[15](withBellon'sexperiment[ 18]),M[87](withBellon'sexperiment[ 18]),G[75](withBellon'sexperiment
[18]),
E.d Others(Possiblynotvalidatedexhaustively)T[ 78,54,55,85,107],L[12,28,115,29,37,14],S[116,111,113,74,57,108],M
[23,31,93],G[65,75]
ARAR.a Yes,completeresultsT[ 99,104](seeat[100]),S[20](seeat[21]),Experiment[18](seeat[17])
Availabilityof
ResultsAR.b Enough/Partialresultsasinthepublishedpaper(oronlinedocuments)T[ 54,41,85,114,78,86,25,92,107],L[8,59,83,
112,58,12,84,115,29,37,14,72,48],S[15,42,116,72,43,52,111,113,74,57,108,14,16,109],M[66,87,31,93,67],G[65,75,
46,81]
SS.a LinuxKernel/part(C,3MLOC)T[ 99],L[12,59,84,14,72],S[52],M[24],G[46]
S.b JDK/Part(Java,204KLOC)T[ 99,114,78,107],L[59,4,29,14,72],S[52,113,108],M[10,93],Experiments[18]
S.c SNNS(C,115KLOC)T[ 99,114],L[4,14,72],S[72,4],Experiments[18]
Subject S.d postsql(C,235KLOC)T[ 99,114],L[84,16,4,14,72],S[72],Experiments[18,4],G[46]
Systems S.e Apachehttpdorpart(C,261KLOC)T[ 99,78],L[14,72,84]
S.f FreeBSD(C,3MLOC)L[ 83,84,59]
S.g OthersT[ 41,85,55,92],L[115,37],S[15,42,116,111,20,74,57,16,14],M[66,67,87,31],G[75,65,81]
Subject Systems: TheSubjectSystemsfacetnoteswhichsystemshavebeenusedinthevalidation.Ifresearchersconduct
theirempiricalstudiesonthesamesystems,resultscanbecomparedmoremeaningfully.
5.9. Toolclassificationandattributes
Inthissectionweprovidetheattributevaluesforthefacetsforeachoftheindividualtoolsinourstudy. Table12presents
adetailedoverviewoftheavailabletoolsandtechniquesintheformofataxonomywherethefirstcolumn( Col.1)groupsby
theunderlyingapproach,andthesecondcolumn( Col.2)listseachtool/techniquebyname(orfirstauthornameforthose
techniquewithoutatoolname)andcitations.Thethirdcolumn( Col.3)givestheattributevaluesforthe Usagefacetsof
Table2thatapplytothetool/technique,andtheremainingcolumnsgivetheattributevaluesfortheotherfacets, Interaction,
Language,Clones,TechnicalAspects ,Adjustments,BasicTransformation/Normalization ,CodeRepresentation ,ProgramAnalysis
andEvaluation,asdescribedin Tables311respectively.
Aparticulartool/techniquecanhavemultipleattributevaluesforafacet,representedasasequenceofattributeletters.
Forexample,theattributevalue``acg''forfacet Freferstoattributes F.a,F.candF.g.Inordertofocusthecomparison,wehave
restrictedthissummarycomparisontomethodsforproceduralandobject-orientedlanguagesandhavenotlistedtoolsand
techniquesaimedatotherparadigms(suchaswebapplications)inthissummary.
6. Scenario-based evaluation of the techniques and tools
Clonedetectiontechniquesareofteninadequatelyevaluated,andonlyafewstudieshavelookedatsomeofthe
techniquesandtools[ 18,105,106,22].Ofthese,theBellonetal.[ 18]studyisthemostextensivetodate,withaquantitative
comparisonofsixstate-of-the-arttechniques,essentiallyallofthosewithtoolstargetedatCandJava.However,evenin
thatcarefulstudy,onlyasmallproportionofthecloneswereoracled,andanumberofotherfactorshavebeenidentified
aspotentiallyinfluencingtheresults[ 4].Thegenerallackofevaluationisexacerbatedbythefactthattherearenoagreed
uponevaluationcriteriaorrepresentativebenchmarks.Findingsuchuniversalcriteriaisdifficult,sincetechniquesareoften
designedfordifferentpurposesandeachhasitsowntunableparameters.
Inanattempttocompareallclonedetectiontechniquesmoreuniformly,independentoftoolavailability,implementation
limitationsorlanguage,wehavetakenapredictive,scenario-basedapproach.Wehavedesignedasmallsetofhypothetical
programeditingscenariosrepresentativeoftypicalchangestocopy/pastedcodeintheformofatop-downeditingtaxonomy.
Derivingsuchscenariosisitselfchallenging,sincethedefinitionofclonesisinherentlyvagueintheliterature[ 102,73].
Baxteretal.[15]givethemostgeneraldefinition,definingclonessimplyassegmentsofcodethataresimilaraccordingto
somedefinitionofsimilarity.Kamiyaetal.[ 59]defineclonesasportionsofsourcefile(s)thatare``identical''or``similar''
toeachother,wherebyidenticaltheymeanexactcopy,butsimilarisundefined.AsimilardefinitionisusedbyBurdetal.
[22],whereacodesegmentistermedacloneiftherearetwoormoreoccurrencesofthesegmentinthesourcecodewith
orwithout``minor''modifications,whereminorisundefined.Severalauthors,includingBaxteretal.[ 15],havedefined
``similar''usingdetection-dependentdefinitionsintermsofdifferencethresholds[ 60,67,84],andithasbeenproposed
thatautomaticallycombiningmultipledetectorresultsetscanhelpovercomesuchsimilaritydefinitionproblems[ 18,67].
Categorizationintheformofclonetaxonomieshasbeensuggestedasawaytoavoidsuchambiguitiesindefinition[ 10,87].
484 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Table 12
Toolsattributes.
Col.1 Col.2 Col.3 Col.4 Col.5 Col.6 Col.7 Col.8 Col.9 Col.10
Usage(Table2)
Interaction(Table3)
Language(Table4)
Clones(Table5)
Technicalaspects( Table6)
Adjustments(Table7)
Processing(Section 5.7)
Evaluation(Table11)Approach
Tool/author
PPlatform
DExternalDependencies
AAvailability
UUserInterface
OOutput
IIDESupport
LPLanguageParadigm
LSLanguageSupport
RCloneRelation
GCloneGranularity
CTCloneTypes
CAComparisonAlgorithms
CUComparisonGranularity
CCComputationalComplexity
PPPre-/Post-Processing
HHeuristics/Thresholds
TTransformations( Table8)
CRCodeRepresentation( Table9)
PAProgramAnalysis( Table10)
EEmpiricalValidation
ARAvailabilityofResults
SSubjectSystemsText-basedJohnson[55,54,53] e a f d c c a b b a a i b d c ad cd bd c d b g
Duploc[41] e a b d c c c bcef ad a ac e a b a cd b bf c bc b g
sif*[85] e a f d a c a b b f ac i b d b c a d a d b g
DuDe[114] e a e a c c c be a a ac d a d a abc ab b b d b bcd
SDD[78] a a a b b a c abe a a ac o b a a ac a b c d b be
Marcus*[86] e b f d a c a b b a acde g c d c b adf h c b b g
NICAD[99,104] b a e a c c c bde b bcd abcd o a b a bc cghi n g bc a abcde
Nasehi[92] e b f b b c b e a b abcd o k d a b h p g d b g
Simian[107] d a b a a c cd a b a ab q a d c e e f a d b bToken-basedDup[8] b a e d c c c be a a ab a ad a b ab b g d bc b bcd
CCFinder(X)[59,58] d a b c c c c bcef ad a abc a d a b abd eh f dg bc b abf
RTF[12] c a e d a c c be b a ab b d a c abd bg f d d b a
CP-Miner[84] e b e d d c c bc b g abc f e d b cd e n e b b adef
SHINOBI*[115] c a f b b b c cdi b a ab b d a b ab e d l d b g
CPD[29] a b a c c c c bce a a ab q d d c c g p d d b b
CloneDetective[ 37] c b ab b b b b ad b a ab q d a c a e f d d b g
clones[14,72] d b d c c c c bdefi ad a ab a ad a c a ah fg d b b abcdeTree-basedCloneDr[15] c b cd c c c c bcef ad a abc hl f b c b i j e bc b g
Asta[42] e b f b b c b de a a abc q f d c bc hi j e b b g
cdiff*[116] e a f d b c a b e f abe o f b a e i j e d b g
cpdetector[72,43] d b e c a c c be a a ab a d a b ad i j e a b cd
Deckard[52] b a e d a c c be b a abc h f b b bc i i h b b ab
Tairas[111] c b f d b b a b ad b ab a d b c e i j e d b g
CloneDetection[ 113] c b f d d c b ce b a ab f e b c c i l e d b b
CloneDigger[20] a b a a c a b eg a a abc a f b c b i l e d a g
C2D2[74] c b f d d c b di a b abc n d d c ab i l e d b g
Juillerat[57] e c f d d c b e e g a q d d c e i l e d b g
SimScan[108] d b b c c ab b e ad a abc q f d c b i j e d b b
ccdiml[16,14] d b d c c c c bcef a a abc l f b c b i j e b b gMetrics-
basedKontogiannis[66] e c f d d c a b a bc abcd e hi b c b i i e b b g
Mayrand[87] e b f d d c a b a b abcd q i b c b d i e bc b g
Davey[31] e c f b b c a b b b abcd j i b c b d i e d b g
Patenaude[93] b b f d d c b e a b abcd q i b c b i i e d b b
Kontogiannis[67] e c f d d c a b a b abcd m i b c b i i e b b gGraph-
basedDuplix[75] e b e d d c a b a a abcd k g c c c i k f cd b g
Komondoor[65] c b e d d c a b ad ab abcd k g c b e i k f d b g
GPLAG*[81] c b e d d c c bce a b abcd k g c c bd i k f b b g
Gabel[46] c b e d d c c bc b b abcd q i c b bcd i i f b b ad
However,thesetaxonomiesarelimitedtofunctionclonesandstillusevaguetermssuchas``similar''[ 87]and``one/two/three
longdifference''[ 10].
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 485
Fig. 2.Taxonomyofeditingscenariosfordifferentclonetypes.
Intuitively,inmostcasesthe``clones''wearelookingforarethosecreatedasaresultofcopy/paste/modifyactionsby
programmers.Inourworkwebeginwiththisassumption,anduseitasthebasisofatop-downtheoryofclones,whichwe
haveformalizedintoataxonomyofeditingscenariosthataprogrammermayundertakeintheintentionalcreationofaclone.
Ourtaxonomyisnotsimplyguessworkitisderivedfromthelargebodyofpublishedworkonexistingclonedefinitions
[15,46,59,65,84],clonetypes[18,67],clonetaxonomies[ 10,60,87],astudyofdevelopercopy/pasteactivities[ 63]andother
empiricalstudies[ 3,11,61,64].Wehavevalidatedthetaxonomybystudyingthecopy/pastepatternsoffunctionclones[ 100]
fromanempiricalstudythatanalyzed17opensourceCandJavasystemsincludingtheentireLinuxKernel(6,265KLOCC,
154,977functions),Apache httpd(275KLOCC,4,301functions)and j2sdk-swing(204KLOCJava,10,971methods)[ 99].
Fig.2demonstratestheuseofourproposededitingtaxonomyforcodefragmentsatthefunctionlevelofgranularity.The
taxonomyisdemonstratedonasimpleexampleoriginalfunction(inthemiddle,labeled``OriginalCopy'')thatcalculates
thesumandproductofaloopvariableandcallsanotherfunctionwiththesevaluesasparameters.Althoughtheediting
stepsaredemonstratedatfunction-levelgranularity,theyaregeneralenoughtobeapplicabletoanygranularityofcode
fragment.Weassumethatourprimaryintentionistofindtrueclones,thatis,thosethatactuallyresultfromcopy-and-edit
reuseofcode.Fig.2showsfourscenarios, Scenario1,Scenario2,Scenario3andScenario4,whereeachscenariohasseveral
sub-scenarios.Mappingtotheliterature(Section 2),wecalltheclonescreatedbythesescenarios Type-1,Type-2,Type-3and
Type-4clonesrespectively.
Fromaprogramcomprehensionpointofview,findingsuchtrueclones(thosearecreatedasperthescenarios)isuseful
sinceunderstandingarepresentativecopyfromaclonegroupassistsinunderstandingallcopiesinthatgroup[ 54].More-
over,replacingallthedetectedsimilarcopiesofaclonegroupbyafunctioncalltotherepresentativecopy(i.e.,refactoring)
canpotentiallyimproveunderstandability,maintainabilityandextensibility,andreducethecomplexityofthesystem[ 44].
Thesescenarioscouldalsobeusedtoguidethedevelopmentofforwardclonemanagementtools(e.g., CReN[51]).
Basedonthesehypotheticalscenarios,wehaveestimatedhowwellthevariousclonedetectiontechniquesmayperform
basedontheirpublishedproperties(eitherinthecorrespondingpublishedpapersoronlinedocumentation).Inorderto
estimatemaximalpotential,wehaveassumedthemostlenientsettingsofanytunableparametersofthetechniques/tools.
Thus,thisisnotanactualevaluation,ratheritprovidesanoverallpictureofthepotentialofeachtechniqueandtoolin
486 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Table 13
Meaningsoftheratingsymbols.
Symbols Meaning Description VerywellDetectsthecloneswithhighaccuracyandconfidence,i.e.,withhighprecisionandrecall.
Hastunableparametersfordifferenttypesofclones(i.e.,candetectclonesofdifferentscenariosseparately).
IncaseofScenario2,hasseparatetunableparametersfordetectingclonesofthesub-scenarios.
Whendetectingclonesofasub-scenarioofscenario k(exceptforScenario2),detectionoftheclonesofother
sub-scenariosof kisdesirableforhighrecall.
Thescenariosareonatop-downfashionandthus,whendetectingclonesofscenario k,detectionofclones
of(sub-)scenario lwherek<lisnotexpected(forhighprecision).However,detectionofclonesof
(sub-)scenariojwherej<kisdesirable.
Thetooleitherhasanoptionfordetectingdifferentgranularities(e.g.,methodorbeginendblock)ofclones
orappliesseveralpre-/post-processingactivitiestoavoidspuriousclones[ 72]oratleast(ifthetoolfinds
clonesoffreegranularity)subsumestheclonesofthe(sub-)scenarioinquestion.
Thetooliscapableofdetectingtheclonesofthe(sub)-scenariowithreasonabletimeandspace(notin
monthsforexample)
Toourknowledgethereisnoempiricalstudiesthatshowsthatthesubjecttoolwasnotcapable(or
performedpoorly)ofdetectingtheclonetypeinquestion.H #Detectstheclonesofthe(sub-)scenariobutmayreturnfewfalsepositives.
Well Mayalsomisssomeoftheclones.
Doesnotmeetoneormoreofthecriteriaofthefirstrow(for verywell).G # MediumDetectstheclonesofthe(sub-)scenariobutmayreturnmanyfalsepositives(about50%forexample).
Doesnotmeetmanyofthecriteriaofthefirstrow(for verywell).
	Detectswithlotsoffalsepositives(lowprecision).
Low Alsomaymissmanyofthesimilarclones(lowrecall).
Doesnotmeetmanyofthecriteriaofthefirstrow(for verywell).
 ProbablycanAlthoughthereisnoempiricalorothersortofevidence,theunderlyingtechniqueofthetechnique/tool
mightbecapableofdetectingclonesofthe(sub-)scenarioinquestion.
Thetool/techniquemightgeneratelotsoffalsepositives(verylowprecision).
Thetool/techniquemightmisssomeclones(verylowrecall).# ProbablycannotWearenotsurebutaspertheunderlyingtechniqueofthesubjecttechnique/tool,itmightbeimpossible
todetecttheclonesofthe(sub-)scenarioinquestion.
Wedonotthinkthereareempiricalstudiesoranysortofevidencethatshowsthatthesubjecttooliscapable
ofdetectingtheclonesofthe(sub-)scenarioinquestion.
 CannotAspertheunderlyingtechniqueofthesubjecttechnique/tool,itisimpossibletodetecttheclonesofthe
(sub-)scenarioinquestion.
Thereisnoempiricalstudyoranysortofevidencethatthesubjecttoolwascapableofdetectingtheclones
ofthe(sub-)scenarioinquestion.
handlingclonesresultingfromeachofthescenarios.Ourcomparisonisnotintendedtobeaconcreteexperiment,and
couldnotbecomprehensiveortrulypredictiveandqualitativeifitwerecastasone,boundtotargetlanguages,platforms
andimplementations.
Table14providesanoverallsummaryoftheresultsofourevaluations,wherethesymbolsrepresentanestimateof
theabilityofeachtechnique/tooltoaccuratelydetecteach(sub-)scenariowithbothhighprecisionandhighrecall.For
example,averywell(denotedwith  )ratingforaparticularsub-scenarioofaparticulartoolmeansthatthesubjecttool
(orthecorrespondingtechniqueusedinthattool)iscapableofdetecting(i.e.,about100%recall)thatscenariowithoutany
falsepositives(i.e.,about100%precision)asperourunderstanding.Whenatool'stunableparametersaresettodetecta
sub-scenarioofaparticularscenario,detectionoftheothersub-scenariosofthatscenarioisnotcountedasfalsepositives.
However,detectingthesub-scenariosofotherscenariosmaybeconsideredasfalsepositives.Becausethetaxonomyis
createdasatop-downtheoryofclonesfrom Scenario1toScenario4,whenatoolissettodetectasub-scenarioofalower
numberedscenario(e.g., Scenario1),anydetectionofsub-scenario(s)ofahighernumberedscenario(i.e.,scenarios2,3or
4)isconsideredasafalsepositive.Ontheotherhand,whenthetoolissettodetectasub-scenarioofahighernumbered
scenario(e.g.,Scenario3),thedetectionofthesub-scenariosofthelowernumberedscenarios(i.e.,scenarios1and2)is
desirable(forhighrecall)andshouldnotbeconsideredasfalsepositives. Table13summarizesthemeaningsofthesymbols
wehaveusedintheevaluation.
ForScenario2,wealsoexpectthatatoolmayprovidedifferenttunableparameterstodetectthedifferentsub-scenarios
separately.Forexample,theremaybeaseparateoptionfordetectingconsistentlyrenamedclonesfromrenamingwhere
consistencyisnotmaintained.Thisisimportantbecausesometoolsusethesametechniquebutdifferwithrespecttothe
tunableparametersfordifferenttypesofclones.Moreover,sometoolsyieldsyntacticcloneswhileothersdonot,leadingto
thelowerratingsfora(sub)-scenario.
Giventhefactthatnotalltoolsactuallyproducetheexpectedoutputinpractice,wehavealsoemployedourexperience
intoolcomparisonandknowledgegainedfromothertoolcomparisonexperimentsandindividualtoolevaluationswhere
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 487
Table 14
Scenario-basedevaluationofthesurveyedclonedetectiontechniquesandtools.
Citation Scenario1 Scenario2 Scenario3 Scenario4
a b c a b c d a b c d e a b c dText-basedJohnson[55,54]   
H #            
Duploc[41]       
H #
H # 
G #   
sif[85]*
G #
G #
G #            
DuDe[114]       
H #
H #
G #
G #
G #   
SDD[78]
H #
H #
G #   
H #
H #	 	 	    
Marcus[86]*
G #
G # 
G #	
G #
G #  
G #
G #
G #
BasicNICAD[99]       
H #
H #
H #
H #
H #   
FullNICAD[104]     
H #
H #
H #
H #
H #
H #
H #
H #   
Nasehi[92]
G #
G #
G #
G #
G #
G #
G #
G #
G #	 	 	
#
#
#
G #
Simian[107]   #
G #
G #
G #         Token-basedDup[8]    
H #         
CCFinder(X)[59,58]
H #
H #
H #
H #
H #
H #         
Gemini[112]*
H #
H #
H #
H #
G #
H #
G #
G #
G #
G #
G #   
RTF[12]    
H #
H #
H #         
CP-Miner[84]
H #
H #
H #
H #
H #
H #	
H #
H #
G #
G #
G #   
SHINOBI[115]*
H #
H #
H #
H #
H #
H #         
CPD[29]  #  
G #
G #
G ##        
CloneDetective[ 37]
H #
H #
H #
H #
H #
H #         
clones/iClones[14,72]  
H # 
H #
H #         Tree-basedCloneDr[15]
 
 
 
 
 
 	
G #
G #	
G #
G #   
Asta[42]
 
 
 
G #
G #
G #
G #
G #
G #      
cpdetector/clast[ 72,14]   
H #
H #
H #         
Deckard[52]
H #
H #
H #
H #
H #
H #
G #
G #
G #
G #
G #   
Tairas[111]
H #
H #
H #
#
#
G #         
CloneDetection[ 113]
H #
H #
H #
H #
H #
H #         
CloneDigger[20]
 
 
 
H #
H #
H #
H #
H #
H # 
#   
C2D2[74]
G #
G #
G #
G #
G #
G #
G #
G #
G #
#
#
#   
Juillerat[57]
 
 
             
SimScan[108]
 
 
 
H #
H #
H #         
ccdiml[16,14]
 
 
 
 
 
 

G #
G #	 
G #   Metrics-basedKontogiannis[66]
H #
H #
H #
H #
H #
H #	 	 	 	 	 	
G #
G #
G #	
Mayrand[87]
H #
H #
H #
H #
H #
G #
G #
G #	 	 	
G #
G #	 
Dagenais[30]*
G #
G #
G #
G #
G #
G #
G #
G #
G #  
G #
G ##
Merlo[89,90]
H #
H #
H #
H #
H #
H #	
G #
G #	 	 	
G #
G #	 
Davey[31]
H #
H #
H #
H #
H #
H #	
G #
G #  
G #	 	 #
Patenaude[93]
H #
H #
H #
H #
H #
H #	 	 	 	 	 	    
Kontogiannis[67]
H #
H #
H #
H #
H #
H #	 	 	 	 	 	 	 	 	 	
Antoniol[1,2]
H #
H #
H #
H #
H #
H #
G #
G #
G #	 	 	
G #
G #	 Graph-basedDuplix[75]
H #
H #
H #
H #
H #
H #
G #
G #
G #
G #
G #
G #
H #
G #	 
Komondoor[65]
H #
H #
H #
H #
H #
H #	 	  	  
H #
H #	 
GPLAG[81]*
H #
H #
H #
H #
H #
H #	 	 	
G #
G #
G #
H #
H #	
G #
Gabel[46]
H #
H #
H #
H #
H #
H #
H #
H #
H #
G #
G #
G #
G #
G #
G # verywell
H #well
G #medium	lowprobablycan
#probablycannotcannot.
applicable.Thus,theratingsin Table14foreach(sub)-scenariorepresentabalanceofwhatisexpectedandwhatis
achieved(whereapplicable)usingaparticulartool,potentiallyhintingtheoverallabilityofthetoolwithrespectto
the(sub)-scenarios.AlthoughthescenariosarerepresentedinthelanguageC,whenweevaluateatoolthatsupports
only object-oriented languages (e.g., Java), we imagine similar scenarios on that language to evaluate the tool (the
adaptability/portabilityisaseparateissueanddiscussedintheprevioussection).
Anasterisk(*)indicatesatechnique/toolwithspeciallimitations(orthathassomeothermainpurposeotherthan
clonedetection)suchaswholefilecomparison,visualizationonly,plagiarismdetection,IDEsupportorotherspecialissues
discussedasapplicable.Inthefollowingsubsections,weconsidereachscenarioandoutlineourreasoninginestimatingthe
abilityofthetechniquestoaccuratelydetectthemusingtheinformationfromSection 5.
6.1. Scenario1
Scenario 1:Aprogrammercopiesafunctionthatcalculatesthesumandproductofaloopvariableandcallsanother
function,foo()withthesevaluesasparametersthreetimes,makingchangesinwhitespaceinthefirstfragment(S1(a)),changes
incommentinginthesecond(S1(b)),andchangesinformattinginthethird(S1(c))( Fig.2).
488 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Anidealclonedetectiontechniqueshouldrecognizeallthreecopy/pasted/modifiedfragmentsasclonepairswiththe
originalorformacloneclassforthemalongwiththeoriginal.Thethirdcolumnunderthe Scenario1headingofTable14
summarizeshowwelleachtechniqueislikelytoworkforthesescenarios.
Amongthetext-basedtechniquesandtools,onlyNICAD[ 99,104]isexpectedtodoverywellonallthesub-scenarios,
inpartbecauseitwasdesignedwiththeminmind.NICADappliesastandardpretty-printingnormalizationthatremoves
comments(scenarioS1(b))andformattingdifferences(scenarioS1(c)),andusesawhitespaceinsensitive(ScenarioS1(a))
textline-wisecomparisontofindclones.Although,linearinspaceandscalable[ 99],NICADhasaquadratictimecomplexity
withrespecttothenumberofextractedcodefragmentsforcomparison.Moreover,NICADisparser-basedandthuslanguage
specific.Whileadaptingtoanewlanguage,oneatleastneedstogetaTXL[ 27]grammarforthatlanguage.Othertext-
basedtools,suchas Duploc[41],DuDe[114]andSimian[107]alsodetectscenariosS1(a)andS1(b)verywell.UnlikeNICAD,
Duplocdoesnotrelyonrobustparsinginsteadituseslightweightlexicalanalysistoremovecomments(scenarioS1(b))
andwhitespace(scenarioS1(a))withinlinesanddetectsclonesusingstring-baseddynamicpatternmatching. DuDeand
Simiandosimilarthingsbyapplyingregularexpressions(i.e.,lexicalanalysisagain).However,alloftheseline-based
techniques/toolsaresensitivetoformatalterationsandthusmaynotdetectscenarioS1(c).Marcus'text-basedLSIapproach
[86]isnotdesignedtodetectscenarioS1(b),sinceitcomparescomments(andidentifiers)infindingclones.Amongthe
othertext-basedtechniques,Johnson'sapproach[ 5355]shoulddetectallthreeofthesesub-scenarioswell.Johnsonapplies
severaloptionsforkeeping/removingwhitespaceandcomments(thus,scenariosS1(a)andS1(b)mightbedetectedwell)
andusesfingerprintsofsubstringsforfindingclones(thusmightnotbeaffectedbyformatting,leadingtodetectscenario
S1(c)).SDD[78]appliesn-neighborapproach(i.e.,allowsgapsinsimilarity)andthusmightdetectthesesub-scenariostoo.
However,allowinggapsmightleadtodetectfalsepositiveclonesevenfortheseexactclones.
Amongthetoken-basedtechniques/tools, RTF[12]andclones[72]shoulddetectallthree Scenario1sub-scenarioswell.
RTFappliesflexibletokenizationand cloneshasapost-processorthatcandistinguishdifferenttypesofclonesbycomparing
identifiervaluesandcandifferentiateothersimilarscenarios(e.g.,sub-scenariosof Scenario2).However,cloneshasproblems
ifsuperflousbracketsareaddedinthecopiedfragmentasitcomparesonlythesequenceoftokensanddoesnotremove
bracketsbeforecomparison.Token-basedtechniquesandtools(e.g., CCFinder)ingeneralcannotdifferentiatebetween
clonesofScenario1andScenario2.Moreover,thesetechniquesoftenreturnnon-syntacticandspuriousclones[ 72].Baker's
DupcanalsodetectclonesofscenariosS1(a)andS1(b)verywellbutcannotdetectclonesofscenarioS1(c),since Dup
summarizesalltokensofalineatatimeandthusissensitivetoformattingchanges.Mostothertoken-basedtechniquesare
notsensitivetoformattingchangessincetheycomparetoken-by-token.
Tree-basedtechniques(e.g., cpdetector)ignoreformattingdifferencesandcommentsandshoulddetectall Scenario1sub-
scenariosverywelliftheylookforexactsubtreeswithoutignoringtree-leaves(inmostcasestheyignoreleavesandthusa
post-processingstepisrequiredtodistinguishclonesof Scenario1andScenario2).However,sometree-basedtechniquesuse
alternativerepresentationsoftheparse-tree/AST(e.g., Deckardworksoncharacteristicvectorsoftheparsetree)andmay
notdetectthemaccurately(apost-processingstepisrequiredtodifferentiatethem).Moreover,arecentstudy[ 104]shows
thatanAST-basedexactmatchingfunctionclonedetectiontechnique[ 111]canevenmisssomeexactfunctionclones.
Metrics-basedtechniquesmayreturnthesamemetricsvaluesforotherscenariosofourtaxonomyandforotherdifferent
fragmentsandthusmayreturnfalsepositivesinoursense.Amongthemetrics-basedapproaches,Mayrandetal.[ 87]provide
afine-grainedsetofmetricsfordetectingfunctionclones(andpossiblyalsoclonesof begin-endblocks).Others(e.g.,Antoniol
etal.[2,1]andMerloetal.[ 90,89])alsoprovidesimilarmetricswithsomeminordifferencesandareexpectedtodowellon
thesescenarios.
Intheory,graph-basedtechniquesshouldbegoodatall Scenario1sub-scenarios.However,inpracticetheyyieldmany
variantsoftheactualclonepairsandthattheremightbesimilargraphsfordissimilarcodeblocks,reducingprecision.Thus
inourviewtheydonotdowellonthesescenarios.However,anewvariantofthe DeckardtoolmapsPDGsubgraphsto
relatedstructuredsyntaxbeforecomparisonandthusmightdowell[ 46].
6.2. Scenario2
Scenario 2:Theprogrammermakesfourmorecopiesofthefunction,usingasystematicrenamingofidentifiersandliteralsin
thefirstfragment(S2(a)),renamingtheidentifiers(butnotnecessarilysystematically)inthesecondfragment(S2(b)),renaming
datatypesandliteralvalues(butnotnecessarilyconsistent)inthethirdfragment(S2(c)),andreplacingsomeparameterswith
expressionsinthefourthfragment(S2(d))( Fig.2).
Onceagain,anidealclonedetectiontechniqueshoulddetectallfourmodifiedfragmentsasclonepairswiththeoriginal
orshouldformacloneclassforthemalongwiththeoriginal.Needlesstosay,codefragmentscreatedfrom Scenario1might
alsoformclonepairsoracloneclasswiththecodefragmentsofthisscenario.Thefourthcolumnunderthe Scenario2
headingofTable14summarizeshowwelleachtechniquemayworkonthesescenarios.
Text-basedtechniquesandtoolsarenotgoodatdetectingclonescreatedbythese(sub)-scenarios.Fordetecting
suchscenariostokennormalization/abstraction/transformationisrequiredtoremovethedifferencesbetweendiffering
identifiersandliterals.Ofthetext-basedtechniques,onlyNICAD[ 104],Nasehi'sapproach[ 92]andSimian[107]candetect
suchscenarios(although SimiancannotdetectscenarioS2(d)).NICADcandetectconsistentlyrenamedclones(scenario
S2(a))andotherrenamedclones(scenariosS2(b)andS2(c))efficiently,andusingflexiblecodenormalizationthuscandetect
scenarioS2(d)aswell.Anextendedversionof Duploc[40]canalsodetectscenariosS2(b)andS2(c),butnotS2(a)andS2(d).
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 489
However,althoughthesetools(i.e.,NICAD,Nasehi'sapproachor Simian)findclonesbytextualcomparison,theyactually
usesourcetransformations(inNICAD'scase,codeabstractionandinNasehi'sapproach,atransformationofprogramcode
toatomicunits)andthusasyntactic/semanticanalysisisrequiredthatmaynotbeeasilyadaptabletootherlanguages.The
remainingtext-basedtechniquescannotdowellwiththesescenariossincetheynormallycompareprogramtextwithout
normalizationortransformationandarethereforefragiletoidentifierrenaming.
Token-basedtechniques/toolsarewellsuitedtodetectingclonescreatedby Scenario2.Almostalltoken-basedtechniques
andtoolscandetectscenariosS2(a),S2(b)andS2(c)well,butarelikelytoalsohavemanyfalsepositivesduetotheir
identifierandliteralnormalizations(orabstractions)andthedetectionofspuriousclones[ 72].However,only Dup[6]and
clones/iClones[48]areratedtoberobustindetectingconsistentlyparameter-substitutedclones(scenarioS2(a))because
oftheiruseofparameterizedsuffixtrees.Mostofthetools(except Dup,RTF[12]andclones/iClones)cannotdifferentiate
betweenType-1(clonesofScenario1)andType-2(clonesofScenario2).RTFandclones/iClonescanalsodifferentiatebetween
thesub-scenariosof Scenario2.Noneofthetoken-basedtechniques(exceptpossibly CP-Miner[84]thatallowsarbitrary
gapsincomparison)candetectclonesofscenarioS2(d)becausetheyneitherapplystructuralabstractiontotheprogram
codenorallowgapsintheircomparison.
WiththeexceptionofJuillerat'sapproach[ 57],whichdetectsonlyexactclones,andTairas'approach[ 111],whichdetects
exactclonesandasmallsubsetof Type-2clones,almostalltree-basedtechniquesmayalsodetectscenariosS2(a),S2(b)and
S2(c)verywell,becausethesetechniquesnormallyignoreidentifiersandliteralswhencomparing.However,likesomeofthe
token-basedapproaches,somesyntactictoolsdonotdifferentiatebetweenclonesof Type-1andType-2.ThetoolsCloneDr
[15],ccdiml[14],cpdetector[72]andclast[14]areknowntodifferentiatethesetypes.ForscenarioS2(d),thetree-basedtools
Asta[42]andCloneDigger[20]seemtobewellsuited,astheycanapplystructuralabstractiontoarbitrarysubtrees.
Metrics-andgraph-basedtechniquescanalsodetectthesescenarios,butmetrics-basedapproachesmayreturnmany
falsepositivesbecauseourotherscenarioscanyieldsimilarmetricsvalues.Graph-basedtechniquesarealsoexpectedtodo
wellinthesescenarios.However,theynormallyreturnmanyvariantsoftheidealclonesandthatdissimilarcodefragments
canleadtosimilargraphsleadingtolowprecision.
6.3. Scenario3
Scenario 3:Theprogrammermakesfivemorecopiesofthefunctionandthistimemakessmallinsertionswithinalineinthe
firstfragment(S3(a)),smalldeletionswithinalineinthesecondfragment(S3(b)),insertssomenewlinesinthethirdfragment
(S3(c)),deletessomelinesfromthefourthfragment(S3(d)),andmakeschangestosomewholelinesinthefifthfragment(S2(e))
(Fig.2).
Wehopethatanidealclonedetectiontechniquewoulddetectallfivefragmentsasclonepairswiththeoriginalandform
acloneclassforthem.Again,codefragmentsof Scenario1andScenario2mightalsoformclonepairs/classeswiththecode
fragmentsofthisscenario.Thefifthcolumnunderthe Scenario3headingofTable14summarizeshowwelleachtechnique
mayworkonthesescenarios.
Ingeneral,text-basedtechniquesandtoolsarenotgoodatdetecting Type-3near-missclonescreatedusing Scenario3
unlesstheyapplythreshold-basedcomparisonorcombinesmaller Type-1andType-2clonesinapost-processingphase.
Duploctransformsprogramtexttoacondensedform(removingwhitespaceandcomments)thenappliesstring-based
dynamicpatternmatchingwithgaps,andhencecandetectchangeswithinaline.Therefore, Duplocisexpectedtodowellon
scenariosS3(a)andS3(b)(andpossiblyS3(e)).Although DuDe[114]istext-based,itcancombinesmallduplicatedsegments
toformlargeronesbyallowinggapsinitsscatterplotvisualization.Both BasicNICAD[99]andFullNICAD[104]detectthese
scenarioswellastheyallowsize-sensitivethreshold-basedcomparisonoftheextractedandpretty-printedpotentialclones.
FullNICAD[104]alsousesflexiblecodenormalizationandfilteringthatremovesmanyofthesmalldifferencesbetweencode
fragmentsandthuscanalsodetect Type-3clones.Nasehi'sapproach[ 92]transformscodetosemanticallyequivalentatomic
unitsandusesaneditdistancealgorithmwithallowablethresholds.Thus,thisapproachisalsoexpectedtodetectscenarios
S3(a)andS3(b)well,andpossiblyalsoscenariosS3(c),S3(d),andS3(e).
Amongthetoken-basedtechniques,only Gemini[112](apost-processor/visualizerfor CCFinder[59])andCP-Miner[84]
arelikelytoworkwellwiththesescenarios. CP-Minerusesafrequentsubsequencedataminingalgorithmwhichallowsit
totolerategapsinclonedsegments. Geminiontheotherhand,usesoutput( Type-1andType-2clones)fromCCFinderand
scatterplotvisualizationtodetectsuchnear-missclones,muchlike DuDe.
Amongthetree-basedtechniques,only Deckard[52]andAsta[42]arelikelytodowellforthesescenarios. Astaderives
syntax-treepatternswithplaceholdersforcompletesubtrees,whichsupportsstructuralabstraction. Deckardusesthenovel
ideaofacharacteristicsvector(thus Deckardcanalsobeclassifiedasametrics-basedtool)toapproximatethestructural
informationfromASTsintheEuclideanspace.However,aswithmetrics-basedapproaches,suchanapproximationis
challengingandvectorvaluesfromtwoquitedistinctcodefragmentsmaybesimilar,indicatingthat Deckardcouldreturn
manyfalsepositivesindetectingsuchclones.Othertree-basedtools,suchas CloneDr[15]andccdiml[14],maydetect
scenariosS3(a)andS3(b)iftheirunderlyingsimilaritymeasureforinexacttreematchingissettotoleratethem.In CloneDr,a
compilergeneratorisusedtogenerateanannotatedparsetree(AST)andcomparesitssubtreesbycharacterizationmetrics
basedonahashfunction.Sourcecodeofsimilarsubtreesisthenreturnedasclones.Thehashfunctionenablesonetodo
parameterizedmatchingandtodetectgappedclones,especiallyifthegapsarewithinaline. ccdimlisavariantofCloneDR
thathasadifferentintermediaterepresentationwithexplicitmodelingofsequences,whichhelpsinfindingnear-missclones
createdfromthesescenarios.
490 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
Metrics-basedtechniquescanfindclonesinthesescenarios,butmayyieldmanyfalsepositives,sincemanyothercode
fragmentsmayhavesimilarmetricsvalues,resultinginloweroverallaccuracy.However,scenariosS3(a)andS3(b)canlikely
beaccuratelydetectedbyatleastsomeofthemetrics-basedapproaches,notablyMayrand's[ 87],Dagenais'[30],Merlo's
[90]andAntoniol's[ 2].
Graph-basedapproachesprimarilyusecontrolanddataflowinformationandthusareexpectedtodetectthesescenarios
well.Infact,inBellon'sexperiment[ 18],thegraph-basedtool Duplix[75]wasfoundtodetectasmallproportionofsuch
near-missclones.However,ingeneralgraph-basedtoolsmayreturnmanyvariantsoftheidealclones,andsomeofthese
variantscanbeconsideredasfalsepositives,yieldingaloweroverallaccuracy.Onlytherecentsemantics-basedapproach
byGabeletal.[46]hasbeendemonstratedtoscale.InsteadofcomparingsubgraphsofthePDGs,Gabel'sapproachmaps
subgraphstorelatedstructuredsyntaxandthenfindsclonesusing Deckardtechnique.
OneshouldalsonotethatalthoughKamiya[ 59],Krinke[75],Mayrand/Merlo[ 90,87],andRieger[41]mentionthattheir
approachescanalsofindclonesof Type-3,accordingtoBellonetal.'sstudy[ 18]inpracticeonlyKrinke's Duplixactuallydoes.
InDuplix,however,clonesofothertypesarefoundwithverylowrecall.
6.4. Scenario4
Scenario 4:Theprogrammermakesfourmorecopiesofthefunctionandthistimereordersthedataindependentdeclarations
inthefirstfragment(S4(a)),reordersdataindependentstatementsinthesecond(S4(b)),reordersdatadependentstatementsin
thethird(S4(c)),andreplacesacontrolstatementwithadifferentoneinthefourth(S4(d))( Fig.2).
Again,weexpectthatanidealclonedetectiontechniqueshouldberobustenoughtodetectsuchmodifiedcodefragments
asclonepairswiththeoriginalorformacloneclassforthem.Onceagain,codefragmentsof Scenario1,Scenario2andScenario
3mightformclonepairs/cloneclasseswiththecodefragmentsofthisscenario.Thesixthcolumnunderthe Scenario4
headingofTable14summarizeshowwelleachtechniqueislikelytoworkinthesescenarios.
Amongthetext-basedtechniques,onlyMarcus'LSIapproach[ 86]islikelytodowellwithscenariosS4(a),S4(b)andS4(c).
Marcus'approachconsidersonlycommentsandidentifiernamesinthecomparison.Whenstatementsofcopiedfragments
arereordered,commentsandidentifiersmaynotbechangedandthustheirapproachmaydetectthesescenarios.Nasehi's
approach[92]performsasemantics-preservingtransformationfordifferentsyntacticvariantsofalanguagetothesame
atomicunits.Thus,therepresentationoftheatomicunitsoftheoriginalfunctionwiththe forloopmightbesimilartothe
atomicrepresentationofthecopiedfunctionwith whileloopofscenarioS4(d).Moreover,thisapproachusesaneditdistance-
basedalgorithm,whichallowsfordissimilaritythresholdsinthecomparison.WethereforeexpectthatNasehi'sapproach
maybeabletodetectclonescreatedbyscenarioS4(d).NICADprobablycandetectthereorderingscenariosS4(a),S4(b)and
S4(c)ifthetotalgapcreatedbythereorderingofstatementsiswithintheallowablesize-sensitivedifferencethresholds.
However,increasingthethresholdmightleadtofalsepositiveclones.
Unfortunately,thereisnotoken-basedtechniquethatcandetectclonescreatedinthesescenarioswell.Thisisobvious
sincethesetechniques/toolsuseexactmatchingonnormalizedtokensequencesanddonotallowforanygaps.Reordering
statements(scenariosS4(a),S4(b)andS4(c))orreplacementsofonecontrolbyanotherequivalentvariant(scenarioS4(d))
obviouslybreaksthetokensequencesbetweentheoriginalandcopiedcodefragments.However,sometoken-basedtools,
suchasGeminiandCP-Miner,mightdetectscenariosS4(a),S4(b)andS4(c). Geminiusesscatterplotvisualizationof Type-1
andType-2clonesfromCCFinderandthusmightdetectscenariosS4(a),S4(b)andS4(c)byallowinggaps. CP-Minerallows
forarbitrarygapsinclonedsegmentsandthusmightalsodetectscenariosS4(a),S4(b)andS4(c).However,thereisno
token-basedtechniquethatcandetectscenarioS4(d).
Thesituationisworseinthecaseoftree-basedtechniques.Thereisnotree-basedtechniqueortoolthatcanbeexpected
todetectthesescenarios,withthepossibleexceptionthat CloneDrmaybeabletodetectclonesofscenarioS4(a)sinceits
subtreecharacterizationcanignoredeclarationstatements.
Metrics-basedtechniquesshouldbeabletodetectscenariosS4(a)andS4(b)well,sincereorderingofdata-independent
statements might not change the metrics values. However, metrics values might change when reordering happens
betweendata-dependentstatements(scenarioS4(c))duetotheunderlyingmetricsdefinition.Whencontrolreplacement
isperformedonthecopiedfragment(scenarioS4(d))metricsvaluesmightchangesignificantlyandthusmetrics-based
techniqueseithercannotdetectscenarioS4(d)orwilldetectitwithmanyfalsepositives,yieldingalowoverallaccuracy.
ItappearsthatonlyPDG-basedtechniquesarelikelytoworkwellwithscenariosS4(a)andS4(b).PDG-basedtechniques
usedataandcontrolflowinformation,whichremainsunchangedacrossreorderingofdeclarationsanddataindependent
statements.Reorderingofdatadependentstatementsmaychangethedataandcontrolflowgraphshowever,sotheymay
notdoaswellwithscenarioS4(c).TodetectscenarioS4(d),exhaustivesourcetransformationmaybenecessary.However,
analternativeapproachisproposedintheplagiarismdetectiontool GPLAG[81]forfindingplagiarizedcodesimilartothose
createdbyscenarioS4(d).
7. An example use of the study
Oursurveyandevaluationsarenotjustintendedforexpertsinclonedetection,butalsoforusersandbuildersoftools
basedonclonedetectiontechniques.Asademonstrationofhowthisstudycanhelp,weprovidetwoexampleuserintentions
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 491
andsuggestatoolorsetoftoolstomeettheirrequirements.Ofcourse,manyothercombinationsofthetoolscanbederived
basedonuserrequirements,bothintermsofdifferentscenariosandthetechniquesused.Suchacombinationmighthelp
onetounderstandhowtodesignahybridapproachtoberobustacrossalltypesofclonesorhowtoemployasetofdifferent
toolstoachieveabetterresult.OurNICADtool[ 104]isanexampleofsuchahybrid,combiningtree-basedstructuralanalysis
withtext-basedcomparison.
Intention 1:Atooluserwouldliketofindalltypesofclones(asoutlinedinthispaper)inalargeCsystem(theLinuxkernel)
withreasonableperformance.
Here,theprimaryobjectiveistheabilitytohandlelargeCsystemswhiledoingwellinfindingallthekindsofclones
thatmaybecreatedbythevariouseditingscenariosoutlinedinSection 6.Letusfirstlookforindividualtoolsthatrate
reasonablywellforthescenarios.From Table14weseethattheobvioussetis Gabel[46],GPLAG[81],Kontogiannis[66],
C2D2[74],CP-Miner[84],Gemini[112],Nasehi[92].Althoughnoneofthesetoolsisabletohandleallofthescenarios,they
allseemtodowellwithmostofthescenarios.
ThesecondrequirementisthatthetoolshouldhandleCsystems.AccordingtoourfindingsinSection 5(column5of
Table12),onlyGabel[46],GPLAG[81],Kontogiannis[ 66],CP-Miner[84],andGemini[112]meetthisrequirement.
Asathirdrequirement,theuserneedsatoolcapableofhandlinglargesystems.Fromthe7thcolumnwithcolumn
headingTechnicalAspects andfromthecorrespondingfacettable( Table6),theusercangetanideaofthealgorithmsused
andtheirassociatedcomplexities.Inparticularfromthesub-column ComputationalComplexity ofTable12andfromthe
lastrow(CC(WorstCaseComputationalComplexity) )ofTable6,weseethatofthesetwehavechosenonly Geminiseems
computationallyefficient.However,although GeminiusesCCFinderinthebackgroundforfindingsmaller Type-1andType-2
cloneswhichislinearw.r.t.thesizeoftheprogram,findingcombinationof Type-1andType-2clonestoformType-3clones
mayrequiresuperlineartime;oftendynamicprogrammingisusedforthiscombination,whichisnotlinear.Furthermore,
Geminiismainlyavisualizationtoolandthusmightnotfullymeetouruser'srequirements.
Thequestionnowremainsastowhetherthereareothertoolsinourcandidatesetthatcanhandlelargesystemsdespite
havingnonlinear(worstcase)computationalcomplexities.Wecanfindthisinformationfromthe10thcolumn(withcolumn
headingEvaluation)ofTable12.Inparticular,fromthesub-columnwithheading SubjectSystemsandthecorresponding
Evaluationfacettable(Table11)weseethatfortunatelyboth CP-MinerandGabelhavebeenevaluatedevenwith Linux
Kernel,oneofthelargestCsystems.Thequestionagainremainswhethertheresultsoftheirstudiesareavailable,especially
fortheLinuxKernel.Wecanseethisinformationinthesamecolumn Evaluationwithsub-column AvailabilityofResults and
thecorrespondingfacettable(withrowheading AR(AvailabilityofResults) inTable11).Weseethatcompleteresultsare
notavailablefor LinuxKernel.Moreover,Linuxischangingeverydayandthusresultsfortheintendedversionmightnotbe
availableanyway.
Astheresultsarenotavailable,theuserneedstorunthetool(either CP-MinerorGabel)tofindclonesin Linux.Thenext
crucialquestionnowiswhetherthetoolsareavailableforthirdpartyuse.Fromthe AvailabilityfacetofUsagecategoryin
Table12andinmoredetailin Table2,weobservethatneitherofthemisavailableonlinebutanevaluationversionmaybe
availableonrequest.
Theremainingquestionis,whichtooltorequestfirst?Theusercanaskforbothtools,orcanbemorespecificin
determiningwhomightactuallybeabletoreleasetheirtool.Inparticular,wecanlooktoseewhetherthetoolisstandalone
orhasanyexternaldependenciesorisapartofrequiredlargertoolset.Ifthetoolisstandalone,itismorelikelythatthetool
willbeavailableuponrequest,otherwiseitislikelythatthetoolmaynotbeavailable,orevenifavailablemaybehardtouse
byathirdparty.Unfortunately,wesee(fromthesametablesabove)thatboththetoolshaveexternaldependencies.With
acloserlookinthedescriptionoftherow ExternalDependencies inTable2weseethatCP-Minerisdependenton CloSpan
andGabelisdependenton CodeSurfer.Giventhatbothtoolsaredependentonothersystems,theusermightcontactboth
thetoolauthorsormaychoosetoundertakefurtherstudiesonthedependenciesbyreadingthedetailsinSection 4orthe
correspondingpapersbeforecontactingthetoolauthors.Theusermightalsoreconsiderothertoolsbecauseneitherofthe
chosentwocanactuallydetectalltypesofclones.Usingourstudyandevaluationsinthispaper,onecanidentifyoptions
quicklyandwithminimaleffort.
Intention 2:Auserwantstodetectclonesfrommanysystemsindifferentlanguages.Theuserdoesnotaimtodetectalltypes
ofclonesbuttheintentionistodetectasmanytypesaspossible.Theuserisalsowillingtodosomeadaptationworkfordifferent
languagesifthetoolisreallygood.Computationalcomplexityshouldbereasonablebutneednotbeideal.
Here,theprimaryconcernoftheuseristhatthetoolshouldbeeitherlanguage-independentoradaptabletoother
languageswithareasonableamountofeffort.However,thereisatrade-offbetweentheadaptabilitytodifferentlanguages
andthequality(e.g.,capabilityofdealingwithdifferenttypesofclones)ofthetool.Theuserisalsocomfortablewith
computationallyexpensivetools,withinreason(i.e.,nottakingweeksormonthstoprocesssystems).
FromTable10wefindthattext-basedtoolsareeitherlanguage-independentoreasilyadaptabletootherlanguagesbut
thecomputationalcomplexitydependsonthealgorithmused.Token-basedtoolsareinmostcaseslanguage-dependent
(needingalexeratleast)butcomputationallyefficient.Astheconcernisadaptability(andnotthecomplexity),theuser
looksforatext-basedtool(orsetoftools)in Table14thatcoversmostofthescenarios.Suchasetoftoolsis FullNICAD
[104]andNasehi[92].Beforetakingthefinaldecisionofwhichtoolshouldbechosen,theuserneedstolookatsomedetails
ofthetools.Inparticular,theuserneedstoknowwhetherthechosentoolshaveanylanguagedependenciesornot,andin
casethereisanylanguagedependency,howmucheffortitmighttaketoadapttootherlanguages.
492 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
FromSection5weknowthatthe ProgramAnalysis facetundercategory Processinghasinformationregardinglanguage
dependencies.Twootherfacets( TransformationandCodeRepresentation )ofcategoryProcessingfurtherhintaboutthe
adaptabilityofatooltoadifferentlanguage.Fromthesub-column ProgramAnalysis ofthe9thcolumnof Table12wesee
thatbothtoolshaveattributevalue gfortheProgramAnalysis facet.Table10tellsusthatthismeansthatbothofthetools
uselanguage-dependenttransformationrules.Thuseventhoughtheyaretext-basedtechniques,theymightnotbeeasily
adaptabletootherlanguagessincetheyapplyadvancedtransformationrulesontheprogramtextbeforethecomparison.
Thesetransformationsobviouslyneedsyntactic(orsemantic)analysisofthesourcecode.
Inordertogainfurtherinsightintothetools,weexaminetheattributevaluesoftheothertwofacets, Transformationand
CodeRepresentation ,andfindthatwhileNICADusesexample-likecodenormalizationrules,whichmayeasilyporttoother
languages,Nasehiappliessemantics-preservingtransformationstoyieldanequivalentsetofatomicinstructions,whichmay
notbeaseasytoadjust.ThusNICADmayrequirelessworktoadaptthan Nasehi.
InthissituationtheusermaychooseNICADormaycompareotherattributesofthetwotoolstocometoafinaldecision.
Inparticular,theusercanexaminethe Languagefacets(LanguageParadigm andLanguageSupport )ofthetwotools.From
the5thcolumnof Table12(andtheassociatedfacet Table4)weseethatwhileNICADcanhandlebothprocedural(e.g.,C)
andobject-oriented(e.g.,Java)systems, Nasehiworksonlywithobject-orientedsystems(Java)andthus, FullNICADmaybe
abetterchoicethan Nasehiforthispurpose.Ofcourse,otherfacetattributesshouldalsobeexaminedforafinaldecision.
Alternatively,theusermaylookfortoken-basedtools.Atafirstglanceat Table14,weseethatCP-Miner[84]covers
mostoftheclonetypes/sub-scenarios.However,afterexaminingitsattributevaluesfrom Table12(andtheassociatedfacet
tables)wefindthatafull-fledgedparserisrequiredwhenitneedstobeadaptedtoadifferentlanguage,andthatitdepends
onanexternalsystem( CloSpan).Theuserthuscannotchoose CP-Miner.
Insteadofgivinguponwhichtooltochoose(thereareabout40toolsoutthere),theusercanexaminethe ProgramAnalysis
facettable(Table10)first.Thistableshowsthedifferentattributes(withdescription)oflanguagedependencyandcitations
tothecorrespondingtools.Fortunately,weseethatattribute PA.h:Needsonlyacontext-freegrammarforthelanguagedialect
ofinteresthasthreecitations,onetext-based(denotedwith T)tool,BasicNICAD[99],onetoken-based(denotedwith L),
Cordy[28],andonetree-based(denotedwith S)tool,Deckard[52].Amongthethreetools, CordyonlyworkswithHTML
pagesandthuscannotbechosenastheuserwantstofindclonesindifferentproceduralandobject-orientedsystems.
Thequestionnowremainswhethertochoosethetext-based BasicNICADorthetree-based Deckard.Theuserthenhas
toexaminewhichtoolcoversmostoftheclonetypes.From Table14weseethatDeckardcoversmoreclonetypes/sub-
scenariosthanBasicNICAD.Furthermore,eventhoughatree-basedtool, Deckardneedsonlyacontext-freegrammarto
adapttoanewlanguage. BasicNICADalsoonlyneedsacontext-freegrammar,buthastobewritteninTXL[ 27]format.Of
course,theuserhastoexaminetheotherassociatedattributevaluesofthetwotoolsbeforecomingtoaconclusion.
Thesetwoexamplesdemonstratesomeofthewayshowourstudycanbeusedtoassistinunderstandingthealternatives
whenfacedwithaneedforclonedetection.Dependingontheparticularintentions,arangeofpossibilitiesmaypresent
themselves,butusingoursummarytables,alternativescanbequicklynarroweddowntofocusontheoneortwomost
appropriatetotheapplication.
8. Related work
Althoughthereisnoworkintheliteraturethatprovidesaproperty-basedcomparisonandscenario-basedevaluationof
thetechniquesandtoolssimilartothisstudy,severaltoolcomparisonexperimentshavebeenconductedtoestimatethe
abilitiesofthetoolsintermsofprecision,recall,andtimeandspacerequirements.
OneofthefirstexperimentswasconductedbyBaileyandBurd[ 22],whocomparedthreestate-of-the-artclonedetection
andtwoplagiarismdetectiontools.Theybeganbyvalidatingalltheclonecandidatesofthesubjectapplicationobtainedwith
allthetechniquesoftheirexperimenttoformahumanoracle,whichwasthenusedtocomparethedifferenttechniquesin
termsofseveralmetricstomeasurevariousaspectsofthereportedclones.
Althoughtheywereabletoverifyalltheclonecandidates,thelimitationsofthecasestudyintermsofasinglesubject
system,modestsystemsizeandvalidationsubjectivitymaymaketheirfindingslessthandefinitive.Moreover,theintention
oftheiranalysiswastoassistinpreventativemaintenancetasks,whichmayhaveinfluencedtheirclonevalidationprocess.
ConsideringthelimitationsofBurdandBailey'sstudy,Bellonetal.setouttoconductalargertoolcomparisonexperiment
[18]onthesamethreeclonedetectiontoolsusedinBurdandBailey'sstudyandthreeadditionalclonedetectiontools.They
alsousedamorediversesetoflargersoftwaresystems,consistingoffourJavaandfourCsystemstotalingalmost850KLOC.
AsinthestudyofBurdandBailey,ahumanoraclevalidatedarandomsampleofabout2%ofthecandidateclonesfromallthe
toolsevenlyandblindly.Whiletheirstudyisthemostextensivetodate,onlyasmallproportionoftheclonecandidateswere
oracledandseveralotherfactorsmayhaveinfluencedtheresults[ 4].Bellon'sframeworkhasbeenreusedinexperiments
byKoschkeetal.[ 72,43]andDucasseetal.[ 40](partially),butwithoutanyimprovementstotheframework.
RysselbergheandDemeyer[ 106,105]haveevaluatedprototypesofthreerepresentativeclonedetectiontechniques,
providingcomparativeresultsintermsofportability,kindsofduplicationreported,scalability,numberoffalsematches,
andnumberofuselessmatches.However,theydidnotmakeareferenceset,usedrelativelysmallsubjectsystems(under10
KLOC)anddidnotprovidethereliabilityofthejudge(s)thatvalidatedthefoundclones.Moreover,ratherthanquantitative
evaluationofthedetectiontechniques,theirintentionwastodeterminethesuitabilityoftheclonedetectiontechniquesfor
aparticularmaintenancetask(refactoring)whichmighthaveinfluencedtheirclonevalidation.
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 493
AnotherinterestingstudyhasbeenconductedbyBruntinketal.[ 19],inwhichseveralclonedetectiontechniquesare
evaluatedintermsoffindingknowncross-cuttingconcernsinCprogramswithhomogeneousimplementations.
9. Conclusion
Inthispaper,wehavefocusedonclonedetectiontechniquesandtools,providingaconcisebutcomprehensivesurvey
andahypotheticalevaluationbasedoneditingscenarios.Amoredetailedreviewoftheentirerangeofclonedetection
researchcanbefoundinourtechnicalreport[ 102].Koschke'sDagstuhlreport[ 73]andthecorrespondingbookchapter[ 70]
alsoprovideanexcellentbriefoverview.
Wehopethattheresultsofthisstudymayassistnewpotentialusersofclonedetectiontechniquesinunderstanding
therangeofavailabletechniquesandtoolsandselectingthosemostappropriatefortheirneeds.Wehopeitmayalsoassist
inidentifyingremainingopenresearchquestions,avenuesforfutureresearch,andinterestingcombinationsoftechniques.
Theevaluationresultsofthispaperarebasedonestimatingtheperformanceoftechniquesusingthemostlenientvaluesof
alltunableparameters,andthusourfindingsdifferfromtheresultsofempiricalstudiessuchasBellonetal.[ 18].
Whileinthisstudyourgoalwaspredictiveratherthanempirical,wearecurrentlyundertakinganexperimentusingour
editingscenariosasthebasisforgeneratingandinjectingthousandsofartificialmutantswhichcanbeusedtoempirically
compareactualtoolsonasimilarbasis[ 98,101].
Acknowledgements
Wethanktheanonymousreviewersfortheirvaluablecommentsandsuggestionsinimprovingthispaper.Wealsothank
thetoolauthorswhoprovidedusefulanswerstoourqueries,andthecolleagueswhoassistedintuningandclarifying
thispaper.ThisworkissupportedbytheNaturalSciencesandEngineeringResearchCouncilofCanadaandbyanIBM
internationalfacultyaward.
References
[1]G.Antoniol,G.Casazza,M.DiPenta,E.Merlo,Modelingclonesevolutionthroughtimeseries,in:Proceedingsofthe17thIEEEInternationalConference
onSoftwareMaintenance,ICSM2001,2001,pp.273280.
[2]G.Antoniol,U.Villano,E.Merlo,M.D.Penta,Analyzingcloningevolutioninthelinuxkernel,InformationandSoftwareTechnology44(13)(2002)
755765.
[3]L.Aversano,L.Cerulo,M.DiPenta,Howclonesaremaintained:Anempiricalstudy,in:Proceedingsofthe11thEuropeanConferenceonSoftware
MaintenanceandReengineering,CSMR2007,2007,pp.8190.
[4]B.Baker,Findingcloneswithdup:Analysisofanexperiment,IEEETransactionsonSoftwareEngineering33(9)(2007)608621.
[5]B.Baker,U.Manber,DeducingsimilaritiesinJavasourcesfrombytecodes,in:ProceedingsoftheUSENIXAnnualTechnicalConference,1998,pp.
179190.
[6]B.Baker,Aprogramforidentifyingduplicatedcode,in:ProceedingsofComputingScienceandStatistics:24thSymposiumontheInterface,vol.24,
1992,pp.4957.
[7]B.Baker,Parameterizedpatternmatching:Algorithmsandapplications,JournalComputerSystemScience52(1)(1996)2842.
[8]B.Baker,Onfindingduplicationandnear-duplicationinlargesoftwaresystems,in:Proceedingsofthe2ndWorkingConferenceonReverse
Engineering,WCRE1995,1995,pp.8695.
[9]B.Baker,R.Giancarlo,Sparsedynamicprogrammingforlongestcommonsubsequencefromfragments,JournalAlgorithms42(2)(2002)231254.
[10]M.Balazinska,E.Merlo,M.Dagenais,B.Lague,K.Kontogiannis,Measuringclonebasedreengineeringopportunities,in:ProceedingsoftheIEEE
SymposiumonSoftwareMetrics,METRICS1999,1999,pp.292303.
[11]M.Balint,T.Girba,R.Marinescu,Howdeveloperscopy,in:Proceedingsofthe14thIEEEInternationalConferenceonProgramComprehension,ICPC
2006,2006,pp.5668.
[12]H.Basit,S.Pugliesi,W.Smyth,A.Turpin,S.Jarzabek,Efficienttokenbasedclonedetectionwithflexibletokenization,in:Proceedingsofthe6th
EuropeanSoftwareEngineeringConferenceandFoundationsofSoftwareEngineering,ESEC/FSE2007,2007,pp.513515.
[13]I.D.Baxter,C.Pidgeon,M.Mehlich,DMS:Programtransformationsforpracticalscalablesoftwareevolution,in:Proceedingsofthe26thInternational
ConferenceonSoftwareEngineering,ICSE2004,2004,pp.625634.
[14]ProjectBauhaus.LastAccessedNovember2008.URL http://www.bauhaus-stuttgart.de .
[15]I.Baxter,A.Yahin,L.Moura,M.Anna,Clonedetectionusingabstractsyntaxtrees,in:Proceedingsofthe14thInternationalConferenceonSoftware
Maintenance,ICSM1998,1998,pp.368377.
[16]S.Bellon,Vergleichvontechnikenzurerkennungdupliziertenquellcodes,DiplomaThesis,UniversityofStuttgart,2002.
[17]S.Bellon,R.Koschke,Detectionofsoftwareclone:Toolcomparisonexperiment,December2007. http://www.bauhaus-stuttgart.de/clones/ .
[18]S.Bellon,R.Koschke,G.Antoniol,J.Krinke,E.Merlo,Comparisonandevaluationofclonedetectiontools,TransactionsonSoftwareEngineering33
(9)(2007)577591.
[19]M.Bruntink,A.Deursen,R.Engelen,T.Tourwe,Ontheuseofclonedetectionforidentifyingcrosscuttingconcerncode,TransactionsonSoftware
Engineering31(10)(2005)804818.
[20]P.Bulychev,M.Minea,Duplicatecodedetectionusinganti-unification,in:SpringYoungResearchersColloquiumonSoftwareEngineering,SYRCoSE
2008,2008,p.4.
[21]P.Bulychev,CloneDiggerResults.LastAccessedFebruary2009. http://clonedigger.sourceforge.net/ .
[22]E.Burd,J.Bailey,Evaluatingclonedetectiontoolsforuseduringpreventativemaintenance,in:Proceedingsofthe2ndIEEEInternationalWorkshop
onSourceCodeAnalysisandManipulation,SCAM2002,2002,pp.3643.
[23]F.Calefato,F.Lanubile,T.Mallardo,Functionclonedetectioninwebapplications:Asemiautomatedapproach,JournalofWebEngineering3(1)
(2004)321.
[24]G.Casazza,G.Antoniol,U.Villano,E.Merlo,M.Penta,Identifyingclonesinthelinuxkernel,in:Proceedingsofthe1stIEEEInternationalWorkshop
onSourceCodeAnalysisandManipulation,SCAM2001,2001,pp.9097.
[25]K.Church,J.Helfman,Dotplot:Aprogramforexploringself-similarityinmillionsoflinesfortextandcode,JournalofAmericanStatisticalAssociation
2(2)(1993)153174.
494 C.K.Royetal./ScienceofComputerProgramming74(2009)470495
[26]K.Cooper,N.McIntosh,Enhancedcodecompressionforembeddedriscprocessors,in:ProceedingsoftheACMSIGPLAN1999Conferenceon
ProgrammingLanguageDesignandImplementation,SIGPLANPLDI1999,1999,pp.139149.
[27]J.R.Cordy,TheTXLsourcetransformationlanguage,ScienceofComputerProgramming61(3)(2006)190210.
[28]J.R.Cordy,T.R.Dean,N.Synytskyy,Practicallanguage-independentdetectionofnear-missclones,in:Proceedingsofthe14thIBMCentreforAdvanced
StudiesConference,CASCON2004,2004,pp.2940.
[29]PMD'sCPD.LastAccessedNovember2008.URL http://pmd.sourceforge.net/cpd.html .
[30]M.Dagenais,E.Merlo,B.Laguë,DanielProulx,Clonesoccurrenceinlargeobjectorientedsoftwarepackages,in:Proceedingsofthe8thIBMCentre
forAdvancedStudiesConference,CASCON1998,1998,pp.192200.
[31]N.Davey,P.Barson,S.Field,R.Frank,Thedevelopmentofasoftwareclonedetector,InternationalJournalofAppliedSoftwareTechnology1(3/4)
(1995)219236.
[32]S.K.Debray,W.Evans,R.Muth,B.DeSutter,Compilertechniquesforcodecompaction,ACMTransactionsonProgrammingLanguagesandSystems
22(2)(2000)378415.
[33]F.Deissenboeck,B.Hummel,E.Juergens,B.Schaetz,S.Wagner,S.Teuchert,J.Girard,Clonedetectioninautomotivemodel-baseddevelopment,in:
Proceedingsofthe30thInternationalConferenceonSoftwareEngineering,ICSE2008,2008,pp.603612.
[34]B.DeSutter,B.DeBus,K.DeBosschere,Siftingoutthemud:LowlevelC++codereuse,in:Proceedingsofthe17thACMSIGPLANConferenceon
Object-OrientedProgramming,Systems,Languages,andApplications,OOPSLA2002,2002,pp.275291.
[35]A.DeLucia,R.Francese,G.Scanniello,G.Tortora,Understandingclonedpatternsinwebapplications,in:Proceedingsofthe13thInternational
WorkshoponProgramComprehension,IWPC2005,2005,pp.333336.
[36]G.A.DiLucca,M.DiPenta,A.R.Fasolino,P.Granato,Cloneanalysisinthewebera:Anapproachtoidentifyclonedwebpages,in:Proceedingsofthe
7thIEEEWorkshoponEmpiricalStudiesofSoftwareMaintenance,WESS2009,2001,pp.107113.
[37]ToolCloneDetective(PartofConQAT).LastAccessedNovember2008.URL http://conqat.in.tum.de/index.php/Main_Page .
[38]G.DiLucca,M.Penta,A.Fasolino,Anapproachtoidentifyduplicatedwebpages,in:Proceedingsofthe26thInternationalComputerSoftwareand
ApplicationsConference,COMPSAC2002,2002,pp.481486.
[39]ToolDupman.LastAccessedNovember2008.URL http://sourceforge.net/projects/dupman .
[40]S.Ducasse,O.Nierstrasz,M.Rieger,Ontheeffectivenessofclonedetectionbystringmatching,InternationalJournalonSoftwareMaintenanceand
Evolution:ResearchandPractice18(1)(2006)3758.
[41]S.Ducasse,M.Rieger,S.Demeyer,Alanguageindependentapproachfordetectingduplicatedcode,in:Proceedingsofthe15thInternational
ConferenceonSoftwareMaintenance,ICSM1999,1999,pp.109118.
[42]W.Evans,C.Fraser,M.Fei,Clonedetectionviastructuralabstraction,in:Proceedingsofthe14thWorkingConferenceonReverseEngineering,WCRE
2007,2007,pp.150159.
[43]R.Falke,R.Koschke,P.Frenzel,Empiricalevaluationofclonedetectionusingsyntaxsuffixtrees,EmpiricalSoftwareEngineering13(2008)601643.
[44]M.Fowler,Refactoring:ImprovingtheDesignofExistingCode,Addison-Wesley,2000.
[45]C.Fraser,E.Myers,A.Wendt,Analyzingandcompressingassemblycode,in:ProceedingsoftheACMSIGPLAN'84SymposiumonCompiler
Construction,1984,pp.117121.
[46]M.Gabel,L.Jiang,Z.Su,Scalabledetectionofsemanticclones,in:Proceedingsofthe30thInternationalConferenceonSoftwareEngineering,ICSE
2008,2008,pp.321330.
[47]D.Gitchell,N.Tran,Sim:Autilityfordetectingsimilarityincomputerprograms,SIGCSEBulletin31(1)(1999)266270.
[48]N.Göde,Incrementalclonedetection,DiplomaThesis,DepartmentofMathematicsandComputerScience,UniversityofBremen,Germany,2008.
[49]J.Guo,Y.Zou,Detectingclonesinbusinessapplications,in:Proceedingsofthe15thWorkingConferenceonReverseEngineering,WCRE2008,2008,
pp.91100.
[50]Y.Higo,Y.Ueda,T.Kamiya,S.Kusumoto,K.Inoue,Onsoftwaremaintenanceprocessimprovementbasedoncodecloneanalysis,in:Proceedingsof
the4thInternationalConferenceonProductFocusedSoftwareProcessImprovement,PROFES2002,2002,pp.185197.
[51]P.Jablonski,D.Hou,CReN:Atoolfortrackingcopy-and-pastecodeclonesandrenamingidentifiersconsistentlyintheIDE,in:ProceedingsofEclipse
TechnologyExchangeWorkshopatOOPSLA2007,2007,pp.1620.
[52]L.Jiang,G.Misherghi,Z.Su,S.Glondu,DECKARD:Scalableandaccuratetree-baseddetectionofcodeclones,in:Proceedingsofthe29thInternational
ConferenceonSoftwareEngineering,ICSE2007,2007,pp.96105.
[53]J.Johnson,Identifyingredundancyinsourcecodeusingfingerprints,in:Proceedingsofthe1993ConferenceoftheCentreforAdvancedStudieson
CollaborativeResearch,CASCON1993,1993,pp.171183.
[54]J.Johnson,Visualizingtextualredundancyinlegacysource,in:Proceedingsofthe1994ConferenceoftheCentreforAdvancedStudieson
Collaborativeresearch,CASCON2004,1994,pp.171183.
[55]J. Johnson, Substring matching for clone detection and change tracking, in: Proceedings of the 10th International Conference on Software
Maintenance,ICSM1994,1994,pp.120126.
[56]E.Juergens,F.Deissenboeck,B.Hummel,S.Wagner,Docodeclonesmatter?,in:Proceedingsofthe31stInternationalConferenceonSoftware
Engineering,ICSE2009,2009,p.11(inpress).
[57]N.Juillerat,B.Hirsbrunner,Analgorithmfordetectingandremovingclonesinjavacode,in:Proceedingsofthe3rdWorkshoponSoftwareEvolution
throughTransformations:EmbracingtheChange,SeTra2006,2006,pp.6374.
[58]T.Kamiya,TheOfficialCCFinderXWebsite.LastAccessedNovember2008.URL http://www.ccfinder.net/ccfinderx.html .
[59]T.Kamiya,S.Kusumoto,K.Inoue,CCFinder:Amultilinguistictoken-basedcodeclonedetectionsystemforlargescalesourcecode,IEEETransactions
onSoftwareEngineering28(7)(2002)654670.
[60]C.Kapser,M.Godfrey,Aidingcomprehensionofcloningthroughcategorization,in:Proceedingsofthe7thInternationalWorkshoponPrinciplesof
SoftwareEvolution,IWPSE2004,2004,pp.8594.
[61]CoryKapser,MichaelW.Godfrey,Cloningconsideredharmfulconsideredharmful:Patternsofcloninginsoftware,EmpiricalSoftwareEngineering
13(6)(2008)645692.
[62]H.M.Kienle,H.A.Müller,A.Weber,Inthewebofgeneratedclones,in:Proceedingsof2ndInternationalWorkshoponDetectionofSoftwareClones,
IWDSC2003,2003,p.2.
[63]M.Kim,L.Bergman,T.Lau,D.Notkin,AnethnographicstudyofcopyandpasteprogrammingpracticesinOOPL,in:Proceedingsof3rdInternational
ACMIEEESymposiumonEmpiricalSoftwareEngineering,ISESE2004,2004,pp.8392.
[64]M.Kim,G.Murphy,Anempiricalstudyofcodeclonegenealogies,in:Proceedingsofthe10thEuropeanSoftwareEngineeringConferenceHeldJointly
with13thACMSIGSOFTInternationalSymposiumonFoundationsofSoftwareEngineering,ESEC/SIGSOFTFSE2005,2005,pp.187196.
[65]R.Komondoor,S.Horwitz,Usingslicingtoidentifyduplicationinsourcecode,in:Proceedingsofthe8thInternationalSymposiumonStaticAnalysis,
SAS2001,2001,pp.4056.
[66]K.Kontogiannis,R.DeMori,E.Merlo,M.Galler,M.Bernstein,Patternmatchingforcloneandconceptdetection,JournalofAutomatedSoftware
Engineering3(12)(1996)77108.
[67]K.Kontogiannis,Evaluationexperimentsonthedetectionofprogrammingpatternsusingsoftwaremetrics,in:Proceedingsofthe3rdWorking
ConferenceonReverseEngineering,WCRE1997,1997,pp.4454.
[68]S.RaoKosaraju,Fasteralgorithmsfortheconstructionofparameterizedsuffixtrees,in:Proceedingsofthe36thAnnualSymposiumonFoundations
ofComputerScience,FOCS1995,1995,pp.631638.
[69]R.Koschke,Frontiersonsoftwareclonemanagement,in:ProceedingsoftheFrontiersofSoftwareMaintenance,24thIEEEInternationalConference
inSoftwareMaintenance,ICSM2008,2008,pp.119128.
[70]R.Koschke,Identifyingandremovingsoftwareclones,in:SergeDe-meyer,TomMens(Eds.),SoftwareEvolution,SpringerVerlag,2008,pp.1539.
C.K.Royetal./ScienceofComputerProgramming74(2009)470495 495
[71]R.Koschke,J.-F.Girard,M.Wrthner,Anintermediaterepresentationforreverseengineeringanalyzes,in:Proceedingsofthe5thWorkingConference
onReverseEngineering,WCRE1998,1998,pp.241250.
[72]R.Koschke,R.Falke,P.Frenzel,Clonedetectionusingabstractsyntaxsuffixtrees,in:Proceedingsofthe13thWorkingConferenceonReverse
Engineering,WCRE2006,2006,pp.253262.
[73]R.Koschke,Surveyofresearchonsoftwareclones,in:ProceedingsofDagstuhlSeminar06301:Duplication,Redundancy,andSimilarityinSoftware,
2006,p.24.
[74]N.Kraft,B.Bonds,R.Smith,Cross-languageclonedetection,in:Proceedingsofthe20thInternationalConferenceonSoftwareEngineeringand
KnowledgeEngineering,SEKE2008,2008,p.6.
[75]J.Krinke,Identifyingsimilarcodewithprogramdependencegraphs,in:Proceedingsofthe8thWorkingConferenceonReverseEngineering,WCRE
2001,2001,pp.301309.
[76]I.Landwerth,CloneDetective.LastAccessedNovember2008.URL http://www.codeplex.com/CloneDetectiveVS .
[77]F.Lanubile,T.Mallardo,Findingfunctionclonesinwebapplications,in:Proceedingsofthe7thEuropeanConferenceonSoftwareMaintenanceand
Reengineering,CSMR2003,2003,pp.379386.
[78]S.Lee,I.Jeong,SDD:Highperformancecodeclonedetectionsystemforlargescalesourcecode,in:ProceedingsoftheObjectOrientedProgramming
Systems Languages and Applications Companion to the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems,
Languages,andApplications,OOPSLACompanion2005,2005,pp.140141.
[79]A.Leitão,Detectionofredundantcodeusing R2D2,SoftwareQualityJournal12(4)(2004)361382.
[80]H.Li,S.Thompson,Clonedetectionandremovalforerlang/OTPwithinarefactoringenvironment,in:ACM/SIGPLANWorkshopPartialEvaluation
andSemantics-BasedProgramManipulation,Proceedingsofthe2009ACMSIGPLANWorkshoponPartialEvaluationandProgramManipulation,
2009,pp.169178.
[81]C.Liu,C.Chen,J.Han,P.Yu,GPLAG:Detectionofsoftwareplagiarismbyprogramdependencegraphanalysis,in:Proceedingsofthe12thACM
SIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,KDD2006,2006,pp.872881.
[82]H.Liu,Z.Ma,L.Zhang,W.Shao,Detectingduplicationsinsequencediagramsbasedonsuffixtrees,in:Proceedingsofthe13thAsiaPacificSoftware
EngineeringConference,APSEC2006,2006,pp.269276.
[83]S.Livieri,Y.Higo,M.Matsushita,K.Inoue,Very-largescalecodecloneanalysisandvisualizationofopensourceprogramsusingdistributedCCFinder,
in:Proceedingsof29thInternationalConferenceonSoftwareEngineering,ICSE2007,2007,pp.106115.
[84]Z.Li,S.Lu,S.Myagmar,Y.Zhou,CP-Miner:Findingcopy-pasteandrelatedbugsinlarge-scalesoftwarecode,IEEETransactionsonSoftware
Engineering32(3)(2006)176192.
[85]U.Manber,Findingsimilarfilesinalargefilesystem,in:ProceedingsoftheWinter1994UsenixTechnicalConference,1994,pp.110.
[86]A.Marcus,J.Maletic,Identificationofhigh-levelconceptclonesinsourcecode,in:Proceedingsofthe16thIEEEInternationalConferenceon
AutomatedSoftwareEngineering,ASE2001,2001,pp.107114.
[87]J.Mayrand,C.Leblanc,E.Merlo,Experimentontheautomaticdetectionoffunctionclonesinasoftwaresystemusingmetrics,in:Proceedingsofthe
12thInternationalConferenceonSoftwareMaintenance,ICSM1996,1996,pp.244253.
[88]E.McCreight,ASpace-economicalsuffixtreeconstructionalgorithm,JournaloftheACM32(2)(1976)262272.
[89]E.Merlo,M.Dagenais,P.Bachand,J.S.Sormani,S.Gradara,G.Antoniol,Investigatinglargesoftwaresystemevolution:Thelinuxkernel,in:
Proceedingsofthe26thInternationalComputerSoftwareandApplicationsConference,COMPSAC2002,2002,pp.421426.
[90]E.Merlo,G.Antoniol,M.Penta,V.Rollo,Linearcomplexityobject-orientedsimilarityforclonedetectionandsoftwareevolutionanalyses,in:
Proceedingsofthe20thInternationalConferenceConferenceonSoftwareMaintenance,ICSM2004,2004,pp.412416.
[91]L.Moonen,Generatingrobustparsersusingislandgrammars,in:Proceedingsofthe8thWorkingConferenceonReverseEngineering,WCRE2001,
2001,pp.1322.
[92]S.Nasehi,G.Sotudeh,M.Gomrokchi,Sourcecodeenhancementusingreductionofduplicatedcode,in:Proceedingsofthe25thconferenceonIASTED
InternationalMulti-Conference:SoftwareEngineering,IASTEDSE2007,2007,pp.192197.
[93]J.Patenaude,E.Merlo,M.Dagenais,B.Lague,Extendingsoftwarequalityassessmenttechniquestojavasystems,in:Proceedingsofthe7th
InternationalWorkshoponProgramComprehension,IWPC1999,1999,pp.4956.
[94]D.Rajapakse,S.Jarzabek,Usingserverpagestounifyclonesinwebapplications:Atrade-offanalysis,in:Proceedingsofthe29thInternational
ConferenceofSoftwareEngineering,ICSE2007,2007,pp.116126.
[95]F.Ricca,P.Tonella,Usingclusteringtosupportthemigrationfromstatictodynamicwebpages,in:Proceedingsofthe11thInternationalWorkshop
onProgramComprehension,IWPC2003,2003,pp.207216.
[96]M.Rieger,Effectiveclonedetectionwithoutlanguagebarriers,Ph.D.Thesis,UniversityofBern,Switzerland,2005.
[97]C.K.Roy,J.R.Cordy,Near-Missfunctionclonesinopensourcesoftware:Anempiricalstudy,JournalofSoftwareMaintenanceandEvolution:Research
andPractice(2009)23(specialissueonWCRE'08)(submittedforpublication).
[98]C.K.Roy,J.R.Cordy,Amutation/injection-basedautomaticframeworkforevaluatingclonedetectiontools,in:Proceedingsofthe4thInternational
WorkshoponMutationAnalysis,Mutation2009,2009,p.10(inpress).
[99]C.K.Roy,J.R.Cordy,Anempiricalstudyoffunctionclonesinopensourcesoftwaresystems,in:Proceedingsofthe15thWorkingConferenceon
ReverseEngineering,WCRE2008,2008,pp.8190.
[100]C.K.Roy,J.R.Cordy,WCRE'08Clones.LastAccessedNovember2008. http://www.cs.queensu.ca/home/stl/download/NICADOutput/ .
[101]C.K.Roy,J.R.Cordy,Towardsamutation-basedautomaticframeworkforevaluatingclonedetectiontools,in:ProceedingsoftheCanadianConference
onComputerScienceandSoftwareEngineering,C3S2E2008,2008,pp.137140.
[102]C.K.Roy,J.R.Cordy,Asurveyonsoftwareclonedetectionresearch,Queen'sTechnicalReport:541,2007,p.115.
[103]C.K.Roy,J.R.Cordy,Scenario-basedcomparisonofclonedetectiontechniques,in:Proceedingsofthe16thIEEEInternationalConferenceonProgram
Comprehension,ICPC2008,2008,pp.153162.
[104]C.K.Roy,J.R.Cordy,NICAD:Accuratedetectionofnear-missintentionalclonesusingflexiblepretty-printingandcodenormalization,in:Proceedings
ofthe16thIEEEInternationalConferenceonProgramComprehension,ICPC2008,2008,pp.172181.
[105]F.Rysselberghe,S.Demeyer,Evaluatingclonedetectiontechniques,in:ProceedingsoftheInternationalWorkshoponEvolutionofLargeScale
IndustrialApplications,ELISA2003,2003,p.12.
[106]F.Rysselberghe,S.Demeyer,Evaluatingclonedetectiontechniquesfromarefactoringperspective,in:Proceedingsofthe9thIEEEInternational
ConferenceAutomatedSoftwareEngineering,ASE2004,2004,pp.336339.
[107]ToolSimian.LastAccessedNovember2008.URL http://www.redhillconsulting.com.au/products/simian/ .
[108]ToolSimScan.LastAccessedNovember2008.URL http://www.blue-edge.bg/simscan/ .
[109]T.Sager,A.Bernstein,M.Pinzger,C.Keifer,DetectingsimilarJavaclassesusingtreealgorithms,in:Proceedingsofthe2006InternationalWorkshop
onMiningSoftwareRepositories,MSR2006,2006,pp.6571.
[110]N.Synytskyy,J.R.Cordy,T.R.Dean,Resolutionofstaticclonesindynamicwebpage,in:Proceedingsofthe5thIEEEInternationalWorkshoponWeb
SiteEvolution,WSE2003,2003,pp.4958.
[111]R.Tairas,J.Gray,Phoenix-basedclonedetectionusingsuffixtrees,in:Proceedingsofthe44thAnnualSoutheastRegionalConference,ACM-SE2006,
2006,pp.679684.
[112]Y.Ueda,T.Kamiya,S.Kusumoto,K.Inoue,Ondetectionofgappedcodeclonesusinggaplocations,in:Proceedings9thAsia-PacificSoftware
EngineeringConference,APSEC2002,2002,pp.327336.
[113]V.Wahler,D.Seipel,J.Gudenberg,G.Fischer,Clonedetectioninsourcecodebyfrequentitemsettechniques,in:Proceedingsofthe4thIEEE
InternationalWorkshopSourceCodeAnalysisandManipulation,SCAM2004,2004,pp.128135.
[114]R.Wettel,R.Marinescu,Archeologyofcodeduplication:Recoveringduplicationchainsfromsmallduplicationfragments,in:Proceedingsofthe7th
InternationalSymposiumonSymbolicandNumericAlgorithmsforScientificComputing,SYNASC2005,2005,p.8.
[115]T.Yamashina,H.Uwano,K.Fushida,Y.Kamei,M.Nagura,S.Kawaguchi,H.Iida,SHINOBI:Areal-timecodeclonedetectiontoolforsoftware
maintenance,TechnicalReport:NAIST-IS-TR2007011,GraduateSchoolofInformationScience,NaraInstituteofScienceandTechnology,2008.
[116]W.Yang,Identifyingsyntacticdifferencesbetweentwoprograms,SoftwarePracticeandExperience21(7)(1991)739755.


UvA-DARE is a service provided by the library of the University of Amsterdam (http s://dare.uva.nl)
UvA-DARE (Digital Academic Repository)
Detecting Refactorable Clones by Slicing Program Dependence Graphs
Hamid, A.; Zaytsev, V.
Publication date
2015
Document Version
Final published version
Published in
Post-proceedings of the Seventh Seminar on Advanced Techniques and Tools for Software
Evolution
License
CC0
Link to publication
Citation for published version (APA):
Hamid, A., & Zaytsev, V. (2015). Detecting Refactorable Clones by Slicing Program
Dependence Graphs. In D. Di Ruscio, & V. Zaytsev (Eds.), Post-proceedings of the Seventh 
Seminar on Advanced Techniques and Tools for Software Evolution: L’Aquila, Italy, 9–11 July 
2014 (pp. 37-48). (CEUR Workshop Proceedings; Vol. 1354). CEUR-WS. http://ceur- 
ws.org/Vol-1354/paper-04.pdf
General rights
It is not permitted to download or to forward/distribute the text or part of it without the consent of the author(s)
and/or copyright holder(s), other than for strictly personal, individual use, unless the work is under an open
content license (like Creative Commons).
Disclaimer/Complaints regulations
If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please
let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material
inaccessible and/or remove it from the website. Please Ask the Library: https://uba.uva.nl/en/contact, or a letter
to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You
will be contacted as soon as possible.
Download date:26 Nov 2025
Detecting Refactorable Clones by Slicing
Program Dependence Graphs
Ammar Hamid1and Vadim Zaytsev2
1ammarhamid84@gmail.com
2vadim@grammarware.net
Institute of Informatics, University of Amsterdam, The Netherlands
Abstract. Code duplication in a program can make understanding and
maintenance dicult. The problem can be reduced by detecting dupli-
cated code, refactoring it into a separate procedure, and replacing all the
clones by appropriate calls to the new procedure. In this paper, we re-
port on a conrmatory replication of a tool that was used to detect such
refactorable clones based on program dependence graphs and program
slicing.
1 Motivation
With the discussion about the extent to which code clones are harmful for soft-
ware readability, maintainability and ultimately quality, still ongoing, there is
still signicant evidence on cost increases being caused by code duplication in
at least some scenarios [5,18]. For simplicity, we intend to adopt that view and
look a step further. Once clones are identied, ideally we would like to provide
advanced support for programmers or maintenance engineers to remove them
| that is, to use refactorings [4] to \de-clone" source code by merging identical
code fragments and parametrising similar ones [17].
The sheer number of code clone detection techniques and tools is immensely
overwhelming [15,16,13]. In section 2, we will give a very brief overview of the
eld and explain terminology needed to understand the rest of the paper. One
of the promising family of methods which is not too complex for a nal Master's
project yet also not too much of a beaten track in code clone research, is graph-
based . Given two programs, we automatically build a graph-like structure with
known properties, employ some slicing and/or matching and based on that can
diagnose them with duplication.
Eventually we have converged to a relatively well-known paper of Ragha-
van Komondoor and Susan Horwitz [8] and dedicated ourselves to replicating it.
Some details about that project can be found in section 3, but in general they
propose to use program dependence graphs [11] (PDG) and program slicing [19].
The authors of the original study were able to nd isomorphic subgraphs of
the PDG by implementing a program slicing technique using a combination of
backward slicing and forward slicing. Basically they search for sets of syntacti-
cally equivalent node pairs and perform backward slicing from each pair with a
single forward slicing pass for matching predicates nodes. The theoretical foun-
dation behind this method mostly lies in plan calculus [14] and an advanced
graph partitioning algorithm [6,7] and essentially allows to detect clones seman-
tically, regardless of various refactorings that may have been applied to some of
the copies but not to others. This leads to reporting only those clones that can
indeed be refactored | as we show on Table 1.
We modied the original study in several ways: some were forced upon us by
technicalities, for others we had our own reasons | all explained in section 4.
We report our results, compare them to the original study and try to explain
the dierences in section 5 and conclude the paper with section 6.
2 Background
Several studies show that 7{23% of the source code for large programs is du-
plicated code [2,9]. Within a project, code duplication will increase code size,
and make maintenance dicult. Fixing a bug within a project with a lot of du-
plicated code is becoming a challenge because it is necessary to make sure that
the x is applied to all of the duplicated instances. Lague et al [10] studied the
development of a large software system over multiple releases and found that
programmers often missed some copies of the duplicated code when performing
modication. Similar results have been observed by Geiger et al [5] and Thum-
malapenta et al [18] who observe the already expected negative impact of clone
co-evolution on software maintenance eort.
In code duplication studies we usually distinguish among the following types
of clones [13,15]:
{Exact clones (type 1) | identical duplicates with some variations allowed
in whitespace and comments;
{Parametrised clones (type 2) | variations are allowed in identier names,
literals, even variable types;
{Near miss clones (type 3) | statements are allowed to be changed, added
or removed up to some extent;
{Semantic clones (type 4) | same computation with a dierent syntax and
possibly even dierent algorithms;
{Structural clones | higher level similarities, conceptually bottom-up-detected
implementation patterns;
{Artefact clones | function clones and le clones;
{Model clones | duplicates over artefacts other than code;
{Contextual clones | code fragments deemed duplicate due to their usage
patterns.
Out of these, type 2 and type 3 are the most well-researched ones, with model
clones quickly getting more and more attention every year.
Techniques and tools can be roughly classied into these groups [13,16] (in
the parenthesis we show a software artefact category in the terms of parsing-in-
a-broad-sense megamodel [20]):
Procedure 1 Rewritten Procedure 1
int foo(void) { int foo(void) {
++ int i = 1; bool w = false;
bool z = true; int t = 10;
int t = 10; ** return new_procedure_bar();
++ int j = i + 1; }
++ int n;
++ for (n=0; n<10; n++) {
++ j = j + 5;
}
++ int k = i + j - 1;
return k;
}
Procedure 2 Rewritten Procedure 2
int bar(void) { int bar(void) {
++ int i = 1; bool w = false;
bool w = false; int t = 10;
int t = 10; ** return new_procedure_bar();
++ int s; }
++ int b = a + 1;
++ for (s=0; s<10; s++) {
++ b = b + 5;
}
++ int c = a + b - 1;
return c;
}
Newly extracted procedure:
int new_procedure_bar(void) {
++ int i = 1;
++ int j = i + 1;
++ int n;
++ for (n=0; n<10; n++) {
++ j = j + 5;
}
++ int k = i + j - 1;
return k;
}
Table 1. Two functions with duplicated code and a refactoring result. In the left col-
umn, the duplicated code is marked with ++; in the right column clones are replaced
with calls to a newly extracted function. This example demonstrates that not every-
thing that has the same structure or the same syntax is reported as clones (e.g. int t
= 10; which has no shared predecessor).
{Text based (Str) such as Simian | blazingly fast methods usually looking for
exact clones, quite often in a language-independent, -parametric or -agnostic
manner;
{Token based (TTk,Lex) such as CCFinder | somewhat more sophisticated
lexical tools;
{Tree based (Ptr,Cst,Ast) such as Deckard | looking for clones in parse
trees, sux trees or abstract syntax trees;
{Graph based (Ast,Dia) such as Duplix | making decisions based on control
ow graphs, data dependency graphs, program dependence graphs or partite
sets and vertices;
{Model based (Dia) such as ConQAT | metamodel-specic representation,
usually graph-like;
{Metrics based such as Covet | using metrics, ngerprinting and/or clus-
tering to work on text or ASTs;
{Hybrid such as CloneMiner | independent component analysis, some vari-
ants of semantic indexing and longest subsequence methods that require
reasoning over trees, memory states, vector spaces, etc.
Following the original paper [8], we use CodeSurfer3, a commercial tool that
can be used to generate program dependence graphs (PDGs) from C programs.
It provides an API that can be used from Scheme programs [1]. In general, PDG
nodes represent program statements and predicates, while PDG edges repre-
sent data and control dependencies. PDG provides an abstraction that ignores
arbitrary sequencing choices made by a programmer, and instead captures the
important dependences among program components. Essentially, a program de-
pendence graph is built starting from a control ow graph (CFG) with statements
as nodes and possible transitions among them as edges, which is then analysed
for dominance to form an acyclic post-dominator graph | the two are merged
into a control dependence graph. A program dependence graph is formed from
the control dependence graph by enhancing it with additional edges for all data
dependencies, an example is given on Figure 1. The resulting complex struc-
ture is graph-like with nodes of several kinds (regions, statements, entry/exit
points) and edges of several kinds (data/control dominance, possibly labelled)
| there are algorithmic variations which are not important for understanding
the current paper. Such a PDG is remarkable in a sense that it captures many
structural aspects of a program and still allows to abstract from concrete details
such as variable names and precise positioning of the code. For a larger/smaller
scale, related methods are used such as system dependence graphs (SDGs) or
execution dependence graphs (EDGs) [12].
The last bit of background needed for understanding this paper is program
slicing [19,3], which is a well-known technique for obtaining a \view" of a pro-
gram with only those statements that are relevant for the chosen variable. In
terms of PDG we can have two query types in program slicing [7]. Backward
slicing from node xmeans nding all the nodes that inuence the value of node
3CodeSurfer, http://www.grammatech.com/research/technologies/codesurfer .
Fig. 1. A tiny code fragment demonstrating the concept of a program dependence
graph: the listing on the left; the corresponding PDG fragment on the right (only
data dependencies for sum are shown, the complete graph is much bigger and more
cluttered) [21].
x.Forward slicing from node ymeans nding all the nodes that are inuenced
by node y. This is an important technique to lter out any statements that are
irrelevant for clone detection.
3 Original study
The main research question asked by Komondoor and Horwitz is the following:
can we nd code clones of type 3 (non-contiguous, reordered, intertwined), which
are refactorable into new procedures? [8]
3.1 Approach
To detect clones in a program, we represent each procedure using its PDG. In
PDG, vertex represents program statement or predicate, and edge represents
data or control dependences. The algorithm performs four steps (described in
the following subsections):
{Step 1: Find relevant procedures
{Step 2: Find pair of vertices with equivalent syntactic structure
{Step 3: Find clones
{Step 4: Group clones
Find relevant procedures. We are only interested in nding clones for
procedures that are reachable from the main program execution. Only then we
can safely remove unreachable procedures from our program and just not detect
clones of them. We do this by getting a system initialisation vertex and forward-
slicing with data and control ow. This will return all PDGs (including user
dened and system PDGs) that are reachable from the main program execution.
From that result, we further lter those PDGs to nd only the user dened ones,
ignoring system libraries.
Find pairs of vertices with equivalent syntactic structure. We scan
all PDGs from the previous step to nd vertices that have the type expression
(e.g. int a = b + 1 ). From those expression vertices, we try to match their
syntactic structure with each other. To nd two expressions with equivalent
syntactic structures, we make use of Abstract Syntax Tree (AST). This way,
we ignore variable names, literal values, and focus only on the structure, e.g.
int a = b + 1 is equivalent with int k = l + 1 , where both expression has
the same type, which is int).
Find clones. From a pair of equivalent structure expressions, we back-slice to
nd their predecessors and compare them with each other. If the AST structures
of their predecessors are the same then we store it in the collection of clones
found. Because of this step, we can nd non-contiguous, reordered, intertwined
and refactorable clones. Refactorable clones in this case mean that the found
clones are meaningful and it should be possible to move it into a new procedure
without changing their semantic.
Group clones. This is the step where we make sense of the found clones
before displaying them. For example, when using CodeSurfer, the vertex for a
while-loop doesn't really show that it is a while loop but rather showing its
predicate, e.g. while(i<10) will show as a control-point vertex i<10 . Therefore,
it is important that the found clones are mapped back to the actual program
text representation and grouped together before displaying them. It is important
that the programmer can understand and take action on the reported clones.
Experimental setup. The authors of the original paper used CodeSurfer
version 1.8to generate PDGs and wrote Scheme program of 6123 lines that
access CodeSurfer API to work with the generated PDGs. They also had to
have a C implementation of 4380 lines to do the processing of those PDG to
actually nd clones.
They were able to nd isomorphic subgraphs of the PDG by implementing
a program slicing technique that used a combination of backward slicing and
forward slicing. They applied it to some open-source software written in C ( tail ,
sort ,bison ) and demonstrated the capability of slicing to detect non-contagious
code clones. We will show the actual numbers later when we compare the results
with the replication.
4 Changes to the original study
The motivation of this replication study is to be able to validate algorithm and
results of the original study. Once validated, we would like to publish our code
and intermediate results into a public repository so that it is easier for any future
researchers to either re-validate our results or to extend our program.
We had to use CodeSurfer 2.3 instead of 1.8 used in the original study: just
to get it running was already a challenge impossible to overcome | we would
eventually need to do a sandboxing of some 2001 version of OS, which would
then need to be properly licensed (CodeSurfer is not open source, but we have
applied for the academic license and got both 1.8 and 2.3 to experiment with).
Porting the existing code (kindly provided to use by Raghavan Komondoor)
to the new version of CodeSurfer was also ruled out as a viable option: the API
changed too much, and actually covered many things with standard calls that
needed to be programmed in full when working with version 1.8. In the end, we
reimplemented the algorithm from scratch, using both the original paper and the
code behind it as guides. Our implementation has 536LOC of Scheme, which is
huge improvement against the 6123 LOC of the original study. The improvement
is mostly not ours to claim, but CodeSurfer API's. For post-processing of clones,
we wrote a Ruby script, which was again shorter: 161 LOC versus the original
4380 LOC, partly due to the improved API, but partly also due to the language
choice (the original post-processing was done in C++). Actually, given a bit
more time, it should have been possible to avoid post-processing entirely, or
rather to implement in all in Scheme. The code is available online for anybody
to do this | http://github.com/ammarhamid/clone-detection | we accept
pull requests.
There are several other important changes from the original paper that we
need to explain. As mentioned above, we only detect clones within the reachable
procedures, excluding any unused procedures that are not reachable from main
execution. This makes the result more accurate, since dead code is out of our
consideration.
Furthermore, we only use backward slicing and no forward slicing to detect
clones. Let us have a look at the example on Table 2. According to the original
paper, only statements indicated by ++will be reported as clones while statement
marked with **is excluded. The main argument according to the original paper
is that fp3is used inside a loop but the loop predicate itself is not matching
(for loop and the rst while loop predicate doesn't match) { or a so called cross
loop [8].
However, we argue that we should still report the statement marked with **
as a clone together with the fact that their loop predicate doesn't match. For a
software developer it would mean one could still refactor this into two separate
procedures, instead of a single procedure proposed by the original paper (Table 3
and Table 4). Therefore, we consider that forward slicing is only necessary to
dene refactoring strategy and not for detecting the clone itself.
Fragment 1 Fragment 2
... ...
** fp3 = lookaheadset + tokensetsize; ** fp3 = base + tokensetsize;
for(i = lookaheads(state); ...
i < k; i++) { if(rp) {
++ fp1 = LA + i * tokensetsize; while((j = *rp++) > 0) {
++ fp2 = lookaheadset; ...
++ while (fp2 < fp3) { ++ fp1 = base;
++ *fp2++ |= *fp1++; ++ fp2 = F + j * tokensetsize;
} ++ while(fp1 < fp3) {
} ++ *fp1++ |= *fp2++;
}
}
Table 2. Two clones from bison that illustrates the necessity to have a forward slicing
according to the original paper [8]
The new fragment 1 The new fragment 2
... ...
fp3 = location(lookaheadset, fp3 = location(base, tokensetsize);
tokensetsize); ...
... if(rp) {
for(i = lookaheads(state); while((j = *rp++) > 0) {
i < k; i++) { ...
compute(LA, lookaheadset, compute(F, base,
i, tokensetsize, fp3); j, tokensetsize, fp3);
} }
}
Table 3. The new fragments after refactoring (without forward slicing)
The extracted procedures
int location(int base, int size) { return base + size; }
void compute(int cons, int base, int index, int size, int loc) {
fp1 = cons + index * size;
fp2 = base;
while (fp2 < loc) { *fp2++ |= *fp1++; } }
Table 4. The new refactored procedures. In this case, procedure location has only
one statement which probably unnecessary to create a new procedure for it. But the
point is if we use forward slicing in clone detection phase, we might hide this statement
prematurely from the programmers, who at least should be aware of the situation
before proceeding with refactoring.
Study Program LOC PDG nodes Elapsed time, minutes:seconds
Scheme C++ Ruby
Original tail 1569 2580 00:40 00:03 |
Replication tail 1668 3052 00:05 | 00:01
Original sort 2445 5820 10:00 00:07 |
Replication sort 2499 6891 00:30 | 00:01
Original bison 11540 28548 93:00 01:05 |
Replication bison 10550 33820 126:00 | 00:42
Table 5. Comparison on program size, number of nodes, implementation and time.
5 Results
To be as close to the original paper as possible, we used the GNU git repositories4
to locate versions that were released around 2001: CoreUtils 4.5.2 (for tail and
sort ) and Bison 1.29 (for bison ).
Table 5 shows the comparison of the sizes of the three programs (in number of
LOC and in number of nodes), and the running times for the algorithm between
the original and replication study. Figure 2 shows the comparison of the result
in details between the original and replication study.
We do not have a solid explanation for the dierences observed, but we can
hypothesise on some issues:
Altered algorithm. We did use a slightly dierent algorithm (only reach-
able code; no forward slicing) to detect clones. However, we have also tried
running it exactly as it was intended originally, and the dierences were rather
minor and could not explain some of the drastic dierences.
Manual inspection was performed to ensure that the clones detected by
our tool are indeed clones and are indeed refactorable. It was possible to review
all clones from tail andsort and cover a random selection of clones for bison
| no false positives were found.
Bison running time in the original study is suspiciously short, which does
not reect the explosive performance behaviour that we have observed in our
implementation. This could indicate a bug in one of the implementations, or
point to a drastically dierent (optimised, distributed) algorithm used for the
actual run of the original experiment. It could also be a simple reporting mistake
(e.g., \one and a half hours" reported instead of actual \one and a half days").
Size of some clones reported for tail and bison is longer than most
functions (group 70+), which means either a mistake or some unreported proce-
dure used in the original experiment to combine several subsequent full-function
clones into one.
Testing a program of 10 KLOC is always harder than testing a program of
1 KLOC, especially if both programs are algorithmically heavy yet the shorter
one relies on a more advanced API. More investigation is needed to see which of
these factors were at play and which results are closer to the truth.
4http://git.savannah.gnu.org/cgit/
tailNumber of nodes in a clone0510152025
Clone size range5–910–1920–2930–3940–4950–5960–6970+OriginalReplication
sortNumber of nodes in a clone0102030405060708090100110
Clone size range5–910–1920–2930–3940–4950–5960–6970+OriginalReplication
bisonNumber of nodes in a clone02004006008001000120014001600
Clone size range5–910–1920–2930–3940–4950–5960–6970+OriginalReplicationFig. 2. Detailed comparison results between the original and replication study
6 Conclusion
We have departed on a quest to nd refactorable semantic clones and have
conducted a replication of a paper that did it with PDG and program slicing.
Our results are statistically somewhat dierent from the results of the original
study, but we can conclude nevertheless that the algorithm described there,
works. So, the fusion of PDG and slicing is suitable for Type 3 clone detection .
As a side product, we have noticed how signicantly CodeSurfer has improved
over the years: the amount of code we needed to write to achieve the same
objectives, is ten times less than what had to be done 13 years ago, with almost
no postprocessing of the obtained results needed.
As for quantitative dierences, unfortunately we could not compare them
in detail since we lack the original data, and we failed in getting the code op-
erational (it would require an old version of CodeSurfer operating on an old
system, preferably with performance comparable to the machine used for the
original experiment). However, we do present some evidence of correctness in
the form of manually reviewed code clones that we reported. We can also con-
clude that the clones are indeed refactorable | this has been evaluated through
manual inspection of the tool reports.
Both the code and the intermediate results of our experiments have been
shared as open source: http://github.com/ammarhamid/clone-detection , to
make it easier to revalidate, replicate, and extend. We hope our clone detector is
a suitable tool to use for future work. Possible future extensions should include
detecting interprocedural clones as well, which would allow detection of type
4 clones and refactorings such as inlining variables and extracting methods.
Intuitively, it would be more useful to provide results over bigger related code
fragments | however, the practical consequences remain to be seen.
Acknowledgement
We would like to thank Raghavan Komondoor for sharing his code: we ended up not
using it directly, but having it at hand helped us to understand some details and make
a better comparison. We would also like to thank David Vitek from GrammaTech for
helping us obtaining an academic license for CodeSurfer and trying to work us through
the changes from 1.8 to 2.3 | again, we ended up not opting for a migration, but
quickly estimating that to be too much of an undertaking, was a part of this project's
success. Last but not least, our thanks go to the participants of SATToSE 2014 for all
the discussions we have had in L'Aquila.
References
1. H. Abelson, R. K. Dybvig, C. T. Haynes, G. J. Rozas, I. Adams, N. I., D. P. Fried-
man, E. Kohlbecker, J. Steele, G. L., D. H. Bartley, R. Halstead, D. Oxley, G. J.
Sussman, G. Brooks, C. Hanson, K. M. Pitman, and M. Wand. Revised5Report
on the Algorithmic Language Scheme. Higher-Order and Symbolic Computation ,
11(1):7{105, 1998.
2. B. S. Baker. On Finding Duplication and Near-Duplication in Large Software
Systems. In WCRE , pages 86{95, 1995.
3. J. Beck and D. Eichmann. Program and Interface Slicing for Reverse Engineering.
InICSE , pages 509{518. IEEE, 1993.
4. M. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts. Refactoring: Improving
the Design or Existing Code . Addison-Wesley Professional, 1999.
5. R. Geiger, B. Fluri, H. C. Gall, and M. Pinzger. Relation of Code Clones and
Change Couplings. In FASE , pages 411{425. Springer, 2006.
6. S. Horwitz. Identifying the Semantic and Textual Dierences Between Two Ver-
sions of a Program. In B. N. Fischer, editor, PLDI , pages 234{245, 1990.
7. S. Horwitz, T. W. Reps, and D. Binkley. Interprocedural Slicing Using Dependence
Graphs. ACM ToPLaS , 12(1):26{60, 1990.
8. R. Komondoor and S. Horwitz. Using Slicing to Identify Duplication in Source
Code. In SAS, pages 40{56. Springer, 2001.
9. K. Kontogiannis, R. de Mori, E. Merlo, M. Galler, and M. Bernstein. Pattern
Matching for Clone and Concept Detection. ASE, 3(1/2):77{108, 1996.
10. B. Lagu e, D. Proulx, J. Mayrand, E. Merlo, and J. P. Hudepohl. Assessing the
Benets of Incorporating Function Clone Detection in a Development Process. In
ICSM , pages 314{321, 1997.
11. K. J. Ottenstein and L. M. Ottenstein. The Program Dependence Graph in a
Software Development Environment. In SDE, pages 177{184, 1984.
12. J. Qiu, X. Su, and P. Ma. Library Functions Identication in Binary Code by Using
Graph Isomorphism Testings. In Y.-G. Gu eh eneuc, B. Adams, and A. Serebrenik,
editors, SANER , pages 261{270. IEEE, Mar. 2015.
13. D. Rattan, R. K. Bhatia, and M. Singh. Software Clone Detection: A Systematic
Review. Information & Software Technology , 55(7):1165{1199, 2013.
14. C. Rich and R. C. Waters. The Programmer's Apprentice . ACM, 1990.
15. C. K. Roy, J. R. Cordy, and R. Koschke. Comparison and Evaluation of Code
Clone Detection Techniques and Tools: A Qualitative Approach. SCP, 74(7):470{
495, 2009.
16. C. K. Roy, M. F. Zibran, and R. Koschke. The Vision of Software Clone Manage-
ment: Past, Present and Future. In S. Demeyer, D. Binkley, and F. Ricca, editors,
CSMR-WCRE , pages 18{33. IEEE, 2014.
17. R. Tairas. Clone Detection and Refactoring. In OOPSLA , pages 780{781, 2006.
18. S. Thummalapenta, L. Cerulo, L. Aversano, and M. D. Penta. An Empirical Study
on the Maintenance of Source Code Clones. EMSE , 15(1):1{34, 2010.
19. M. Weiser. Program Slicing. IEEE TSE , 10(4):352{357, 1984.
20. V. Zaytsev and A. H. Bagge. Parsing in a Broad Sense. In J. Dingel, W. Schulte,
I. Ramos, S. Abrah~ ao, and E. Insfran, editors, MoDELS , volume 8767 of LNCS ,
pages 50{67. Springer, Oct. 2014.
21. L. Zhang. Implementing a PDG Library in Rascal. Master's thesis, Universiteit
van Amsterdam, The Netherlands, Sept. 2014.


Software clone detection: A systematic review
Dhavleesh Rattana,⇑, Rajesh Bhatiab,1, Maninder Singhc,2
aDepartment of Computer Science and Engineering and Information and Technology, Baba Banda Singh Bahadur Engineering College, Fatehgarh Sahib 140 4 07, Punjab, India
bDepartment of Computer Science and Engineering, Deenbandhu Chhotu Ram University of Science and Technology, Murthal (Sonepat) 131 039, Haryana, In dia
cComputer Science and Engineering Department, Thapar University, Patiala 147 004, Punjab, India
article info
Article history:
Received 21 June 2011Received in revised form 29 December 2012Accepted 21 January 2013
Available online 14 February 2013
Keywords:
Software clone
Clone detectionSystematic literature reviewSemantic clonesModel based cloneabstract
Context: Reusing software by means of copy and paste is a frequent activity in software development. The
duplicated code is known as a software clone and the activity is known as code cloning . Software clones
may lead to bug propagation and serious maintenance problems.
Objective: This study reports an extensive systematic literature review of software clones in general and
software clone detection in particular.
Method: We used the standard systematic literature review method based on a comprehensive set of 213
articles from a total of 2039 articles published in 11 leading journals and 37 premier conferences andworkshops.Results: Existing literature about software clones is classiﬁed broadly into different categories. The
importance of semantic clone detection and model based clone detection led to different classiﬁcations.
Empirical evaluation of clone detection tools/techniques is presented. Clone management, its beneﬁtsand cross cutting nature is reported. Number of studies pertaining to nine different types of clones is
reported. Thirteen intermediate representations and 24 match detection techniques are reported.
Conclusion: We call for an increased awareness of the potential beneﬁts of software clone management,
and identify the need to develop semantic and model clone detection techniques. Recommendations are
given for future research.
/C2112013 Elsevier B.V. All rights reserved.
Contents
1. Introduction & motivation . . . . . . . . . . . .................................................................................. 1166
1.1. Motivation for work . . . . ........................................................................................ 1166
2. Background. . . . ..................................................................................................... 1167
2.1. Software clones . . . . . . . . ........................................................................................ 1167
2.2. Types of clones . . . . . . . . ........................................................................................ 1167
2.3. Why clones . . . . . . . . . . . ........................................................................................ 1167
2.4. Advantages of clones. . . . ........................................................................................ 1167
2.5. Disadvantages of clones . ........................................................................................ 1167
3. Review method. ..................................................................................................... 1168
3.1. Planning the review . . . . ........................................................................................ 1168
3.2. Research questions . . . . . ........................................................................................ 1168
3.3. Sources of information . . ........................................................................................ 1168
3.3.1. Additional sources . . . . . . . . . ............................................................................. 1168
3.4. Search criteria . . . . . . . . . ........................................................................................ 1169
3.5. Inclusion and exclusion criteria . . . . . . . . . . . ........................................................................ 1170
3.6. Quality assessment . . . . . ........................................................................................ 1170
3.7. Data extraction . . . . . . . . ........................................................................................ 1170
0950-5849/$ - see front matter /C2112013 Elsevier B.V. All rights reserved.
http://dx.doi.org/10.1016/j.infsof.2013.01.008⇑Corresponding author. Tel.: +91 9814837334; fax: +91 1763232113.
E-mail addresses: dhavleesh@rediffmail.com (D. Rattan), rbhatiapatiala@gmail.com (R. Bhatia), msingh@thapar.edu (M. Singh).
1Tel.: +91 9467948996; fax: +91 130 2484004.
2Tel.: +91 9815608309; fax: +91 175 2364498.Information and Software Technology 55 (2013) 1165–1199
Contents lists available at SciVerse ScienceDirect
Information and Software Technology
journal homepage: www.else vier.com/locate/infsof

4. Results. . . . . ........................................................................................................ 1170
4.1. Current status of clone detection . . . . . . . ........................................................................... 1170
4.1.1. Intermediate source representations and match detection techniques ............................................. 1170
4.1.2. Clone detection tools . . . . ................................................................................ 1173
4.1.2.1. Text based clone detection techniques. . . . . ......................................................... 1173
4.1.2.2. Token based clone detection techniques . . . ......................................................... 1174
4.1.2.3. Tree based clone detection techniques. . . . . ......................................................... 1174
4.1.2.4. Graph based clone detection techniques . . . ......................................................... 1175
4.1.2.5. Metrics based clone detection techniques . . ......................................................... 1175
4.1.2.6. Hybrid clone detection techniques . . . . . . . . ......................................................... 1175
4.1.3. Comparison and evaluation of clone detection tools and techniques . ............................................. 1176
4.2. Status of research in semantic and model clone detection techniques . . . . . . . . . . . . ........................................ 1179
4.2.1. Semantic clone detection . ................................................................................ 1179
4.2.2. Model based clone detection . . . . . . . . . . . . . . ................................................................ 1180
4.3. Key sub areas. . . . .............................................................................................. 1181
4.3.1. Code clone evolution . . . . ................................................................................ 1182
4.3.2. Code clone analysis . . . . . ................................................................................ 1182
4.3.3. Impact of software clones on software quality ................................................................ 1184
4.3.4. Clone detection in websites . . . . . . . . . . . . . . . ................................................................ 1186
4.3.5. Cloning in related areas . . ................................................................................ 1186
4.3.6. Software clone detection in aspect oriented programming/cross-cutting concerns. . . . . . . . . .......................... 1186
4.4. Current status of clone management . . . . ........................................................................... 1187
4.4.1. Benefits of clone management. . . . . . . . . . . . . ................................................................ 1187
4.4.2. Clone management – a cross cutting and an umbrella activity. . . . . . ............................................. 1187
4.4.2.1. Clone visualization. . . . . ......................................................................... 1187
4.4.3. Clone management: a systematic map . . . . . . ................................................................ 1188
4.5. Subject systems . . .............................................................................................. 1188
5. Discussion. . ........................................................................................................ 1190
5.1. Key sub areas. . . . .............................................................................................. 1190
5.2. Clone management – a cross cutting topic . . . . . . . . . . . . . . . ........................................................... 1190
5.3. Implications for research and practice. . . ........................................................................... 1191
5.4. Limitations of this review. . . . . . . . . . . . . ........................................................................... 1191
6. Conclusions and future work. . . ........................................................................................ 1191
Acknowledgements . . . . . . . . . . ........................................................................................ 1192
Appendix A. A quality assessment forms . . . . . . . . . . ..................................................................... 1192
A.1. Screening question . . . . . . . . . . . . . . . . . . ........................................................................... 1192
A.2. Screening question . . . . . . . . . . . . . . . . . . ........................................................................... 1192
A.3. Detailed questions .............................................................................................. 1192
A.4. Detailed questions .............................................................................................. 1193
Appendix B. Data items extracted from all papers. . . ..................................................................... 1193
Appendix C. Journals/conferences reporting most clone related research . . . .................................................. 1193
Appendix D. Acronyms. . . . . . ........................................................................................ 1194
References . ........................................................................................................ 1194
1. Introduction & motivation
Copying existing code fragments and pasting them with or
without modiﬁcations into other sections of code is a frequent pro-
cess in software development. The copied code is called a software
clone and the process is called software cloning . A bug detected in
one section of code therefore requires correction in all the repli-
cated fragments of code. Thus, it is important to ﬁnd all related
fragments throughout the source code. Considering the high main-
tenance cost, software clone detection has emerged as an active re-
search area. Different programming paradigms and languages have
led to number of clone variants and detection techniques.
There are two landmark literature surveys by Roy and Cordy
[187] and Koschke [135] in the ﬁeld of software clones. However,
the volume of research in the ﬁeld is continually increased. This
has led to a need for critical evaluation and integration of the avail-able research in particular the need for a systematic literature re-
view. Kitchenham and Charters [127] , Brereton et al. [25] and
Budgen and Brereton [30] deﬁne a systematic literature review
as a means of identifying, evaluating and interpreting all available
research relevant to a particular research question, or topic area, or
phenomenon of interest. This paper reports a systematic literature
review to analyze and report the ﬁndings in clone-based research.Systematic literature reviews are time consuming but provide
transparent and comprehensive view of ongoing research, and
can be used to identify a number of research avenues. This review
identiﬁes different key areas of research on software clones, dis-
cusses the concepts, research method used and major ﬁndings.
1.1. Motivation for work
/C15Software clones are present in many different software artifacts.
Therefore, our study on detection techniques goes beyond
source code.
/C15Upon assessing state of art in software clone research, we real-
ized the lack of systematic literature review. Thus we summa-
rized the existing research based on extensive and systematic
database search and report the research gaps for further
investigation.
The remainder of this article is structured as follows: Section 2
presents the background, deﬁnitions and general theories on soft-
ware clones. Note, a glossary of acronyms used in this paper can be
found in Appendix D . Section 3describes the research questions,
research method that we used to select and review the data mate-
rial for our research, and presents our chosen framework for anal-1166 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
ysis. Section 4presents the results of the systematic review. In Sec-
tion 5, we discuss the ﬁndings and their implications. For research,
we identify what we believe are the most important research gaps.
Section 6concludes and provides recommendations for further re-
search in the area of software clone detection.
2. Background
Firstly, we deﬁne the different types of software clones, and the
factors leading to software clones. We then summarize the draw-
backs of software cloning and state some points as to why software
cloning is beneﬁcial sometimes.
2.1. Software clones
The Merriam-Webster dictionary deﬁnes a clone as one that ap-
pears to be a copy of an original form, thus being synonymous to a
duplicate. In source code and other software artifacts, the original
(code) fragment is copied and pasted with or without modiﬁca-
tions. The pasted (code) fragment is said to be a clone and this
activity is known as (code) cloning. However in software engineer-
ing ﬁeld, the term code clones is still searching for a suitable deﬁ-
nition. Its vagueness was properly reﬂected in Ira Baxter’s words:
‘‘Clones are segments of code that are similar according to some
deﬁnition of similarity’’.
Roy and Cordy [187] mentions code duplication or cloning as a
form of software reuse. Baker [7]after experimenting with a sam-
ple program concluded that code can shrink by 14% based on exact
matches, and 61% based on parameterized matches. The study sug-
gests that as much as 20–30% of large software systems consist of
cloned code. Fowler et al. [61] mentions duplication of code as one
of the bad practices in software development increasing mainte-nance cost. The increasing use of open source software and its vari-
ants also increased code reuse. Existing code can be modiﬁed to
cater to new requirements thereby facilitating and advancing open
source development. Urgent need to detect software clones has
invigorated software clone detection as an active research area.
2.2. Types of clones
It is quite pertinent to mention that standards in case of nomen-
clature are still missing thereby leading to different taxonomies by
different researchers. We list here basic types of clones
[20,135,187] .
Type 1 (exact clones) : Program fragments which are identical ex-
cept for variations in white space and comments.
Type 2 (renamed/parameterized clones) : Program fragments
which are structurally/syntactically similar except for changes in
identiﬁers, literals, types, layout and comments.
Type 3 (near miss clones) : Program fragments that have been
copied with further modiﬁcations like statement insertions/dele-
tions in addition to changes in identiﬁers, literals, types and
layouts.
Type 4 (semantic clones) : Program fragments which are func-
tionally similar without being textually similar.
Structural clones : These are patterns of interrelated classes
emerging from design and analysis space at architecture level.
Structural Clones [14] reﬂect design level similarities which help
in maintenance.
Function clones : The clones which are limited to the granularity
of a function/method or procedure. Several studies devised the
clone detection methods that found the clones at function level
which can be extracted in a different procedure.
Model based clones : Nowadays graphical languages are replacing
the code as core artifacts for system development. Unexpectedoverlaps and duplications in models [47] are termed as model
based clones.
2.3. Why clones
Although cut–copy–paste–adapt techniques are considered bad
practices from a maintenance point of view, many programmers
use them. We list some of the reasons of software cloning.
/C15Programmers limitation and time constraints : The software is sel-
dom written under ideal conditions. Limitations of program-
mer’s skills and hard time constraints inhibit proper software
evolution [122] . Only way out is copying/pasting/editing.
/C15Complexity of the system : The difﬁculty in understanding large
systems only promotes copying the existing functionality andlogic.
/C15
Language limitations : Kim et al. [122] conducted an ethno-
graphic study on why programmers copy and paste code. They
concluded that sometimes programmers are forced to copy and
paste code due to limitations in programming languages. Many
languages lack inherent support for code reuse, leading to
duplication.
/C15Phobia of fresh code : Programmers often fear to bring in new
ideas in existing software. They fear that introduction of new
code may result in a lengthy software development life cycle.
Furthermore, it is easier to reuse the existing code than to
develop a fresh solution since new code may introduce new
errors [99,152] .
/C15Lack of restructuring : Programmers delay restructuring (refac-
toring, abstraction, etc.) of code due to time limits. Often,
restructuring gets delayed until after product delivery which
increases subsequent maintenance costs. [141] .
/C15Forking/templating : Forking is the reuse similar solutions, with
the hope that evolution of the code will occur independently
at least in short term [120] . Use of structural and functional
templates are often mentioned as reuse mechanisms.
2.4. Advantages of clones
Sometimes software developers intentionally introduce code
clones into existing software. The study by Kapser and Godfrey
[118,120] discusses this issue. Some of the points are mentioned
below:
/C15It is a fast and immediate method of addressing change
requirements.
/C15Some programming paradigms encourage the use of Templates
in programming.
/C15If a programming language lacks reuse and abstraction mecha-
nism, it is the only way left to quickly enhance the existing
functionality.
/C15The overhead of procedure calls sometimes promotes code
duplication for efﬁciency considerations.
2.5. Disadvantages of clones
/C15Higher maintenance costs : Two studies [170,172] conﬁrm that
presence of code clones in software greatly increase the post
implementation maintenance (preventive and adaptive) effort.
/C15Bug propagation : If a code fragment contains a bug and that
fragment is pasted at different places, the same bug will be
present in all the code fragments. So code cloning increases
the probability of bug propagation [104,158] .
/C15Bad impact on design : Code cloning discourages the use of refac-
toring, inheritance, etc. [61,147] . It leads to bad design practice.D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1167
/C15Impact on system understanding/improvement/modiﬁcation :I ti s
quite common that the person who developed the original system
is not the one who is maintaining it. Moreover the presence of
duplicated code not only complicates the design but leads to
decreased understanding thereby hampering improvements and
modiﬁcations. In the long run, the software may become so com-
plex that even minor changes are hard to make [136,170] .
/C15Strain on resources : Code cloning increases the size of the soft-
ware system thereby putting a strain on system resources
[104,135] . It degrades the overall performance in terms of com-
pilation/execution time and space requirements.
3. Review method
The systematic review reported in this paper was done follow-
ing the guidelines of Kitchenham et al. [127,128,25] . The steps in-
cluded in the review include: development of a review protocol,
conducting the review, analyzing the results, reporting the results
and discussion of ﬁndings.
3.1. Planning the review
The review protocol includes the research questions framework,
the databases searched, methods used to identify and assess the
evidence. Conducting the review comprises identiﬁcation of pri-
mary studies, applying inclusion and exclusion criteria and synthe-
sizing the results. To reduce researcher bias, the protocol,
described in the remainder of this section, was developed by one
of the authors, reviewed by the other authors and then ﬁnalized
through discussion, review, and iteration. Electronic databases
were extensively searched and its studies are reported. Moreover,
some of the leading software engineering journals and conference
proceedings which fail to come in electronic search were searched
manually. In total 2039 articles appeared in electronic and manual
search as shown in Table 2 . Study selection procedure is shown in
Fig. 1 .3.2. Research questions
The main goal of this systematic review was to identify and
classify the existing literature focusing on clone detection, clone
management, semantic clone detections and model based clone
detection techniques. To plan the review, a set of research ques-
tions were needed. Table 1 list the speciﬁc research questions
and sub questions.
3.3. Sources of information
A broad perspective is necessary for an extensive and broad cov-
erage of the literature. Before starting the search, an appropriate set
of databases must be chosen to increase the probability of ﬁnding
highly relevant articles. [25,127] recommends searching widely in
electronic sources and following databases were searched:
/C15ACM Digital Library ( www.acm.org/dl ).
/C15IEEE eXplore (ieeexplore.ieee.org).
/C15ScienceDirect ( www.sciencedirect.com ).
/C15Springer ( www.springerlink.com ).
/C15Wiley Interscience ( www3.interscience.wiley.com ).
/C15Scientiﬁc Literature Digital Library and Search Engine ( http://
citeseerx.ist.psu.edu/ ).
3.3.1. Additional sources
/C15Reference lists from primary studies and other review articles.
/C15Books and Technical Reports.
/C15Code clone literature website: http://students.cis.uab.edu/tair-
asr/clones/literature/ .
These databases are highly relevant as far as software clone re-
search is concerned. Refs. [127,128] recommend looking for studies
in related disciplines for rigorous search. Many developers of tools/
algorithms are queried for additional information. The main goal is
not to limit the coverage but to make systematic review goal ori-
Table 1
Research question, sub question and motivation.
Research question Motivation
(1) What is the current status of clone detection? It helps in understanding the clone detection techniques. Various intermediate
representations and match detection techniques used in clone detection technique/tool are reported. Various tools/techniques for clone detection developed till date are
mentioned with their chare of usage. The research question explores the studies which
evaluated/compared different clone detection technique. We mentioned studies whichempirically compared different clone detection tools. The number of studies for eachtype of clone is also reported(1.1) What methods of clone detection (intermediate representation and
match detection technique) are used and what granularity of clone do they
use?
(1.2) What tools are available for software clone detection, what method do
they use, what clone type do they address, how frequently are they cited?
(1.3) Which studies have evaluated methods/tools and with what results?(2) Research status in semantic and model based clone detection It is hard to detect semantic clones. Functional equivalence problem is undecidable i n
general and subgraph isomorphism is NP-complete. Model based clones are quite hardto locate too. So any research indication for the same is immensely helpful. It will helpin devising better and highly scalable strategies(2.1) What are different studies in semantic clone detection and their
comparative analysis?
(2.2) What are the different studies in model based clone detection and
comparative analysis?
(3) Key sub areas It helps in knowing the type of study carried out in the article. It is important to know
the number of studies for each sub area which helps in identifying key areas for furtherresearch. A time based count shows how the key area has evolved over time(3.1) What are the important areas related to software clones, number of
studies in each classiﬁed area and their ﬁndings?
(3.2) A time based count to show how the area has evolved over time.(4) What is the current status of clone management Clone management has turned out to be a cross cutting topic. Recent research is
shifting towards efﬁcient clone management techniques. The research questionsfocuses on understanding the current status of research in clone management and its
sub-topics like clone visualization. Different key area identiﬁed in research question 3
touch clone management. It is important to know different clone detection methodsand clone detection tools overlapping with clone management topics(4.1) What are the studies discussing beneﬁts of clone management?
(4.2) What is the current status of research in clone management and
visualization?
(4.3) A systematic map showing cross cutting nature of clone management
(5) What is the subject system used It will help in building the database on which the clone detection research can be
carried out. It is a step towards benchmarking and standardization of comparativeanalysis studies(5.1) What is the size of software used in LOC?
(5.2) What is the programming language of the subject system and whether
the system is open source or commercial?1168 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
ented and such that the future directions are clear for further
research.
3.4. Search criteria
In almost all the searches, the keyword ‘‘clone’’ is included in
abstract. It is an extensive and time consuming process. Table 2
shows the deﬁned search strategy from different e-resources. We
tried to extract as much of relevant literature as possible.We undertook a meticulous database search to ensure the com-
pleteness of our study. Even so some of the known research papers
were not included in predeﬁned search strategy due to number of
reasons. It may be due to different article title, search string not in
abstract, etc. It is a hard fact that research community is still striv-
ing for standard deﬁnition of the term ‘‘clone’’. Due to this, many
traditional research studies refer to clones as duplication of code,
etc. These studies are included in the database by keyword search
to make review process complete. Redundancy, duplication, copy
Fig. 1. Study selection procedure.
Table 2
Search strings.
Sr.no.E-resource Search string Dates Product/content
typeSubjects #
1 ieeexplore.ieee.org Abstract: Clone 1988–2011 Conferences,
Journals and
StandardsComputing and Processing (Hardware and Software),
general topics for Engineers (Math, Science and
Engineering), Engineering Profession967
2 www.acm.org Abstract: Clone All dates Journal,
Proceedings,Transaction andMagazineAll subjects 485
3 www.sciencedirect.com Abstract: Clone All Years All sources Computer Science, Decision Sciences and Engineering 134
4 www.springerlink.com Title: CloneAll Text:
(Software/Code)Entire range
of
publication
datesAll sources All subjects 245
5 www3.interscience.wiley.com Article Title: Clone Full
Text/Abstract: code orsoftwareAll dates Journals, Reference
works, DatabasesAll subjects 208D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1169
and paste are some of the keywords which usually replace clone in
article title and abstracts.
3.5. Inclusion and exclusion criteria
In the ﬁrst stage, irrelevant papers were excluded manually
based on titles. In our case, the number of irrelevant papers is high
as research articles on clones in biology, mathematics and net-
works are hard to distinguish from software clones in online dat-
abases search. In addition, there are many plagiarism detection
tools which overlap with software clone detection tools. Studies
were eligible for inclusion in the review if their focus of study
was software clone detection or software clones in general. Studies
of both students and professional software developers were in-
cluded. The systematic review included qualitative and quantita-tive research studies, published up to and including 2011 starting
from the initial date of the digital library to make the database
search comprehensive. Only studies written in English were in-
cluded. We included technical reports in our study. Fig. 1 shows
the exclusion at different stages. Studies were excluded if their fo-
cus, or main focus, was not software clones. Research papers
repeating in different e-resources and databases were individually
excluded to ensure our research database remained normalized.
Position papers were excluded from the literature review but some
of the position papers showing future directions are mentioned in
the conclusion and future work section. Some of the articles were
ﬁrst published in conferences and then extended versions appear
in journals. Such preliminary studies were excluded. All missing
relevant papers were found manually using references of identiﬁed
papers. Some of the journals like Journal of Software Maintenance
and Evolution: Research and Practice were individually searched to
verify the results from electronic keyword search.
As shown in Fig. 1 , Our search returned over 2039 total papers,
which were narrowed down to 269 papers based on their titles,
and 229 papers based on their abstracts. Then, these 229 papers
were read entirely to select a ﬁnal list of 213 papers based on
the inclusion and exclusion criterion.
3.6. Quality assessment
After using the inclusion and exclusion criterion to select rele-
vant papers, a quality assessment was performed on the remaining
papers. Since the ﬁeld is eclectic, a large number of different jour-
nals and conferences include research papers of our interest. Qual-
ity assessment was done in accordance to CRD guidelines as cited
by[127] , i.e., each study was assessed for bias, internal validity and
external validity of the results.
Using the quality assessment as per Appendix A , all of the in-
cluded papers contain high-quality software clone research, pro-
viding additional conﬁdence in the database of selected papers.
In the quality assessment form ( Appendix A ), the high level
question in Section 1set the basis for screening the study. After
the research paper was included, the paper was studied for classi-
ﬁcation based on questions in Section 2. Then we proceeded to Sec-
tions 3 and 4 .
3.7. Data extraction
Appendix B identiﬁes the guidelines for data extraction from all
the 213 studies included in the systematic literature review. The
data extraction form was designed when we started the informa-
tion gathering process which is sufﬁcient to address the research
questions framed.
Quality assessment form in Appendix A sets the basis for inclu-
sion/exclusion criteria of the study. To some extent, our quality
assessment form and data extraction form overlapped. When westarted the systematic literature review, we experienced many
problems. It was difﬁcult to extract all the relevant data ( Appendix
B) from many studies. Due to this, it was necessary to contact
many researchers to ﬁnd the required details which we were not
able to infer from the research paper.
The data extraction procedure can be summarized as:
/C15One of the authors reviewed all of the papers and extracted data
from all the 213 agreed primary studies.
/C15To check the consistency of data extraction, another researcher
performed data extraction on a random sample of primary stud-
ies and the results were cross checked.
/C15If there were any disagreement when papers were cross-
checked, consensus meetings among the authors were used to
resolve them.
4. Results
The goal of this study is to investigate the available literature as
per the research questions mentioned in Table 1
. Out of 213 pa-
pers, seventeen are published in leading journals and the rest is
published in premier conferences and workshops on software
engineering, programming languages and allied areas. Appendix
Clists the journals and conferences publishing most clone related
research, including the number of papers which report software
clone detection as prime study from each source.
It is worth mentioning regarding the publication for that papers
on software clone detection are published in wide variety of jour-
nals and conference proceedings. We noticed that conferences like
International Conference on Software Engineering, International
Conference on Software Maintenance, and Working Conference
on Reverse Engineering contribute large share of studies. Premier
journals like IEEE Transactions on Software Engineering, Journal
of Software Maintenance Evolution: Research and Practice, Journal
of Systems and Software contribute greatly to our study domain.
A 83% of the studies were published in conferences and work-
shops and 17% of the literature appeared in journals.
4.1. Current status of clone detection
There are a large number of clone detection tools/techniques.
For any technique/tool, the source representation and the match
detection technique are most the important characteristics.
4.1.1. Intermediate source representations and match detection
techniques
Initially, source code is pre-processed to remove any uninterest-
ing parts (e.g. comments and blank lines). Then suitable transfor-mation techniques are applied to the pre-processed code to
obtain an intermediate representation of the code. Intermediate
representation is a way of extracting useful information based
upon which comparison is done. Clone granularity deﬁnes the
boundary of comparison. It can be ﬁxed, e.g. function, class, etc.
or free, e.g. number of statements. We listed granularity level for
each intermediate representation.
Different clone granularity levels apply to different intermedi-
ate source representations. We list all of them in Table 3 . Abstract
Syntax Trees (ASTs) or Parse trees, Source code or text and Regular-
ized tokens are the most frequently used intermediate
transformation.
Match detection algorithms are the prominent issue in clone
detection process. After a suitable source code representation
and granularity level is decided, an appropriate match detection
technique is applied to the units of the source code representa-
tion. The output is a list of matches with respect to the trans-
formed code. All the match detection algorithms found in our1170 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
primary studies are shown in Table 4 . We have listed primary
studies that discuss each match detection algorithm. The most
frequently occurring match detection techniques are Metric/Fea-
ture Vector clustering, Sufﬁx tree based token by token compar-
ison, Substring/Subtree/Model comparison and Dynamicprogramming. In post-processing, detected clones are screened
for false positives manually. Since many software systems con-
tain large duplication, the outcome of the clone detection results
is reported using techniques like scatter plots and other forms of
visualization.
Table 3
Intermediate representations, relative count, granularity and citations.
Sr.no.Intermediate
representation/transformationtechniqueCode # Clone granularity level Citations
1 Regularized tokens S1 16 Set of statements, set of tokens, fragments of
sequence diagrams, ﬁles, functions[7,16,17,27,35,68,89,103,105,106,113,152,153,157,199,230]
2 AST/parse tree S2 28 Number of tokens, lines of source code, set of
instructions, code regions, methods, functions,
threshold set by user[3,4,8,19,22,24,27,31,36,40,58,59,67,95,132–
134,147,150,153,170,176,196,202,208,214,226,231]
3 Partite sets and vertices S3 1 Program [37]
4 Source code/text S4 16 Functions, methods, threshold as set by user,
number of words/lines[13,41,42,56,102,104,129,146,164,168,179,180,191,207,209,228]
5 Call graph S5 1 Functions [35]
6 Vector space
representationS6 3 Methods, blocks [74,154,210]
7 One dimensional array S7 1 Fragments of sequence diagrams [155]
8 PDG S8 5 A set of statements that can be extracted into a
function, threshold as set by user, non-contiguousclones[63,84,85,130,138]
9 Index and inverted index S9 1 Set of statements [149]
10 Sparse, labeled directed
graphS10 3 Fragments of graph [47,90,182]
11 Recorded parsing actions
and lexical informationS11 1 Set of statements [166]
12 Abstract memory states S12 1 Procedures [125]
13 Description logic S13 1 Functions, methods, control blocks [202]
Table 4
Match detection techniques.
Sr.
no.Match detection
algorithmCode # Clone granularity level Citations
1 Sufﬁx Tree based
token by token
comparisonM1 12 Fragments of sequence diagrams, functions, program
fragments, number of tokens as set by user, number of
words[7,59,68,105,106,113,134,153,155,157,166,214]
2 Weighted partite
matchingM2 2 Number of blocks, program [37,47]
3 LSI based clustering
algorithmsM3 2 Code segments, functions, ﬁles [164,168]
4 Metrics/feature
vectors clusteringM4 17 Set of instructions, code regions, functions and methods,
Threshold set by user, blocks[3,4,8,35,42,95,129,132,133,146,147,154,170,176,179,180,196]
5 Fingerprinting M5 3 Number of lines, set of statements, blocks [36,104,180]
6 Anti-uniﬁcation M6 3 Threshold of tokens set by user, sub expressions [27,31,150]
7 Hashing/LSH M7 6 Set of instructions, code regions, ﬁles [22,63,89,176,196,199]
8 FIM M8 3 Higher level similarities, i.e. ADT, classes [17,152,226]
9 Program Slicing M9 2 Procedure, non-contiguous clones [84,130]
10 DP M10 8 Methods, set of statements, programs [8,22,41,67,106,132,147,231]
11 Sufﬁx arrays M11 4 Function, sequence of tokens [16,35,103,230]
12 LCS M12 6 Program, variable size [67,89,125,191,210,231]
13 ICA M13 1 Methods, blocks [74]
14 Associative array M14 1 Number of tokens, lines of source code [58]
15 Nearest neighbor M15 1 Set of statements [149]
16 Canonical labeling M16 2 Fragments of graph [90,182]
17 Substring/subtree/
model comparisonM17 9 Set of tokens, number of lines of code [13,19,24,56,63,85,207–209]
18 k-Length patch
matchingM18 1 Threshold as set by user [138]
19 Partitioning algorithm M19 1 Different components of the program [85]
20 Tree kernel M20 1 Class, method, set of statements [40]
21 Levenshtein distance M21 1 Class, method, set of statements [95]
22 Semantic web
reasonerM22 1 Functions, methods, control blocks [202]
23 Random testing M23 1 Lines of source code [102]
24 Dot plot/scatter plot M24 2 Lines of source code [56,228]D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1171
Table 5
Tool type, tool/ﬁrst author name, source representation/match detection technique, number of studies referring it and citations.
Tool/1st author Method # Citations
Text based
duploc Source Code, Substring Comparison/Dot Plot
Scatter Plot5 [20,56,57,195,227]
Simian Source Code, Substring Comparison 12 [13,21,55,139–143,202–204,207]
DuDe Source Code, Dot Plot/Scatter Plot 2 [83,228]
SDD Index and Inverted Index, Nearest Neighbor 1 [149]
CSeR AST, Metrics/Levenshtein Distance 1 [95]
NICAD Source Code, LCS 6 [129,169,190,191,193,194]
EqMiner Source Code, Random Testing 1 [102]
Johnson Source Code, Fingerprinting 1 [104]
Cordy Source Code, DP 1 [41]
Marcus Source Code, LSI 1 [168]
Barbour Source Code, Substring Comparison 1 [13]
Token based
dup Tokens, Sufﬁx Tree 7 [7,20,57,60,68,195,227]
CCFinder (X) Tokens, Sufﬁx Tree 54 [2,13,15,20,21,24,29,32,38,57,62,66,75–77,82,83,94,95,98,101,112–114,116–120,123–
125,137,158,160,165,172–174,186,197,199,201–204,219,223,224,227,230,232,234,235]
D-CCFinder Tokens, Sufﬁx Tree 2 [156,157]
RTF Tokens, Sufﬁx Array 1 [16]
clones/cscope AST, Sufﬁx Tree 1 [134]
iClones Tokens, Sufﬁx Tree 2 [68,70]
CP-Miner Tokens, FIM 3 [76,100,152]
SHINOBI Tokens, Sufﬁx Array 1 [230]
FCFinder Tokens, LSH 1 [199]
Jian-lin Tokens, Sufﬁx Array 1 [103]
Chilowicz Tokens/Call Graph, Metrics/Sufﬁx Array 1 [35]
Tree based
Deckard PDG/Parse Tree, LSH/Subtree Comparison 10 [55,63,64,100,109,125,151,184,220,221]
CloneDR AST, LSH/DP 9 [20,22,32,60,75,206,212,217,227]
SimScan AST, Subtree Comparison 11 [6,13,21,54,55,60,87,158,174,208,223]
Asta AST, Associative Array 1 [58]
Clone Digger AST, Anti-uniﬁcation 2 [31,40]
Sim Parse Tree, DP/LCS 1 [67]
ClemanX AST, Metrics/Feature Vector Clustering/LSH 1 [176]
JCCD API AST, Subtree Comparison 1 [24]
ccdiml AST, Subtree Comparison 3 [19,29,223]
CloneDetection AST, FIM 1 [226]
cpdetector AST, Sufﬁx Tree 1 [134]
clast Parse Tree, Sufﬁx Tree 1 [59]
Chilowicz AST, Fingerprinting 1 [36]
Saebjornsen AST, Metrics/Feature Vector Clustering/LSH 1 [196]
Tairas AST, Sufﬁx Tree 1 [214]
Lee AST, Anti-uniﬁcation 1 [150]
Yang Parse Tree, DP/LCS 1 [231]
Brown Tokens/AST, Anti-uniﬁcation 1 [27]
Graph based
PDG-DUP PDG, Program Slicing 2 [29,130]
Scorpio PDG, Program Slicing 1 [84]
Duplix PDG, k- length patch matching 3 [20,138,227]
Choi Partite Sets and Vertices, Weighted Partite
Matching1 [37]
Horwitz PDG, Substring Comparison/Partitioning
Algorithm1 [85]
Metrics based
CLAN /Covet AST, Metrics 10 [4,20,32,34,51,60,144,170,195,227]
Li Vector Space Representation, Metrics/
Feature Vector Clustering1 [154]
Kontogiannis AST, Metrics/Feature Vector Clustering/DP 2 [132,133]
Similar Methods
ClassiﬁerAST, Metrics/DP 1 [8]
Antoniol AST, Metrics 1 [3,4]
Dagenais Source Code, Metrics 1 [42]
Kodhai Source Code, Metrics 1 [129]
Patenaude Source Code, Metrics 1 [179]
Perumal Source Code, Metrics/Fingerprinting 1 [180]
Lavoie AST, Metrics/DP 1 [147]
Lanubile Source Code, Metrics/Feature Vector
Clustering1 [146]
Model based
CloneDetective /
ConQATTokens, Sufﬁx Tree/DP 10 [48,49,52,96,105–109]1172 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
4.1.2. Clone detection tools
Numerous tools have been developed for clone detection. We
have conducted an extensive survey regarding the penetration
and usage of clone detection tools for instructors, research or com-
mercial purpose. Table 5 shows tools name/ﬁrst author name, its
source representation and match detection method, which papers
have cited it. The table includes clone detection based not only in
source code but also on the usage of the tool in other areas like
web applications and requirement speciﬁcations. As shown in
Table 5 we have classiﬁed the techniques roughly into seven types:
text based, token based, tree based, graph based, metrics based,
model and hybrid clone detection techniques. Apart from model-
based techniques, these techniques and the tools that use them
are discussed in more detail later in this section. Model-based
techniques are discussed in more detail in Section 4.2.2 .
Different types of clones are detected by different techniques.
Many tools/techniques are able to detect only a subset of clone
types. In Table 6 , we have enumerated the type of clones and iden-
tify the studies discussing each type of clone. Table 6 makes it clear
that clone research has concentrated primarily on clones of Types 2
and 3, clones of Type 1, Type 4 and Model based clones have been
given some attention, but the remaining four clone types have
been the subject of very little research.
4.1.2.1. Text based clone detection techniques. In text based clone
detection techniques, two code fragments are compared with each
other in the form of text/strings/lexemes and similar fragments are
reported as code clones. Johnson [104] applied a ﬁngerprinting
technique for comparison of source code. Ducasse et al. [56] devel-
oped a language independent clone detection tool duploc which re-
quired no parsing. Line based comparison is done using dynamic
pattern matching and results are displayed in the form of dot plot.DuDe [228] is another line based clone detection tool which is
able to detect duplication chains consisting of a number of smallersize exact clones. Simian [207] is able to detect clones in different
programming languages. If Simian does not recognize program-
ming language of the source ﬁle, then it treats it as a plain text ﬁle
to ﬁnd clones. The SDD (Similar Data Detection) [149] tool is help-
ful in detecting code clones in large size systems. The technique is
based on generating index and inverted index for code fragments
and their positions. Then an n-neighbor distance algorithm is used
to ﬁnd similar fragments.
NICAD [188,191] is a text based hybrid clone detection tool
which is able to detect type 3 clones effectively. It is based on
a two stage process, viz. identiﬁcation and normalization of po-
tential clones using pretty printing and code normalization and
code comparison using longest common subsequences. Variants
ofNICAD [190] have been used to calculate recall and precision
by applying a mutation/injection based framework. NICAD has
been used to detect function clones in open source systems writ-
ten in Python to discover any changes in cloning patterns as
compared to traditional software systems [194] . Martin and Cor-
dy[169] useNICAD to detect and analyze similar web services in
the form of contextual clones. Cordy et al. [41] detected near-
miss clones in HTML web pages using island grammar to identify
and extract all structural fragments and applying UNIX diff as
comparator. Barbour et al. [13] used the Knuth–Morris–Pratt
algorithm for string comparison to update the clone information
from the server incrementally to save time in a client server set-
up. Later on, only relevant clones are retrieved by individual
developers. The technique is found to be faster than string based
Simian and AST based SimScan . However, since it uses string
based technique, it fails to detect clones with minor and major
changes.Table 5 (continued )
Tool/1st author Method # Citations
ModelCD Sparse labeled direct graph, canonical
labeling2 [49,182]
DuplicationDetector One Dimensional Array, Sufﬁx Tree 1 [155]
MQ lone Model/Source Code, Model Comparison 1 [209]
Clone Detective Sparse labeled direct graph, Weighted
Partite Matching1 [47]
Hummel Sparse labeled direct graph, canonical
labeling1 [90]
Hybrid
Clone Miner Tokens, FIM 4 [14,17,18,236]
MeCC Abstract Memory States, LCS 1 [125]
Maeda Recorded Parsing Actions and Lexical
Information, Sufﬁx Tree1 [166]
Lucia Source Code, LSI 1 [164]
Li Tokens/AST, Sufﬁx Tree 1 [153]
Hummel Tokens, LSH/LCS 1 [89]
Sutton Vector Space Representation, LCS 1 [210]
Cordy Vector Space Representation, ICA 1 [74]
DL_Clone AST/Description Logic, Semantic Web
Reasoner1 [202]
Corazza AST, Tree Kernel 1 [40]
Table 6
Number of studies referring to different types of clones.
Sr. no. Type of clone # Citations
1 Type 1/exact clones 11 [56,57,59,89,104,129,134,153,157,180,226]
2 Type 2/parameterized clones 23 [7,16,56,57,59,68,83,89,103,113,129,134,148,153,157,166,170,180,214,225,226,230,233]
3 Type 3/near miss clones 27 [22,27,36,40,41,57,59,67,74,83,84,101,106,131,133,134,138,148,150,166,170,179,191,193,203,210,214]
4 Type 4/semantic clones 8 [37,63,102,125,130,138,168,202]
5 Structural clones 3 [14,17,18]
6 Model based clones 7 [47,49,90,105,155,182,209]
7 Function clones 3 [35,58,193]
8 File clones 1 [199]
9 Contextual clones 1 [169]D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1173
4.1.2.2. Token based clone detection techniques. It is more meaning-
ful in parameterized clone detection as tokens are better than sim-
ple keyword matches. In token based clone detection techniques,
ﬁrstly, tokens are extracted from the source code by lexical analy-
sis. Then some set of tokens (at a speciﬁc granularity level) is
formed into a sequence. Sufﬁx tree or sufﬁx array based token by
token comparison is the heart of token based clone detection
algorithms. This match detection technique is the most frequently
cited in the literature and was used in one of the ﬁrst clone detec-
tors dup [7]. Token sequences are fed into a sufﬁx tree. The ap-
proach used ‘‘functor’’ as an abstraction of concrete values of
identiﬁers and literals that maintains their order. The study re-
ported a greater number of parameterized matches than exact
matches in the same subject system. CCFinder [113] , a token based
clone detection tool uses sufﬁx tree matching algorithm to ﬁndidentical subsequences. It is a popular tool among researchers
and has been widely used for code clone analysis, code clone man-
agement, etc. Many researchers have worked to enhance the out-
put of CCFinder by devising clone visualization tools. For instance,
CCFinder is used by Basit et al. [15] to study patterns of clones in
a standard template library (STL). In their work, they increased
the threshold in CCFinder to ﬁlter small clones. Livieri et al. [157]
developed a distributed version of CCFinder , viz. D-CCFinder for
large systems by using 80 workstations in master slave conﬁgura-
tion. CCFinderX [114] was used to study code clone genealogies at
release level. Two studies [197,137] used it for analysis of the rela-
tions between open source software quality and code cloning.
Monden et al. [173] concentrated on detecting type 2 clones using
CCFinderX . The number of tokens of largest clone pair and the per-
centage of duplication within the most suspicious source ﬁle pair
are important metrics in distinguishing Type 2 clones in their
study.
CP-Miner [152] is a token-based tool using frequent itemset
mining to detect bugs in the software induced by cloning. Clone
Miner detects structural clones which are high level abstractions.
RTF[16] works by applying sufﬁx array on tokens. Sufﬁx array on
source code tokens is also used by Jian-lin and Fei-peng [103] .
Koschke et al. [134] ’s tool clones uses a parser and generates ab-
stract syntax tree. Then the AST is serialized and input to sufﬁx tree.
The technique is able to detect syntactic units which are not possible
by applying sufﬁx tree only. Göde and Koschke [68] developed the
incremental tool iclones by extending clones to detect clones for mul-
tiple versions. Li and Thompson [153] used two techniques, viz. com-
bination of token stream and the AST to detect and remove code
clones. The two representations are used for their accuracy and
speed. Match detection is done with the help of a sufﬁx tree. Another
modern multi-input open source clone detector framework ConQAT
[105,106] detects clones using a sufﬁx tree on tokens. The tool is
based on a pipelined approach for extensible token based clone
detection. ConQAT has been used to detect behaviorally similar code
[109]
. A number of approaches [47,90] using ConQAT have been pro-
posed to detect duplications in Matlab/Simulink models. Acceptance
of tools like CCFinder ,dup,ConQAT in academia and research showed
the usefulness of the fast speed with which sufﬁx trees detect clones.
Yamashina et al. [230] proposed a novel clone detection/modi-
ﬁcation tool to support the software maintenance process. The
study reported a substantial difference between novice and expe-
rienced programmers regarding motivation and behavior in han-
dling clones. Using CCFinderX ’s preprocessor, tokens are gathered
from the source code. Then they are input to a sufﬁx array for fast
retrieval. Clone retrieval and ranking is performed by the SHINOBI
server. The evaluation shows SHINOBI to be fast and accurate. In
the pre-experiment, a large number of programmers were inter-
viewed to analyze their behavior. SHINOBI still needs improvement
in ranking algorithm. However, it can be extended to support other
useful information in addition to code clones.Sasaki et al. [199] developed a new token based clone detection
tool FCFinder to detect ﬁle clones (ﬁles which are copied across
projects) using hashing. The study detected 68% of the FreeBSD
Ports collection as ﬁle clones. However, FCFinder took a long time
to detect ﬁle clones in the 10 GB collection.
4.1.2.3. Tree based clone detection techniques. Abstract syntax trees
and parse trees are frequently used representations when source
code is to be transformed into tree structures. However, tools
based on this approach suffer from large execution times when
analysing a large source code base. The output is purely syntactic
units of source code which are ready for refactoring. Tree based
clone detection is capable of detecting clones in which the code
is inserted or deleted (type 3 clones).
Yang [231] proposed one of the ﬁrst approaches for ﬁnding the
syntactic differences between two versions of the same program.
The technique was based on grammar and builds a variant of a
parse tree for both the versions. Detection is applied synchronously
to both the trees and is based on the longest common subsequence
method of dynamic programming. A limitation of this approach is
that his differential comparator can only work for syntactically cor-
rect programs conforming to the grammar.
Semantic Designs’ CloneDR [22] is another tool which is able to
detect exact and near miss clones using hashing and dynamic pro-
gramming. The tool has different variants for different program-
ming languages. The study reported the use of clone detection in
ﬁnding commonalities in the form of domain concepts in source
code which will help analysts in understanding the design of the
system for better maintenance. SimScan [208] and ccdiml [19] are
variations of CloneDR .ccdiml transforms the source to intermediate
representation and SimScan applies subtree comparison on the
parsed source code. The source code is parsed with the help of
ANTLR parser generator. SimScan and ccdiml have been used to
classify the evolution of source code clone fragments in Java and
C source code ﬁles [223] . Falke et al. [59] and Tairas and Gray
[214] used sufﬁx tree to detect clones in code transformed into
an AST. The technique has advantage of precision of syntax tree
and high speed of sufﬁx tree.
Gitchell and Tran [67] developed Sim which converts source
programs to parse trees. Viewing parse trees as strings, the tool ap-
plied longest common subsequence and dynamic programming to
assess similarity. Deckard by Jiang et al. [100] is based on comput-
ing characteristic vectors from the AST and clustering vectors
which are close in Euclidean space by locality sensitive hashing.
Deckard has been used to identify refactoring on parts of a clone
in open source systems [220] and localizing the representation of
clone groups [221] and has been used to detect behaviorally simi-
lar code [109] . Another application of Deckard is to assess the im-
pact of code clone on defects in source code [184] .Asta [58] is an
AST based tool which works on the phenomenon of structural
abstraction of arbitrary sub trees of an AST. ClemanX [176,177] is
an incremental AST based framework. The tool constructs charac-
teristic vectors from AST subtrees and used locality sensitive hash-
ing. Saebjornsen et al. [196] also used the same set of techniques to
detect clones in assembly code.
Anti-uniﬁcation is used in three studies [150,27,31] to calculate
the distance between two AST’s and grouping the similar classes in
one cluster. Anti-uniﬁcation helps to discover common sub-
expressions in source code represented as a tree. CloneDigger [31]
is a language independent tool in which anti-uniﬁcation is applied
to XML representation of source code. CloneDetection , a tree based
tool by Wahler et al. [226] , is based on frequent itemset mining ap-
plied on XML representation of source code. Chilowicz et al. [36]
developed a new technique to detect exact clones based on syntax
tree ﬁngerprinting.1174 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
Shifting our focus to code clone management, CSeR (Code Seg-
ment Reuse) was developed by Jacob et al. [95] to check copy
and paste induced clones in an integrated development environ-
ment. The tool was designed to compute clone differences interac-
tively by checking if some piece of code was copy-pasted as the
programmer was editing and typing the code. It works on the phe-
nomenon of converting the immediate clone to an AST and com-
puting the difference with the original in a bi-directional manner
using metrics like the Levenshtein distance.
Biegel and Diehl [23,24] introduced a novel way for fast and
conﬁgurable code clone detection using pipelines. They developed
JCCD , a ﬂexible and customisable AST based clone detection tool in
which several cascaded processors perform various steps of clone
detection process. JCCD API parallelizes the detection process using
multiple cores.
4.1.2.4. Graph based clone detection techniques. A program depen-
dency graph (PDG) represents control and data ﬂow dependencies
of a function of source code. Horwitz [85] used this method to
identify syntactic and semantic differences between two versions
of a program. Graph representation of source program is parti-
tioned depending upon the behavior of source code fragment.
The partitioning algorithm and substring comparison are used to
detect similarity. Duplix [138] works on the k-limiting approach
of ﬁnding maximal similar subgraphs. PDG-DUP [130] is also a
PDG-based tool which uses program slicing to ﬁnd isomorphic sub-
graphs. It helps in detecting non-contiguous clones. Scorpio [84] by
Higo and Kusumoto applied two-way slicing to detect clones. The
tool currently works on for Java and is based on number of PDG
specializations for Java language and heuristics to speed up the
overall detection process. It was developed to address the problem
that the existing PDG based clone detection approach is slow indetection of contiguous clones.
4.1.2.5. Metrics based clone detection techniques. In the data extrac-
tion form, we extracted the studies using metrics and characteris-
tic features in the same column. Both the match detection
techniques are applied after the source code is represented in some
suitable form such as an abstract syntax tree. In the systematic lit-
erate review, we found a large number of articles using this tech-
nique. Characteristic vectors are usually applied for the sub tree
matching in an abstract syntax tree or parse tree to detect type 3
clones. The metrics which are extracted from source code are com-
pared to assess similarity. Mayrand et al. [170] developed CLAN ,
one of the ﬁrst approaches to compare metrics obtained from an
AST of source code. Metrics are calculated from names, layout,
expressions and control ﬂow of functions. CLAN has been widely
used in the last decade. Patenaude et al. [179] detected metrics
from source code organized in ﬁve themes, viz. classes, coupling,
methods, hierarchical structure and clones. Kontogiannis et al.
[132,133] report a technique to detect code clones using metrics
extracted from an AST representation of code. Match detection is
done by applying dynamic programming on source code lines
using minimum edit distance. Balazinska et al. [8]found metrics
and applied dynamic matching to an AST representation of source
code. Metrics were used by Lanubile and Mallardo [146] to detect
function clones in web applications. Perumal et al. [180] used met-
rics and ﬁngerprinting technique to detect clones in source code.
Kodhai et al. [129] and Dagenais et al. [42] applied metrics on tex-
tual representations of source code. Li and Sun [154] explored a no-
vel approach by viewing source code clones in metric space with
coordinate values. The distance between members across samemetric space is measured and the distance reﬂects similarity be-
tween code fragments. This study was accurate and scalable but
the technique is yet to be veriﬁed for different subject systems.Metrics have been used successfully in clone analysis [10,82] , clone
evolution [3,4,51] , clone visualization [101] , etc.
Lavoie et al. [147] presented a novel technique based on graph-
ics processing unit (GPU) algorithms to compute many instances of
the longest common subsequence problem on a generic GPU archi-
tecture using classic DP-matching. Because the algorithm is parall-
elized on a GPU using dynamic pattern matching algorithm, it
leads to an opportunity of increased performance. The tool is useful
to address the problem of ﬁnding more false positives compared to
metrics-based clone detection methods. It also compared clone
identiﬁcation problem on CPUs and GPUs hardware architectures.
The study recommends clone detection techniques using string-
matching with sufﬁx trees could take advantage of the GPU
algorithm.
4.1.2.6. Hybrid clone detection techniques. Sutton et al. [210] applied
an evolutionary algorithm to search for clones in large code bases.
The source code is represented as variable size vector. Clustering of
similar code fragments is done with the longest common subse-
quence. Cordy and Grant [74] introduced a technique using an
existing information retrieval method, namely independent com-
ponent analysis (ICA) to analyze vector representations of software
methods. Firstly, singular value decomposition is applied on origi-
nal method token matrix. Then ICA is applied and points in new
vector space that correspond to the input data are recognized.
The distance between any two vectors is considered a measure of
their similarity.
Maeda [166] introduced a technique based on PALEX source
code representation. The PALEX source code includes lexical infor-
mation and parsing actions recorded from the compiler as it pro-
cesses the source program. The technique is language
independent and uses a sufﬁx tree for comparison. The hybrid ap-
proach by Corazza et al. [40] uses a tree kernel which is a class of
functions for computing similarities among information arranged
in tree structure. It works in a recursive fashion on a tree, starting
from similarity measure of the nodes and aggregating the results.
The technique is language independent and works at method level
for Java programs. The results are compared with AST based tool
CloneDigger. A disadvantage of this approach is that it takes a sub-
stantial time to execute.
Chilowicz et al. [35] developed a technique to detect function
clones in source code represented as call graph using sufﬁx array
and metrics. The technique starts with collecting tokens using lex-
ical analysis. Basit and Jarzabek [17] developed Clone Miner using
frequent itemset mining which works on the output of token based
clone detection tool, RTF[16].
Hummel et al. [89] developed a hybrid incremental index-based
clone detector which takes input in the form of token sequences.The index is used to lookup for all clones in a single ﬁle and allows
updating on addition, deletion or modiﬁcation. The tool in imple-
mented in ConQAT and runs in a pipeline fashion thereby highly
scalable, incremental and provides excellent run time perfor-
mances. In one case study, 100 machines performed clone detec-
tion in 73MLOC in 36 min. The authors proposed the use of
locality sensitive hashing in the current implementation to support
the detection of type 3 clones. The technique is used in code clone
detection as well as model based detection.
Fig. 2 shows different clone detection techniques. The tech-
niques are reported with corresponding source representation
and match detection technique. The ﬁgure shows the amount of re-
search that has been carried out in different clone detection tech-
niques. Table 3 lists thirteen different intermediate representation
or transformation techniques which are referred to in Fig. 2 asSX
(where Xis a number from 1 to 13). Table 4 lists 24 different tech-
niques of match detection which are referred to in Fig. 2 asMX
(where Xis a number from 1 to 24).D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1175
4.1.3. Comparison and evaluation of clone detection tools and
techniques
Comparison and evaluation of clone detection techniques is a
challenging task. Diverse subject systems and the absence of stan-
dard similarity measures complicate the comparison task. So stud-
ies covering comparison and evaluation are immensely important
to identify an efﬁcient clone detector.
Table 7 shows the empirical studies for comparison and evalu-
ation of clone detection tools. In all the studies barring one by Burdand Bailey [32], where we mentioned exact values, we wrote ordi-
nal scales ( /C0/C0, +, ++,+++) where /C0/C0reports lowest and +++ reports
highest depending upon the value of parameters in the paper. The
reader should refer to the relevant research paper to ﬁnd the exact
values. Different studies evaluated the tools using different param-
eters. We have left some of the entries blank as the paper does not
report the relevant results. These studies are discussed below.
Burd and Bailey [32] conducted the ﬁrst experiment to compare
three clone detection tools, CCFinder ,CloneDR and Covet and two
Fig. 2. Different clone detection techniques, match detection algorithms, source representations and citations.1176 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
Table 7
Empirical Comparison Studies.
D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1177
plagiarism detectors JPlag and Moss . They validated all the clone
candidates of the subject system obtained by all the tools and
made a human oracle. Then they used the human oracle for com-
paring the different techniques in terms of precision and recall.
The result of their experiment shows 100% precision for syntax-
based technique CloneDR indicating that no false positives in its de-
tected clones are reported by this tool, however, recall was very
low. The token-based tool CCFinder shows the highest recall
(72%) and reasonable precision (72%).The metric based tool Covet
showed the minimum precision (63%) compared to the other tools.
The limitation of the case study was in terms of system size. The
case study used source code of GraphTool written in Java which
was only 16 KLOC.
Rysselberghe and Demeyer [195] compared text-based duploc ,
token-based dup and metric based clone detector CLAN . The goal
of this comparative study was to identify the most appropriate
clone detection tool for refactoring. They use ﬁve small to medium
(under 10KLOC) sized cases for evaluating the techniques. These
techniques were evaluated qualitatively rather than quantitatively
in terms of suitability, relevance, conﬁdence and focus. The results
show that metric ﬁngerprint techniques were best suited to work
with a refactoring tool. No signiﬁcant difference was found be-
tween the approaches with respect to relevance and focus. Simple
line matching gives the highest conﬁdence as it ﬁnds exact
matches whereas all the other techniques requires a manual
inspection to reject false positives. Their study also found that
parameterised matching techniques returns more clones.
Koschke et al. [134] evaluated their AST-sufﬁx tree based tool
cpdetector in terms of precision, recall and runtime against existing
tools using Bellon’s experimental procedure and additional tools
arecpdetector ,ccdiml ,clones and cscope . Since their developed tool
is suitable for C systems only, therefore they worked only with 4 C
systems of Bellon’s experiment and provided detail results for only
one system. The results show that the AST-based tool ccdiml shows
a good recall (53%). However, the average recall for the token-
based tools is almost double (54%) than the AST-based tools
(30%). Their experiment result shows that clones found 71% more
clones than CCFinder . Metrics based tool CLAN is good and duplix
is worst in terms of runtime.
Bellon et al. [20] conducted a tool comparison experiment with
the same three clone detection tools that were used in Burd and
Bailey’s study and with three additional tools, viz. dup,duplix and
duploc . They also used software systems in Java and C (four Java
and four C systems) totalling almost 850KLOC. Their experiment
showed that precision and recall was complementary for each of
the tool except the PDG-based duplix where both as attributes
exhibited the lowest values. The AST based CloneDR and the met-
rics based CLAN had high precision but their recall was very low.
The token based tools ( dup and CCFinder ) and the text based tool
duploc had the highest recall but low precision. The experiment
shows that the PDG-based tool duplix performed very badly in
terms of execution time compared to the other clone detection
tools.
Falke et al. [59] empirically compared ccdiml ,cpdetector ,clast,
clast-ba ,clones-uk ,clones-ba and cscope using subject systems in
C and Java. The results show that token based tools yield large
number of clones. AST matching shows lower rejection rate, but
also has a lower recall. The result indicates that detection based
on sufﬁx trees is faster than detection based on tree matching.
Parse tree based tools show lower rejection rate than AST-based
tools for C systems but a higher rate for Java systems. Also parse
tree based tools are faster than AST based tools for java systems.
In contrary to previous experiments, this study does not show high
recall for token based tools. According to this study the advantage
of token based techniques is that it is easier to implement lexer
than parser and requires less space than AST. On the other handAST based techniques are good to ﬁnd syntactic clones and help
to ﬁlter those syntactic structures which are of little interest.
Roy and Cordy [190] propose a mutation/injection based frame-
work for evaluating clone detection techniques. In this method
mutant versions of code fragments are created. Then these mutant
versions are injected into original source code. Different variants of
tool NICAD (Basic NICAD ,FlexP NICAD and Full NICAD ) are run on
these mutant versions to compare tool on basis of precision and re-
call. The result of this study shows that Basic NICAD has poor recall
for clones generated by mutant operators of type-2 clones. FlexP
NICAD is also not good to ﬁnd clones generated by mutant opera-
tors of type-2 clones. Full NICAD is best to ﬁnd clones generated
by mutant operators of all type of clones. The advantage of this
framework is to evaluate and compare recall of different clone
detection tools without manual intervention and similarly preci-sion can be evaluated either automatically or by using an interface
with minimal manual intervention.
The experiment [49] compared the techniques of Pham et al.
[182] and Deissenboeck et al. [47]. The study proposes reduction
in branching to avoid multiple occurrence of sub graph in the
search tree. This is done to prune the search space to make it rel-
evant and fast. The techniques to remove obvious clones and
branch reduction lead to lower recall.
Juergens et al. [109] demonstrated the applicability of state of
the art tools in detecting behaviorally similar code. The authors
stated that behaviorally similar code is highly unlikely to be syn-
tactically similar and such code results due to independent devel-
opment. Deckard and ConQAT cannot detect more than 1% of such
code. Selim et al. [203] proposed a hybrid technique in which
clone detection is performed simultaneously for source code
and intermediate code which are merged to detect near miss
clones in Java. Using Bellon benchmark [20], comparison with
other state of the art tools is done. The technique gives lower
precision and higher recall than CCFinder and
Simian , when used
standalone. The technique detected some clones which are not
useful. Use of the technique on large code bases is still to be
done.
An assessment of Type 3 clones as detected by the clone detec-
tion tools namely ccdiml ,clones ,clast,duplix and CLAN is performed
by Tiarks et al. [222] . The study apparently points out that existing
type-3 clone detectors need to be improved as only 25% of detected
clones are accepted by human oracle. An empirical study [193] is
carried out regarding function clones in open source software.
Upon assessing each of studies, it is difﬁcult to ﬁnd out the best
tool for each study. After a complete review of all studies, we are
able to write following general remarks:
Token based clone detection tools like CCFinder detected large
number of clones. They have high recall and reasonable precision.These tools do not help the developer in refactoring in a straight-
forward manner.
Tree based tools like CloneDR have high precision. Though these
tools detect very less number of clones with low recall, but the de-
tected candidates are ready for refactoring thus helping the devel-
oper in clone management.
Metrics based tools like CLAN has good precision but suffer from
low recall and less number of candidates detected. These tools run
fast and detect function clones ready for refactoring.
Tools which apply sufﬁx tree in AST representation of code like
cpdetector works faster than other AST based tools.
One PDG based tool named duplix is able to recognize type 3
clones only but suffer from high time complexity.
We have not found any empirical study comparing various
semantic clone detection tools/techniques.
There are two papers comparing model based clone detection
approaches, i.e. ModelCD and CloneDetective and ConQAT .1178 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
Benchmark [20] has been used by [134,20,59,203] in their
empirical studies. It consists of clone pairs validated by humans
for eight software systems written in C and Java from different
application domains.
We have mentioned the empirical studies comparing different
clone detection tools in the above paragraphs. These studies are
undertaken by taking one or more subject systems to evaluate
the tools. Evaluation is done with parameters like precision, recall,
etc. as shown in Table 7 . Other studies comparing clone detection
tools/techniques qualitatively are explored in the following para-
graphs. Studies devising clone oracle are also discussed in follow-
ing paragraphs.
Ducasse et al. [57] compared their string based clone detection
technique duploc with Baker’s token based tool, dupand Kamiya’s
token based tool, CCFinder and conﬁrms that this inexpensive clone
detection technique can also yield high recall and acceptable pre-
cision. This study uses Weltab (9KLOC) and Cook (46 KLOC) as sub-
ject systems. The detailed results of the study are shown in Table 8 .
Forduploc – means no normalization; C means constants normal-
ized; I means identiﬁers normalized; F means functions normal-
ized; CI means constants and identiﬁers normalized; IF mean
identiﬁers and functions normalized; CIF means full normaliza-
tion; and 0, 1, 2 speciﬁes the maximum gap size in the comparison
sequence. The results of the study show that for Weltab, normaliz-
ing identiﬁers and function names is important to achieve similar
results as that of dupand CCFinder . For Cook, normalizing identiﬁ-
ers can lead to too many clones but normalizing constants only
with maximum gap size zero gives good precision. The study con-
ﬁrms that this inexpensive clone detection technique can also yield
high recall and acceptable precision, although the tool needed to be
extensively calibrated to each system. However, the results also
show clearly that the effectiveness of clone detection tools is
strongly inﬂuenced by the speciﬁc system to which the algorithms
are applied. This conﬁrms that studies attempting to compare dif-
ferent types of clone detection tools must evaluate them on a vari-
ety of different systems.
Roy and Cordy [189] compared clone detection techniques on
the basis of several criteria like language support, comparison
granularity, clone similarity, and code representation. They also
propose a set of hypothetical editing scenarios for different clone
types and evaluate the clone detection techniques based on their
estimated potential to accurately detect clones that may be created
by those scenarios. Their studies results shows that hybrid tech-
nique based on tree-based techniques (e.g., cpdetector ) and text
based techniques (e.g. duploc ) can detect type-1 clones efﬁciently.
Hybrid approach of token based ( dup and RTF) and AST based
(cpdetector and Asta) best suits to ﬁnd type-2 clones. Type-3 clones
are best found by hybrid approach based on text based ( DuDe and
SDD) and AST based ( Deckard ) techniques and graph based tech-
niques ( duplix and GPLAG ) are best suitable to ﬁnd semantic clones.
The results of this study are predictive rather than empirical but
assist to understand and ﬁnd interesting combinations of
techniques.
In another study, Roy et al. [192] conducted a large case study to
classify and compare clone detection approaches based on a num-
ber of facets, each of which has a set of attributes. They qualita-tively evaluated the classiﬁed techniques and tools with respect
to taxonomy of editing scenarios designed to model the creation
of Type-1, Type-2, Type-3 and Type-4 clones. So this case study
compares the clone detection techniques and tools qualitatively
and helps to understand the potential of each technique and tool
to ﬁnd clones generated by different scenarios.
Walenstein et al. [227] carried out a study to highlight the prob-
lems in devising universal oracle. The study involves researchers’
view in classifying the candidate clones into clones and non-clones
categories as detected by tools, viz. dup,CloneDR ,CCFinder ,duplix ,
CLAN and duploc . Authors observed high level of disagreement. This
exploratory study is a step towards clone detector benchmarks.
The study pointed out that inter-rater reliability measures should
be calculated for human generated reference data. Lakhotia et al.
[145] stressed on the need to create a community supported open
benchmark suite to help researchers in evaluating and comparing
clone detectors and choosing standard subject systems for the
study. Lavoie et al. [148] presented a novel technique to construct
clone oracles automatically in large systems based on the Levensh-
tein metric. Compared to manual oracles, this oracle is of good
quality for type-3 clone detection assessment and is able to deal
with large code base in reasonable time. The oracle generates good
quality clones and aims for comparison and evaluation of clone
detection techniques in a reasonable time.
Barring one comprehensive study by Roy et al. [192] , compara-
tive studies of clone detection techniques pertain to some subset of
tools. We found only eleven empirical studies as shown in Table 7
which shows apparent lack of work in comparison and evaluation
of clone detection techniques. We found two studies by Deis-
senboeck et al. [49] and Pham et al. [182] on comparison of exist-
ing model based clone detection techniques.
4.2. Status of research in semantic and model clone detection
techniques
Semantic clone detection and model based clone detection
techniques are challenging upcoming areas. We focused our review
to analyze the available techniques in detail.
4.2.1. Semantic clone detection
Two program fragments differing in their concrete syntax may
be semantically very close. Detecting semantic equivalence is very
difﬁcult. It needs deep semantic analysis. There are some studies
which tried to detect semantic clones. They are mostly approxima-
tions to type 4 clones. In 1990, a key article [85] by Horwitz was
published to detect textual and semantic similarities. Table 9 com-
pares and details different semantic clone detection techniques.
PDG is a directed attributed graph representing the statement
and control ﬂow and captures semantic information from source
code. It works as an abstraction of source program. The application
of a subgraph isomorphism technique to detect clones in the form
of isomorphic subgraphs is NP-complete. Krinke [138] , Komondoor
and Horwitz [130] , Gabel et al. [63] presented techniques to detect
semantic clones using PDG as source representation. Krinke [138]
used k-length patch matching to detect maximal induced subgraphs.
The technique worked well with reasonable precision and recall on
Table 8
Comparison of three clone detection systems on two software products.
Study/tool WELTAB COOK
Candidates Precision (%) Recall (%) Candidates Precision (%) Recall (%)
Dup 2742 80 80 8593 29 70
CCFinder 3888 99 93 2388 42 43Duploc 2378 (IF,1) 90 86 9043 (CIF,0) 26 71
2609 (IF,1) 90 88 7661 ( /C0,2) 42 64
3761 (CIF,0) 91 92 276 (C,0) 49 26D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1179
sample software systems. Komondoor and Horwitz [130] used pro-
gram slicing to detect isomorphic subgraphs in the PDG. The tech-
nique uses backward and forward slicing and able to detect good
clone candidates for procedure extraction. It can detect non-contig-
uous clones. Gabel et al. [63] presented a scalable technique to detect
semantic clones from the PDG representation of the source code. The
key element of the algorithm is to map the NP-complete graph iso-
morphism problem to tree similarity. The tree similarity is based
upon comparing characteristic vectors. Upon empirical evaluation,
the tool has good execution times on large code bases.
Marcus and Maletic [168] applied latent semantic indexing (LSI)
on the textual representation of source code to identify semanticsimilarities across functions/ﬁles/programs. LSI is vector based sta-
tistical method to represent meanings of comments and identiﬁers
of source code. They tried to detect similar high level concept
clones, e.g. abstract data types.
Software birthmarks have been used successfully to detect cop-
ied programs and software theft. Choi et al. [37] used a set of API
calls to detect similar programs. The similarity technique de-
pended upon maximum weighted bipartite matching. In this
way, the method is useful in detecting semantic equivalences
duplications in case of software thefts. However, the technique is
vulnerable to deobfuscation attacks.
There is only one study by Jiang and Su [102] which identiﬁed
functionally equivalent code fragments of arbitrary size depending
on the input–output behavior of a piece of code. They detected two
pieces of code that always produce same output on random inputs
although they are syntactically different. They deﬁned functional
equivalence as a special case of semantic equivalence. The results
were validated by applying random tests. The tool was scalable
and able to work on million lines of code ﬁnding that 58% of func-
tionally equivalent code was syntactically different. The technique
worked for C programs only.
Kim et al. [125] proposed MeCC , a semantic clone detector based
on a path-sensitive semantic-based static analyzer. The analyzer
was used to estimate the memory states at each procedure’s exit
point; then memory states were compared to determine clones.
The authors compared their ﬁndings with CCFinder and Deckard .
MeCC is able to detect larger number of procedural clones, to trace
inconsistencies, identify refactoring candidates and understand
software evolution related to semantic clones.Schugerl [202] presented a novel technique to detect global
clones. An abstract syntax tree representation of the source code
is normalized in the form of description logic. Then a semantic
web reasoner is applied to trace similar source code based on con-
trol-blocks and used data types. The author compared the tech-
nique with state of the art clone detection tools but only on Java
source code. The technique is highly scalable with the use of
semantic web reasoner for match detection.
Several authors suggested areas for further research. Marcus
and Maletic [168] proposed the combination of multiple detection
algorithms in future. A number of hybrid clone detection algo-
rithms were developed as a result. PDG based approaches ofdetecting semantic clones suffer from slow generation of clone
pairs and imprecise deﬁnition of semantic clones. Future work
[63] lies in developing the framework to help in fast generation
of PDG from source code. However, PDG does not consider state-
ment ordering, thus detecting non-contiguous clones which may
turn out to be false positives during manual veriﬁcation. So,
approximate solutions of mapping PDG to trees as by Gabel et al.
[63] by applying tree similarity technique are more scalable. Choi
et al. [37] proposed both extending birthmarks with more informa-
tion and making technique robust against attacks. Schugerl [202] ’s
technique can be parallelized using a cluster of computers. Empir-
ical evaluation across more subject systems would help identify fu-
ture extensions of the tool which currently does not detect small
clones and clones across method. Jiang and Su [102] proposed
exploring future research on functionality-equivalent code refac-
toring and reuse. A general method for different programming lan-
guages should be developed to detect functionally equivalent but
syntactically different code fragments. MeCC
[125] can be extended
by adapting a static analyzer to collect memory states for any arbi-
trary code blocks to make clone detection possible at ﬁner
granularity.
4.2.2. Model based clone detection
With the rise in abstraction, model driven development has
turned to be an emerging area. Large models are developed using
UML, Matlab/Simulink, domain speciﬁc modeling languages, etc.
The presence of duplicated sub structures in different types of
models cannot be ruled out. Model based clone detection tech-
niques are still in their infancy. Detecting clones in models is anTable 9
Semantic clone detection and comparative analysis.
Normalizations/transformationsSource code
representationClone matching
techniqueAdvantages Disadvantages Tools
Jens Krinke [138] PDG Fine grained
PDGn-Length patch
matching (maximalsimilar subgraphs)High precision and recall Needs a PDG generator for
different language, works forC languageDuplix
Komondoor & Horwitz
[130]CodeSurfer to PDG PDG PDG Subgraph
matching usingprogram slicingMechanical refactoring can
lead to procedureextractionNeeds a PDG generator, very
slow for large code basesPDG-DUP
Choi et al. [37] Programs to partite
sets and functions to
verticesBirthmarks Maximum weighted
bipartite matchingEfﬁcient, highly resilient Needs deobfuscation
methods against attacks
Marcus and Maletic
[168]Comment removal
and tokenregularizationText Vector representation
using LSIFinds high level structural
clonesHighly dependent on
comments, low precision
Gabel et al. [63] CodeSurfer to PDG to
ASTPDG Characteristic vectors
in Euclidean SpaceHighly scalable Needs a PDG generator, slow
for large code basesEnhanced
Deckard
Jiang and Su [102] Program text to
intermediatelanguageC
intermediatelanguageAutomated random
testingScalable Works for C programs only EqMiner
Kim et al. [125] Semantic based
static programanalysis toolAbstract
memorystatesAbstract memory state
comparisonPrecise, can be used to
identify bugs,inconsistencies, plagiarismMore false positives, semantic
based static analyzer takes lotof timeMeCC
Philipp Schugerl [202] AST to description
logicDescription
logicSemantic web reasoner Scalable, can be parallelized Fails to detect smaller clones
and clones across methodsDL_Clone1180 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
emerging area. Many researchers tried to ﬁnd the clones in models.
So this classiﬁcation includes studies and tools related to detection
of duplication in different diagrams and models as summarized in
Table 10 .
Liu et al. [155] detected duplications in sequence diagrams by
converting the 2-dimensional sequence diagram to a 1-dimen-
sional array. Then, the 1-dimensional array is used to build sufﬁx
tree. Common preﬁxes are identiﬁed from the sufﬁx tree in the
form of reusable sequence diagram as refactoring candidates. The
study conﬁrmed the presence of 14% duplication in sequence dia-
grams of sample industrial projects.
The automatic detection of clones in models leads to identiﬁca-
tion of potential domain speciﬁc library elements [47]. Deis-
senboeck et al. [47] used ConQAT as an integrated framework to
detect clones in Simulink/Matlab models especially in automotive
domain. The tool CloneDetective , which is part of the ConQAT
framework, works by representing the model as a normalized
multigraph where labels are assigned to relevant blocks. Similarity
between blocks is checked by a heuristic which performs a depth
ﬁrst search based looking for matched pairs. After detection, clones
are clustered based on set of nodes using union function.
Pham et al. [182] presented two algorithms namely escan and
ascan to detect clones in models. These were incorporated in the
tool ModelCD . Firstly, the model was pre-processed to be repre-
sented as a parsed, labeled directed graph. escan was used to detect
exact matching using an advanced graph matching technique
called canonical labeling and ascan was used to detect approximate
matching by counting vector of sequence of nodes and edges’ la-
bels. The technique is incremental in the way it generates candi-
date cloned sub graphs. Their tool ModelCD was compared with
CloneDetective (which is included in the ConQAT framework) [47].
For the same clone granularity and subject systems, both the tools
were compared based on four parameters: Precision, complete-
ness, scalability, incrementality. ModelCD performed better. In a
subsequent paper, Deissenboeck et al. [49] discussed the presence
of a large number of false positives in Simulink/Matlab models,
pointing out that it is important to identify relevant clones. Model
clones suffer from the problem of scalability, clone inspection and
relevance. Their study provided useful insights in addressing these
problems in real time industrial context. The authors proposed
reducing the size of models to make clone detection speedier.
Firstly, removal of obvious cloned sub-systems is carried out. After
which, as proposed by Pham et al. [182] , all nodes with high degree
are removed. After the detection process is complete, the algorithmtries to connect smaller nodes that are connected to each other
over high degree nodes. Deissenboeck et al. [49] then compared
their enhanced version of ConQAT and escan showing ConQAT has
a faster execution times than escan .
Storrle [209] pioneered the detection of clones in all types of
UML domain models. The technique was based on model querying.
Using any of the UML case tools, XMI ﬁles are generated from UML
domain models. These ﬁles are transformed into Prolog ﬁles. A
small model is input in the query and using model matching, the
output is generated. The tool is capable of comparing models orig-
inating from diverse sources including a variety of UML versions.
We observed that the tool is naïve and still to be veriﬁed for differ-
ent subject systems. Hummel et al. [90] introduced an incremental
algorithm for model clone detection. A Simulink/Matlab model is
pre-processed by ﬂattening the model into a directed multigraph.
Then, relevant edges and blocks are labeled. A clone index is cre-
ated for all subgraphs of same size. Canonical label of all subgraphs
in the clone index is calculated and similar labels are hashed. Clone
retrieval and index update are integrated for fast retrieval. It has
not been veriﬁed on large models.
It is still to be veriﬁed whether canonical matching and vector
based approach can be applied on other graph based models like
UML models. We observed one study by Deissenboeck et al. [49]
highlighting the practical issues to be resolved in model clone
detection. The study pointed out that ranking of clones may help
in improving scalability and relevance of model clones. A compre-
hensive model clone detection tool for UML models and other data
ﬂow languages is missing. Different forms of models have individ-
ual features which need to be exploited for clone detection. A map-
ping of UML constructs from syntactical to semantic domain may
help in detecting clones having same behavior but different syntac-
tical structure. We noticed a vagueness in the deﬁnition of model
clones which hinders understanding of the topic area.
4.3. Key sub areas
We categorized the literature related to software clones in six
different yet allied areas. We realized that different identiﬁed cat-
egories are very important from the research perspective in the
ﬁeld of software clones. Although many sub areas overlap each
other, we have tried to separate them into self contained topics.
Cross cutting studies in some of these key areas are included in a
clone management systematic map constructed to answer re-
search question 4 in Section 4.4.3 (see Fig. 4 ). Details of theseTable 10
Model based clone detection and ﬁndings.
Liu et al. [155] Pham et al. [182] Deissenboeck et al. [47] Herald Storrle
[209]Hummel et al. [90]
Preprocessing/normalizations Two dimensional
sequence diagrams intoone dimensional arrayTransformation of models
to graphs, assigning labelsto relevant blocksTransformation of
models to graphs,assigning labels torelevant blocksXMI ﬁles from
UML domainmodelsTransformation of
models to graphs,assigning labels torelevant blocks
Source representation One dimensional array Sparse, labeled directed
graphLabeled multigraph Prolog code Directed, labeled
multigraph
Clone matching technique Sufﬁx tree Canonical matching,
vector based approachMaximum weighted
bipartite matchingModel
matchingCanonical matching,
clone index based
hashing
Advantages High precision and
recallAlgorithm is able to detect
model fragments withmodiﬁcations,incrementalScalable Supports
refactoringIncremental,
distributed, fastdetection time
Disadvantages Works only for
sequence diagramsLower precision Large number of false
positivesComplex java
implementationInfeasible for large
subgraphs
Application area Sequence diagrams Matlab/Simulink models Matlab/Simulink/
Targetlink modelsUML domain
modelsMatlab/Simulink
models
Model clone granularity Extractable fragment of
a sequence diagramNumber of blocks Number of blocks Sub models Sub models
Tools DuplicationDetector ModelCD CloneDetective MQ
lone Integrated in ConQATD. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1181
studies have been discussed in their respective key areas to make
the corresponding key area complete in itself. This is done to help
researchers to pursue further research in these sub areas.
4.3.1. Code clone evolution
Code clone evolution depicts the patterns in which the code is
developed throughout the history of the software. Other interest-
ing patterns of clones by evolution of software through different
versions are also covered in clone evolution.
As software evolves with time and introduction of newer ver-
sions, so clones present in the software evolve too. Laguë et al.
[144] pioneered clone evolution analysis using metrics based func-
tion clone detection technique for large telecommunication moni-
toring system of 1 million LOC. Two changes, viz. preventive
control (to keep the introduction of newer clones in system under
control) and problem mining (to cope with the existing code clones
in a system under continuous development and maintenance) are
studied to assess their impact on clone detection design. Both the
changes can effectively improve clone management. Antoniol
et al. [3,4] analyzed different versions of the Linux kernel to check
the changes in cloning patterns. In an earlier study [3], the author
modeled the time series by analyzing clones over several versions
of software. Shawky and Ali [206] modeled clone evolution using
chaos theory. The study predicted clones in new versions of open
source systems with high prediction accuracy. Di Penta et al. de-
vised a framework, i.e. Evolution Doctor [50,51] to control software
system evolution. It deﬁnes a set of methods and tools to deal with
removal of clones, restructuring and reorganizing the source code.
Code clone genealogies approximate how programmers create,
propagate and evolve code clones [124,126] . Saha et al. [197] car-
ried out an empirical study to evaluate and understand clone gene-
alogies in 17 open source software systems in four different
languages at release level. Their study isan extension to a study
by Kim et al. [124] . Unlike [124] , this study analyzed the evolution
of clones at release level. It used CCFinderX , a token based clone
detection tool. A location independent approach was used to match
identiﬁer names across releases. The clone genealogies were classi-
ﬁed as alive genealogy, dead genealogy, syntactically similar gene-
alogy and consistently changed genealogy.
Clone Evolution View [11] was developed to work with a metrics
based clone detection tool to study how developers copy across
different versions of a program. Livieri et al. [156] carried out evo-
lution analysis of 136 versions of Linux kernel using code clone
coverage metrics. They used D-CCFinder , a distributed extension
of code clone detection tool CCFinder . Aversano et al. [6]performed
an empirical study using SimScan , a syntax based clone detector, ontwo open source Java systems. They deﬁned three clone evolution
patterns to study the effect of maintenance activities on clones.
Bakota et al. [12] attempted to connect separate clone instances
across different versions of the software based on similarity mea-
sure. The clone detection is carried out by the clone detection tool,
clones [134] . The concept of dynamic code smells is introduced
which deﬁne the conditions under which a clone becomes suspi-
cious compared to its other occurrences.
Krinke [139] pioneered the argument that clones have a bad
impact on software maintenance. In ﬁve large open source sys-tems, the author traced the changes across 10 weeks. The study
showed that clone groups are continually changed in 50% cases.
Lozano et al. [158] analyzed clones at method level. CloneTracker
was applied to measure the number and density of changes in
two cases, i.e. during the presence of cloned code in methods
and not. The study observed that cloned code methods need to
be changed more frequently than non-cloned code. Lozanoet al. [159] presented a way to perform origin analysis and assess
the effect of cloning on methods’ maintenance effort. The study
computed measures of likelihood and the impact of change as
they represent the work required for maintaining a method.
The study concluded that change effort increases when a method
has clones. In another study [160] a resilient approach to track
clone instances over time is presented. Extension, persistence
and stability in methods were the chosen metrics to assess the
cloning imprint and impact of clones on changeability of the
application. In sample subject systems, the study concluded that
cloning extension remains stable in 10–20% of the application.
Otherwise cloning presents low stability, high persistence and
low extension.
An ethnographic study of clones in object oriented program-
ming paradigm was carried out by Kim et al. [122] . Software devel-
opers’ copy and paste programming behavior was captured with
the help of a logger. The study observed that language limitations
and programmers intentions promote clones. The study pointed
out the use of copying and pasting in understanding and restruc-
turing source code. Detailed evolution analysis of type-1 clones
was carried out by Göde [69]. The study included 200 revisions
of nine open source systems. He found that the lifetime of clones
decreased on average. The minimum clone length and program-
ming language had little impact on the results but the lifetime of
fragments differed between the systems.
4.3.2. Code clone analysis
This topic covers studies related to refactoring of code clones
based on code clone classiﬁcation or detection. Many software
Fig. 3. A time based count for key areas.1182 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
renovation frameworks work on improving software by miniatur-
ization of code, i.e. clone removal. Some studies investigated clon-
ing patterns. These are also included in this domain.
Fanta and Rajlich [60] used CloneDR ,dup, and CLAN to develop a
re-engineering process intended to eliminate clones from a pro-
prietary software of the Ford Motor Company, i.e. Powertrain Engi-
neering Tool sized at 120 KLOC. The study pointed out
disadvantages of clones. Balazinska et al. [9,10] developed a clone
re-engineering tool CloRT which works with any AST based clone
detector. Their analysis focused on two aspects of clones, i.e. themeaning of their differences from programmers’ point of view
and context analysis which help in refactoring. The study con-
cluded that clones are good candidates for refactoring. The clone
analysis tool Gemini [225] takes the output of CCFinder and displays
the results in the form of scatter plot and metrics graph. The tool
provides users with useful functions for analysis, maintenance
and refactoring of code.
Higo et al. [78,79,82] suggested code clone analysis based on a
refactoring perspective. The tool ARIES gives indicators for certain
refactoring methods in the form of metrics from the output of
Fig. 4. Clone management map.D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1183
CCFinder . It helps in merging code clones. In one study [80], a tool
Libra is developed for simultaneous modiﬁcation based support
method. Libra helps in ﬁnding clone candidates for the input ﬁle se-
lected by the maintainer.
Kapser and Godfrey [117,118] observed that code clone detec-
tion tools produce large result sets hindering in-depth investiga-
tion of any subject system. They carried out the study on the
Apache web server to gain insight into cloning patterns and under-
stand cloning behavior. The study concluded that cloning usually
occurs in related subsystems. Kapser and Godfrey [120] used CLICS
to determine clone characteristic and location patters. Cloning pat-
terns are deﬁned by what, why and how cloning takes place. In the
sample subject system, the study concluded that patterns have
good impact on a software system if used carefully. Quo et al.
[183] stressed the need to shift the onus of pattern mining of
clones from spatial space analysis to logic domain analysis. The
authors use a PDG as the source code representation and propose
a joint space-logic domain framework for pattern mining. The pro-
posed approach mines two lists of patterns: one ordered by reused
times and other by size of patterns. Former patterns provide good
inputs for code optimization. The tool helps in locating related de-
fects across identical pieces of code.
Tairas et al. [212,217,218] developed CeDAR (clone detection,
analysis and refactoring) which takes the output from CloneDR
and other clone detection tools. It helps in refactoring of detected
code clones. Tairas and Gray [219] applied latent semantic index-
ing to ﬁnd relationships in clone classes, thereby helping in cluster-
ing and maintenance of clones. Clone detection was done with the
help of CCFinder on a sample subject systems viz. MS Windows NT
source code kernel. In one study, Tairas et al. [221] used CeDAR to
represent clone groups in a localized manner and information
about each clone in a group could be viewed in one location. Each
clone in the group is represented as an abstract syntax tree, after
then sufﬁx tree is used to trace similarities and differences. The
technique is capable of ﬁnding near miss clones and uses Deckard
as a back end. Deckard was also used for sub-clone refactoring
[220] in open source software artifacts.
Jarzabek and Li [97] found out that 68% of code in Java Buffer li-
brary, JDK1.5 was contained in cloned classes or class methods.
Manual investigation of situations leading to clones revealed difﬁ-
culties in their elimination. The authors proposed a generative pro-
gramming technique of XML based variant conﬁguration language
(XVCL ) to analyze and represent clones. Tiarks et al. [222] found a
large number of false positives, i.e. as high as 75%. This has an ad-
verse impact of clone understandability. It also hinders the use of
clone detection for practical purposes. Respective studies were car-
ried out to detect and remove code clones from Erlang/OTP [153]
and Haskell [27] programs. Jacob et al. [95] used different mecha-
nisms to compute differences in clones. Their study used metrics
and the Levenshtein distance to display the changes interactively
in the code to the developer.
Juergens and Göde [107] successfully used clone coupling to de-
tect relevant clones from a large number of false positives. The
clone detector is re-run to improve accuracy by removing false
positives. Shawky and Ali [205] assessed a set of metrics for simi-
larity prediction for clone detection. Precision and recall were cal-
culated for every experiment. They concluded that the order in
which metrics are used for clone detection affects results.
Krinke et al. [140,141] analyzed the version control system to
distinguish the original from the copied code. Each clone pair is
classiﬁed as identical, copied or unclassiﬁable. The clones of a clone
pair are said to be classiﬁable with a tolerance based on the
Levenshtein distance. In a particular case study [141] for GNOME
projects, more than 60% of the clone pairs could be separated into
original and copy. Increasing the minimal clone size in the clone
detection tool, i.e. Simian , the number of clone pairs decreasedasymptotically. Choi et al. [38] used a combination of clone metrics
to extract code clones from the source code ready for refactoring.
The metric graph of Gemini was used to analyze the output of
CCFinder using metrics namely: average length of token sequence
in a clone set, ratio of non-repeated token sequences of code clones
in a clone set, number of code clones in a clone set. Basit et al. [15]
analysed patterns of clones in STL using CCFinder . The study reports
a high rate of cloning in container classes and signiﬁcantly less in
algorithms of STL. The authors proposed an XML-based variant
conﬁguration languages based clone free representation for STL’s
under study. In another work, Basit et al. [18] carried out a study
to analyze the presence of simple clones in structural clones. They
used the clone detection tool, Clone Miner . Across a comprehensive
set of 11 subject systems, structural clones are analyzed to identify
their location, similarities, etc. The analysis of structural clones, i.e.high level similarities is intended to help in understanding, refac-
toring and maintenance of the software system. The study con-
cluded that over 50% simple clones were a part of structural clones.
4.3.3. Impact of software clones on software quality
Do clones have adverse effect on system quality, i.e. maintain-
ability, reliability, etc.? This has been a matter of extensive discus-
sion in research community. This section summarizes the related
studies on whether the clones are harmful or not in the form of a
table. In this section, we also include studies concerning detection
of bugs as side effect of cloning and inconsistent modiﬁcation.
Monden et al. [172] used ARIES to discover the relation between
software clones and software quality attributes like reliability and
maintainability. The study concluded that modules (ﬁles) having
large code clones (more than 200 LOC) are less reliable and main-
tainable than non-clone modules. Imai et al. [91] estimated the
maintenance cost caused by clones. The study measured functional
redundancy which is a degree of propagation of clone potential
function. After clustering, a functional redundancy tree is con-
structed where the weight given to each node of the tree indicates
cost.
Krinke [142] carried out an important study to compare the sta-
bility of cloned code and non-cloned code. He studied changes par-
ticularly deletions, additions and changes of ﬁve open source
systems across 200 weeks in cloned code and non-cloned code.
This study was extended by Göde and Harder [71] using different
parameters and detailed measurements. They concluded that clone
detection parameters inﬂuence the results but do not change the
relation between stability and non-stability. They also concluded
that type-1 clones are less stable than type-2 and type-3 clones.
In another study [72], they analyzed patterns of consecutive
changes to clones and their impact on unwanted inconsistencies.
The study concluded that consecutive changes are not good choiceto detect unwanted inconsistencies. Moreover detected unwanted
inconsistencies had very low severity. In addition to [142,71] ,
Krinke [143] investigated the age of code as a parameter for clone
stability. He calculated the average age of cloned code and con-
cluded that cloned code in a ﬁle is usually older than non-cloned
code, thus more stable.
Table 11 lists the related studies on whether the clones are
harmful or not. In addition to the studies which analysed the rela-
tion between code clones and software quality to know the impact
of clones, we also listed some studies like Kapser and Godfrey [120]
which categorized the cloning patterns to be harmful or harmless.
Some of the studies mentioned in the table are discussed in othersections of the paper.
It is always problematic to identify consistently changing clones
over time. Thus a clone tracking and awareness tool is essential to
assist software developers in efﬁcient maintenance of software.
Jablonski and Hou [94] identiﬁed features of CnP which help in
cutting software maintenance costs. Clone information during1184 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
software development helps programmers in modiﬁcation and
debugging tasks. Visualization and renaming features, i.e. CReN
and LexID ofCnPwere tested thoroughly. The study showed the ef-
fect of clone information on maintenance. Bettenburg et al. [21] ex-
plored the effects of inconsistent changes to code clones on
software quality at release level through an empirical study. Devel-
opers usually carry numerous changes in different parts of soft-
ware systems across releases. They are usually interested in
source code at release level.
Earlier studies investigated the impact of code clones at much
ﬁner granularity level. Duala-Ekoko et al. used Clone Region
Descriptor [53] approach to track code clones across releases. All
clone genealogies found were manually inspected for inconsistent
change. Juergens et al. [108] carried out clone detection to ﬁnd
copy and paste activities in requirements speciﬁcations docu-
ments. Large documents are used to detect any redundancy, there-
by assessing the quality of speciﬁcations. The comprehensive study
was carried out across 28 documents with 9000 pages, ﬁxing clone
length to be 20 words. Rahman et al. [184] carried out an empirical
study to investigate the impact of code clones on defects in code.
The clones were not found to be particularly error-prone. Clonedetection tool, Deckard and data mining from version control and
bug repositories were used to carry out the study. Göde [70] found
that most of the clones detected by state of the art clone detectors
need not be removed. His study has signiﬁcant implications from
point of view of software maintenance. With standard subject sys-
tems as input and an incremental clone detector tool, the study
identiﬁed procedure extraction as the most commonly used refac-
toring method. Kozlov et al. [137] explored internal quality attri-
butes and code clone detection metrics. For all 117 releases of
peer to peer open source software namely, eMule, a software pro-
ject fork, internal quality attributes were measured using SoftCalc
tool and code clone detection metrics were extracted using CCFind-
erX. Statistically signiﬁcant correlations across groups were identi-
ﬁed based on the Pearson product moment correlation. The study
was based on a number of hypotheses taken from prominent clone
detection studies using metrics. The study concluded that internal
quality attributes act as explanatory variables for code clone detec-
tion metrics. Selim et al. [204] used survival models to study theimpact of clones on software defects. The probability of occurrence
of a defect at any time was modeled using Cox’s proportional haz-
ard function. The study used a set of predictors to classify clones as
helpful or harmful. The study was the ﬁrst of its kind to use Spear-
man correlation between actual and predicted occurrences of de-
fects. It explored a new set of predictors related to code siblings
at method revision level. They concluded that cloned code is not al-
ways more risky than non-cloned code.
Copied code leads to inconsistencies at multiple places when a
bug is introduced in the original code fragment. Automatic detec-
tion of these bugs has turned to be an allied area effecting the qual-
ity and maintainability of source code. Li et al. [152] pioneered
defect detection in clones using CP-Miner . The technique was able
to detect code duplications and related bugs using a frequent sub-
sequence mining technique. However, the tool reports many false
positives. Jiang et al. [99] stated that inconsistencies emerge when
code is copied to a new place and appropriate changes are not
made with reference to new context. They used Deckard to detect
context based clone related inconsistencies (bugs). The approach
was able to discover previously unknown bugs and the results
were compared with CP-Miner . Hayase et al. [76] introduced a ﬁl-
tering technique to reduce the false positives generated by CP-
Miner .CCFinder
was used to ﬁnd identiﬁer naming inconsistencies
and CP-Miner was used to ﬁlter code clone related bugs. Yoshida
et al. [233] used lexical analysis and identiﬁer similarities to detect
duplicate code. The technique helps in detecting code fragments
with similar defects. In a similar study, Yoshida et al. [235] de-
tected similar defects in source code based on comparison of syn-
onymous identiﬁers using the Jensen–Shannon divergence
method. Clustering of identiﬁers was based on distance between
identiﬁers. They also compared their results with CCFinder on the
same subject systems. Juergens et al. [106] introduced the CloneDe-
tective framework to detect inconsistencies. The study pointed out
that inconsistent clones lead to faults. In the sample subject sys-
tem, 58% of the clones contain inconsistencies. Gabel et al. [64]
introduced DejaVu , a tool to detect inconsistent bugs. Firstly simi-
lar code fragments are found using a Deckard based clone detection
framework. Later on, buggy change analysis is done to classify be-
nign and buggy inconsistencies from the clone detection data set.Table 11
Studies related to whether the clones are harmful or not.
Sr.no.Study Focus of the study Findings/results
1 Monden
et al. [172]Relation between code clones and software reliability and
maintainabilityClone included modules are more reliable and less maintainable than non-cloned
modules
2 Kim et al.
[122]Analysis of programmers’ copy and paste programming
practicesCloning is not always harmful as many of the clones are intentionally introduced by
the programmer which helps in fast development and program understanding
3 Lozano et al.
[158]Analysis of harmfulness of cloning based upon change
based experiment at method level granularityClones are harmful and have bad impact on maintenance
4 Kapser and
Godfrey
[120]Categorization of cloning patterns in programs to know
whether they are useful or notCloning is not always harmful and some of the cloning patterns are beneﬁcial to
software development and maintenance
5 Krinke [142] Analysis of stability in terms of changes to the system
from an analysis of 200 weeks of evolutionCloned code is more stable than non-cloned code
6 Juergens
et al. [106]Analysis of inconsistent changes to code clones and
whether these changes lead to defectsInconsistent clones are a major source of faults thus increasing maintenance
7 Juergens
et al. [108]Clone detection is done in requirement speciﬁcation
documents by customizing code clone detection toolCloning is harmful in requirement speciﬁcation documents
8 Rahman
et al. [184]Analysis of relationship between cloning and defect
pronenessCloning do not introduce more bugs thus not harmful
9 Selim et al.
[204]Whether cloning is harmful? What features of cloned
code make it error prone?Harmfulness of cloning is subject system dependent.
10 Bettenburg
et al. [21]Analysis of effect of inconsistent changes to code clones
on software quality at release levelCloning do not effect post release quality of the subject system
11 Göde and
Harder [71]Analysis of stability of the software system in terms of
deletions to the cloned code and non- cloned codeCloned code is more stable than non-cloned code
12 Krinke [143] Analysis of stability of the software system using average
age of cloned code in comparison to non-cloned codeCloned code is more stable than non-cloned codeD. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1185
The potential bugs are classiﬁed as: bugs, code smells, style smells,
unknown, false reports. Jalbert and Bradbury [96] used clone
detection and rule evaluation to identify bugs in concurrent soft-
ware. They tried to reduce the domain of testing by using clone
detection. An identiﬁed bug is input to ﬁnd similar bug patterns
in concurrent software.
4.3.4. Clone detection in websites
Websites, i.e. web applications are usually multilingual and suf-
fer from short development life cycles. Changing requirements fre-
quently leads to introduction of clones. Many studies conﬁrm the
presence of clones in websites. The extent of cloned code varies
from 30% [211] to as much as 63% [185] .
Aversano et al. [5]proposed reuse of existing sites by means of
cloning and adaptations from a repository of conceptual views andcode components. Lucca et al. [161] presented an approach to de-
tect duplicate web pages using similarity metrics. They proposed
reﬁning the results of similarity metrics using the Levenshtein dis-
tance between each pair of analyzed HTML strings. Lanubile and
Mallardo [146] conducted a study to detect script function clones
using metrics. The study was conducted on three sample subject
systems and found 39–50% of the total script functions to be
clones. Synytskyy et al. [211] and Cordy et al. [41] used island
grammar for simultaneous parsing of multilingual web applica-
tions. They used UNIX diffcommand to compare potential clones.
The method is able to detect near miss clones. Lucia et al.
[162,163] proposed a method to identify cloning patterns in a
web application. The method was based on clone detection using
similarity thresholds. The technique was helpful in clone analysis
and reducing the code size and navigational patterns of a web
application.
Rajapakse and Jarzabek [185] used CCFinder to detect patterns
of clones in websites. Authors extended the study further [186]
to unify most of the clones using server pages. This helped in
reducing code size and the possibility of update anomalies. Differ-
ent clustering algorithms and latent semantic indexing were used
by Lucia et al. [164] to detect clones in web applications. The tech-
niques were tested on different static web sites. Different cluster-
ing algorithms produced comparable results. Jung et al. [111]
explored three levels of views namely, relationships between
web applications, passed parameters and target applications for
detecting clone pairs in a web application. Clone pair candidates
were selected based on static and dynamic approaches. The com-
bined approach was successfully validated on two open source
projects. Martin and Cordy [169] introduced the concept of contex-
tual clones, i.e. clones that can only be found by augmenting code
fragments with related information referenced by the fragment to
give its context. They proposed a technique to leverage the idea ofcontextual clones to detect similarities in web service description
language.
4.3.5. Cloning in related areas
Duplication is also prevalent among other software artifacts like
requirement speciﬁcations and binary executables. Such studies
are included in this category. Studies of different applications of
clone detection are included in this category too.
Software archives contain large amount of similar software.
Kawaguchi et al. [121] applied a code clone based similarity metric,
a decision tree based approach and latent semantic analysis based
approach to categorize similar software in an archive. The tech-
nique helps to identify relationships among software systems.
Gallagher and Layman [65] found similar decomposition slices,
i.e. slice clones. A decomposition slice is a program slice which cap-
tures all relevant computations from a given variable. The study
presented the negative and positive points to identify slice clones
as software clones.Domain analysis is usually carried out in device drivers to
search for similar implementations. Ma and Woo [165] used
CCFinder to detect clones within the ﬁle and across ﬁles in device
driver source ﬁles. Mao et al. [167] used table recognition technol-
ogy and clone detection to convert conventional table-based web-
sites to modern cascading style sheet websites. Software clone
detection was used to detect common layout styles in pages. Ger-
man et al. [66] studied technical and legal implications of cloning
in code siblings when there is license compatibility between copy-
right owner and destination. Monden et al. [173] chose metrics
with a lower bound on code clone measurement threshold to
determine violations in open source licensing. Fifty open source
subject systems were chosen from free software directory to trace
violations. Brixtel et al. [26] used clone detection tool for checking
plagiarism in student projects and assignments. They tested theirtechnique on projects using different languages. Davis and Godfrey
[45] used assembly instructions to detect source code clones.
Software product lines have a core part around which its differ-
ent components are built. Dalgarno [43] applied clone detection in
a product line context. Mende et al. [171] applied token based
clone detection and the Levenshtein distance to identify similar
functions which make the core part in software product lines.
Schulze et al. [201] identiﬁed clones in feature oriented software
product lines. Using CCFinder , a signiﬁcant number of clones were
detected in 10 subject systems. They discussed reasons for cloning
in feature oriented software product lines and the way most of the
clones can be refactored. Domann et al. [52] used the CloneDetec-
tive [105] framework to ﬁnd instances of clones in 11 software
requirement speciﬁcation documents of 2500 pages. Clones in bin-
ary executables were detected by Saebjornsen et al. [196] . This tree
based approach worked by clustering of characteristic vectors on
labeled trees. Ciancarini and Favini [39] carried out a study to de-
tect clones in game playing software. They found a criterion to
judge similarities in game playing software with chess as an exam-
ple. Juergens et al. [108] investigated the amount and nature of
duplicated text in software requirement speciﬁcations using Clon-
eDetective tool. After detecting duplications in 28 software require-
ment speciﬁcation (SRS) documents of 8667 pages,
recommendations were given for working with SRS in practice.
Whaley and Lam [229] applied cloning in pointer alias analysis
by creating clones of methods. They used binary decision diagrams
to achieve context sensitive results.
4.3.6. Software clone detection in aspect oriented programming/cross-
cutting concerns
Aspect-oriented programming (AOP) was a response to the
problem of cloned code relating to cross-cutting concerns (e.g.
logging, and error-handling) in object-oriented systems. Thedetection of code that should be refactored into an aspect is an
important part of AOP.
Yokomori et al. [232] analyzed the relationships between as-
pects to understand how the behavior of existing code clones in
original classes spread to aspects. The study used CCFinder to de-
tect code clones. The study concluded that number of clone rela-
tions between class and aspect increases if only one part of clone
group is extracted. Bruntink [28] used clone metrics to ﬁlter clone
detection results to detect aspect candidates. A grade was associ-
ated with each clone class to rank its suitability in improving main-
tenance. Bruntink et al. [29] conducted a study where the token-
based CCFinder, AST-based ccdiml and PDG-based PDG-DUP were
evaluated in terms of ﬁnding cross-cutting concerns in C programs
with homogeneous implementations. Some well known cross-cut-ting concerns such as error handling, tracing, range checking, null-
value checking and memory error handling were found. Their
study showed that both ccdiml and CCFinder are best suited for
null-value checking and error handling concerns while ccdiml is1186 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
also suitable for the range checking concern. PDG-DUP can ﬁnd
tracing and memory handling concerns. The study conﬁrmed that
code clones contribute 25% of the code size in aspects. Schulze
et al. [200] used code clone classiﬁcation to decide whether to
use object-oriented refactoring or aspect-oriented refactoring.
Code clone classiﬁcation was done by adding semantic information
to clone detection tool.
Fig. 3 shows the number of publications in different key areas in
the years 1997–2011. Different trends can be seen for different key
areas. Research in the area of impact of clones on software quality
rose most dramatically in 2010 from a single study in 2009 to ten
studies in 2010. The number of publications in area of code clone
analysis grew sharply, almost doubling from about one study in
2007, two studies in 2008, ﬁve studies in 2009 and eight studies
in 2010. The research in the key areas of code clone analysispeaked in 2010. It shows the improvement in recognition and need
of research in these areas recently. On the contrary, research in
area of clone detection in AOP comprised the smallest numbers.
On the other hand, number of publications in the key areas of clone
detection in websites, cloning in related areas and code clone evo-
lution remained stable throughout the years.
4.4. Current status of clone management
Clone management is a set of activities like clone classiﬁcation,
refactoring, visualization, tracking and evolution. It plays a pivotal
role in development and maintenance process. Some of the bene-
ﬁts of clone management are discussed in Section 4.4.1 . However,
it also overlaps with clone analysis, clone evolution, and impact of
clones on software quality which are discussed in Section 4.3.
4.4.1. Beneﬁts of clone management
In literature, we came across many studies which discussed
beneﬁts of clone management. Some of the ﬁndings are:
/C15Laguë et al. [144] identiﬁed that an effective clone management
strategy improves customer satisfaction and software system
quality.
/C15Kim et al. [122] pointed out that many clones are intentionally
introduced in code due to language restrictions. Thus refactor-
ing after clone detection may not improve the software. So it
is more important to manage the clones to see how they evolve
over time. Moreover, clone management in an Integrated Devel-
opment (IDE) makes developers concerned about duplication.
The developer should be informed in the IDE about all the
clones which are introduced deliberately due to hard time con-
straints, etc.
/C15Kapser and Godfrey [120] identiﬁed cloning patterns which are
helpful in improving the quality of the system. They found that
as many as 71% clones had a positive impact on the maintain-
ability of the software. They stressed the importance of manag-
ing code clones using synchronous maintenance of code clones.
/C15Duala-Ekoko and Robillard [53] proposed managing code clones
by notifying developers of modiﬁcations to clone regions. They
developed a clone tracking system which works as the system
evolves.
/C15Jablonski and Hou [94] concluded that clone awareness with
visualization and consistent identiﬁer renaming support help
developers during debugging and modiﬁcations. The study
highlights the importance of clone management.
We highlight the importance of clone management by showing
the percentage of cloned code from selected studies. Studies are se-
lected to show different clone detection techniques and subject
systems. It reﬂects the percentage by which the code can be shrunk
in software (see Table 12 ).4.4.2. Clone management – a cross cutting and an umbrella activity
Code clone management is an umbrella activity covering all as-
pects regarding clones. It is a superset including clone analysis,
clone evolution, code clone taxonomies, code clone classiﬁcation,
etc. It also covers code clone visualization. We discussed here those
studies which focused on clone management and clone visualiza-
tion. Moreover, the relevant information is spread across many
themes addressing research question 3 in Section 4.3.
Balazinska et al. [8]focused on restructuring and reengineering
software after successful clone detection. Using six open source
subject systems written in Java, method clones were manually ana-
lyzed for reengineering opportunities. Higo et al. [77] provided a
technique to identify meaningful blocks in code clones that are
easy to merge. They used CCFinder to detect code clones. The tech-
nique is helpful in reducing number of clone pairs detected in twoopen source Java systems. Kapser and Godfrey [116] investigated
two large subject systems to classify code clones, viz. function
clones and partial function clones. The authors suggested manage-
ment of code clones by classiﬁcation and ﬁltering false positives.
CReN [93] developed by Jablonski and Hou provides programmers
with identiﬁer renaming support and tracking of clones in an inte-
grated development environment. The authors extended their
work in the form of CnP [92].CnP [86,87] is intended to support
and manage clones proactively as they are created and evolved.
The tool was developed as Eclipse plug-in.
Tairas [216] proposed a technique to unify clone detection,
analysis and refactoring. The study presented a method to improve
clone maintenance by eliminating redundant code by identifying
refactoring opportunities. Nguyen et al. proposed Cleman [174] ,a
framework for comprehensive code clone group management in
evolving software. They developed Clever [175] , a clone aware soft-
ware conﬁguration management system which works with any
AST based clone detection tool. It performs umbrella activities like
clone detection, clone change management, clone consistency val-
idating, and clone merging. Duala-Ekoko and Robillard developed
CloneTracker [54] to track clones during the evolution of source
code. It uses SimScan as clone detection tool. The authors used
CloneTracker to produce clone region descriptors (CRDs) [55] which
are an abstract combination of lexical, syntactical and structural
information. Clones are tracked using CRD which represents a
clone region for different clone groups which are of interest to a
developer. This approach goes beyond code based clone descriptors
in integrated development environments like CReN .CloneBoard
[46] is a clone management tool which infers clone relations
dynamically by monitoring clipboard activity. The tool is inte-
grated in Eclipse to support copy pasted clones. Lee et al. [151]
introduced a scalable and instant code clone search technique for
use during software development. The technique works by extract-ing characteristic vectors from the source code. Then a multidi-
mensional indexing tree structure R ⁄tree is used. In the index,
ﬁltering and ranking is used to evaluate code clone detection que-
ries in order. The authors also devised an approximate clone detec-
tion technique which is fast but less accurate. Both the algorithms
gave sub second response time for processing a million lines of
source code.
4.4.2.1. Clone visualization. Code clone visualization is one of the
most important areas of code clone management after successful
code clone detection. With the increase in duplication in various
software artifacts, e.g. source code, proper representation of soft-
ware clones has become a challenge. This domain covers presenta-
tion of duplicated code which helps in fast analysis of clone
detection results.
Several clone detection tools report the presence of clones in
form of starting and ending line number, ﬁle name, etc. One of
the widely accepted formats for representation of clones is scatterD. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1187
plot. Tairas et al. [213,215] extended the AspectJ Development Tool
visualizer to display the results of CloneDR in Eclipse framework.
The main application of the tool is to display the cross cutting con-
cerns in aspect oriented programs. Adar and Kim [1]developed
SoftGUES S which supports exploration and visualization of code
clones. Their system supported different views of analysis of clones
over single and multiple versions, through analysis of graphs. Jiang
and Hassan [101] developed a Clone System Hierarchical Graph ,a n
interactive graph used to select nodes to highlight how the clones
are scattered in a particular directory. They used clone mining to
highlight clones at different levels of abstraction.
Most of the clone visualization tools like Gemini [81] read the
output of CCFinder . These tools ﬁlter uninteresting code clones
and navigate to clones having features the users are interested
in. Zhang et al. [236] developed a standardized graphical represen-
tation as an Eclipse plug-in called Clone Visualizer to ﬁlter and visu-
alize the output of Clone Miner . Fukushima et al. [62] used a code
clone graph to visualize the output of CCFinder . Nodes of a code
clone graph correspond to code clone sets and edges represent
clone sets in the same ﬁle. The technique helps in representing dif-
fused clones in which clone set clusters are located in ﬁles having
different functionality. Tairas [217] presented a technique in which
one clone instance displays the properties of all the clones in the
clone group. The technique was integrated as an Eclipse plug-in
called CeDAR (Clone Detection, Analysis and Refactoring). This rep-
resentation help in refactoring as clone group representation dis-
plays the difference among clone instances.
4.4.3. Clone management: a systematic map
Clone detection tools are applied to detect clones after the soft-
ware development is completed in a postmortem approach of
clone management. But even the leading clone detection tools re-
port a large number of false positives. So recently, researchers and
practitioners have tried to make clone detection an integrated part
of development environment to increase the effectiveness of clone
management. Developers need to be informed online as and whenclones proliferate.
Clone management is a cross cutting topic touching different
domains of software clones. We identiﬁed four key areas in this
systematic literature review, i.e. clone analysis, clone evolution,
impact of clones on software quality and clone visualization which
touch clone management. The ﬁrst of these three key areas has
been discussed in detail in the context of research question 3.
The papers from these key areas were studied to identify relevant
sub topics of clone management facet below:
1. Code clone classiﬁcation.
2. Code clone refactoring.
3. Code clone visualization.
4. Code clone tracking.
5. Code clone evolution.
We used the systematic mapping method of Petersen et al.
[181] to map clone management papers with clone detectionmethod papers and clone detection tool papers. From the set of pri-
mary studies, we identiﬁed 49 relevant papers. Papers were classi-
ﬁed based on these three different facets and the results are
presented in the form of bubble plot as shown in Fig. 4 .
The bubbles show the number of publications identiﬁed for
each clone management facet with clone detection method facet
and clone detection tool facet. Total number of papers on either
side of the map is not equal as many clone detection tools use
more than one method for clone detection. Our bubble plot shows
that the majority of research is in clone refactoring using the suf-
ﬁx tree and dynamic programming methods of clone detection.
The metrics/characteristic vectors method of clone detection is
frequently used in different sub topics of clone management.We observed the use of clip board operations as clone detection
method in clone tracking and visualization. This is due to the fact
that clip board activity captures in the initial creation of a clone
in an IDE. CCFinder
(X) is the most frequently cited tool. It has
been used for clone classiﬁcation, clone refactoring and clone
visualization as it is able to detect large number of clone candi-
dates with high recall. The map suggests a lack of research in
clone classiﬁcation. Barring CCFinder (X),SimScan ,CloneDR ,Dec-
kard,Simian , and CLAN , the rest of the tools are only used in
one or two papers.
4.5. Subject systems
We have observed that different subject systems are being used
in clone detection research. We are hopeful that the above table
may help researchers in choosing most commonly used subject
system as benchmark for evaluation and empirical studies. We list
28 open source subject systems that were subjects of different
studies. Table 13 lists all open source software systems and Ta-
ble 14 lists commercial systems. We also list approximate size in
LOC, programming language of the system and usage count. The
usage of the subject system according to our classiﬁcation of liter-
ature and citations is also mentioned in the table.
Recently clones in Matlab/Simulink models are detected by
[47,49,88,182] . Studies [48,49,88] have used common models
(SIM,MUL,SEM,ECW) available from Matlab central. The size of
the model in blocks varied from 440–18,000 blocks. Domann
et al. [52] and Juergens et al. [108] applied clone detection to 11
and 28 requirement speciﬁcations respectively from a total of
2500–8667 pages.
We have omitted those open source subject systems from Ta-
ble 13 which are only used in one study. Different versions of the
same program are mentioned in one place and the size of latest
version used in any study is included. For instance, different ver-
sions of Linux have been used by [16,113,152,193] , etc. These are
written in the one place and the largest size among them is
reported.
JDK has been used many times for clone detection and clone
analysis. The Apache web server and Linux kernel and its different
versions have been used extensively as subject systems to carry
out the clone detection and analysis study. Similarly, the softwareTable 12
Percentage of cloned code across different systems.
Sr. no. Percentage of cloned code (%) Subject system Size (LOC) Clone detection technique Citation
1 13–20 SS subsystem 1.1 M Token based [7]
2 5–20 Telecommunication monitoring systems 1 M Metrics based [170]
3 12.7 Process control system 400 K Tree based [22]
4 50 GCC and other application projects. 6.5–460 K Text based [56]
5 8.3–14.8 E-business website and resource management system 15–35 Sequence diagrams Model based [155]
6 20–50 Java source code, C# source code 425 K, 16 K Tree based [58]
7 14.9 SRS 2500 pages Text based [52]
8 12.1–32.1 Open source python systems 9–272 KLOC Hybrid [194]1188 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
system ArgoUML has been used in recent studies to investigate the
impact of software clones.
Subject systems in C (weltab, snns, postgresql) and in Java (net-
beans-javadoc, eclipse ant, eclipse-jdtcore and j2sdk1.4.0-javax-swing) used by Bellon’s experiment [20] are frequently used by
researchers. Most of the research is carried out using subject sys-
tems written in C and Java. This may be due to a lack of suitability
of tool for other languages. The efﬁciency of existing tools shouldTable 13
Open source subject systems.
Sr. no. Subject system Size (LOC) Language # Classiﬁcation Citations
1 JDK 3200 K Java 10 Clone detection [36,113,151,176,179,202,226]
Clone analysis [8,97]
Comparison and evaluation [202]
2 Apache-httpd 343 K C 9 Clone detection [68,125,150,152,193,194]
Clone analysis [120,140,184]
3 Apache-Ant 1.41 M Java 4 Clone analysis [18,82,221]
Impact of software clones [204]
4 ArgoUML 1.76 M Java 10 Clone evolution [6]
Clone analysis [140,221]
Impact of software clones [21,70,71,142,143,204]
Clone detection [68]
5 Linux 6.2 M C 10 Clone detection [16,34,74,89,113,152,193,194]
Clone analysis [101]
Impact of software clones [233]
6 Weltab 11 K C 7 Clone detection [57,129,180,193,194,214]
Clone analysis [205]
7 Netbeans-javadoc 19 K Java 7 Clone detection [13,59,84,193,194,203]
Comparison and evaluation [58]
8 jEdit 157 K Java 5 Clone detection [24]
Clone analysis [18,221]
Impact of software clones [21,143]
9 Bison 16 K C 5 Clone detection [59,130,134,138,193]
10 PostgreSQL 937 K C 6 Clone detection [59,125,134,152,193,194]
11 Snns 105 K C 5 Clone detection [59,134,180,193,194]
12 FreeBSD 403 M C 3 Clone detection [113,152]
Clone analysis [157]
13 ANTLR 61 K Java 3 Clone detection [179]
Clone analysis [8,18]
14 Eclipse-Ant 35 K Java 7 Comparison and evaluation [58,193,194]
Clone detection [13,59,68,84]
15 Wget 17 K C 3 Clone detection [59,193,134]
16 Cook 70 K C 3 Clone detection [57,180,193]
17 Abyss 1500 K C 3 Clone detection [193,214]
Clone analysis [205]
18 Tomcat 130 k Java 3 Comparison and analysis [148]
167 K Clone detection [24,147]
19 SQuirreL 218 K Java 3 Clone analysis [221]
Impact of software clones [71,142]
20 GCC 1.2 M C 3 Clone detection [56,68,104]
21 FileZilla 90 K C++ 3 Impact of software clones [142]
Clone evolution [206]
Impact of software clones [108]
22 Tcsh 45 K C 2 Clone detection [132]
Clone analysis [133]
23 Bash 40 K C 2 Clone detection [132]
Clone analysis [133]
24 CLIPS 34 K C 2 Clone detection [132]
Clone analysis [133]
25 Jabref 114 K Java 2 Clone detection [89,109]
26 DNSJava 25 K Java 2 Clone evolution [6]
Clone analysis [18]
27 Eclipse-jdtcore 148 K Java 8 Comparison and evaluation [58]
Clone detection [13,59,84,95,193,194]
Impact of software clones [142]
28 j2sdk1.4.0-javaxswing 204 K Java 7 Comparison and evaluation [58]
Clone detection [13,59,84,193,194]
Clone analysis [18]D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1189
be measured using other languages which the tools support. Re-
search up to the end of 2011 have predominantly been done on
open source systems. Few commercial systems have been used.
Clearly the use of open source systems is preferable from the view-
point of repeatability of experiments and also allows tool compar-
isons to be easily extended to cover new or amended tools.
5. Discussion
We surveyed 213 articles out of a collection of 2039 and pro-
vided categorization and quantitative overview. Unlike previous
surveys, we put an emphasis on clone management, model clones
and semantic clones and classiﬁed the literature from different key
areas. Existing surveys/technical reports by Roy and Cordy [187]
and Koschke [135] consider research ﬁndings till 2007. These sur-
veys ﬁlled the initial void for useful text for budding researchers in
this domain. The work by Roy et al. [192] focused on clone detec-
tion tools and techniques up to 2009. Pate et al. [178] presented
systematic review of existing literature on clone evolution. The
authors framed three research questions to investigate what meth-ods have been used to study clone evolution, to study cloning pat-
ters and to discover the presence of consistent/inconsistent
changes to clones during evolution. The authors identiﬁed 30 pri-
mary studies regarding clone evolution. Our focus is broader than
the earlier surveys and includes the latest research work related to
software clones up to mid 2011 using the systematic literature re-
view guidelines of Kitchenham and Charters [127] . In addition to
clone detection tools and methods, we have addressed other issues
related to software clone research such as clone analysis, clone
evolution, and impact of clones on software quality. We used a sys-
tematic method to develop a clone management map which iden-
tiﬁes how clone management papers overlap with clone detection
method papers and clone detection tool papers. We explored the
model based and semantic clones in detail and compared the state
of the art techniques. Moreover, major breakthroughs in model
clone detection happened after 2007. We presented all the studies
in different sections in chronological order which makes it easy to
identify the latest research carried out after 2007 as done in earlier
surveys.
This section discusses the principal ﬁndings of our systematic
review, strengths and weaknesses of the evidence. We begin with
the discussion of key sub areas followed by clone management.
Implications for researchers and practitioners are summarized
after that, followed by limitations of the review.
5.1. Key sub areas
We divided the literature into six different key areas realizing
the importance from research perspective. We noticed that some
of the areas are inter-related.
It is not an easy task to model clone evolution under a number
of versions. The prediction accuracy of the approach depends upon
parameters and their variation. Future research should consider
using sound mathematical modeling approaches. Many clonegenealogies are alive and long lived and clones are easy to manage
in smaller systems as compared to large systems. The area is still
open for research to study clone genealogies using state-of-the-
art clone detection tools in different sample subject systems.
A large numbers of studies conﬁrm the harmfulness of cloning
in software systems. Less research was found in tracing useful pat-
terns of cloning which help the programmer. We observed limited
number of studies investigating cloning patters in different pro-
gramming paradigms. More studies should be carried out to inves-
tigate the types of clones and their characteristics like persistence
over time in different programming methodologies. In the initial
years, we found few studies attempting to calculate the impact
of code clones on maintenance cost. We noticed increase in the
number of studies undertaken to compare the behavior of cloned
and non-cloned code and their impact on system quality during
last 2 years. Most of these studies use version control information.
However, these systems detect minor changes like white spaces
too, which should be ignored from the clones point of view. We
found contradictions among the papers and the area is still open,
since the number of subject systems is too low to arrive at any gen-
eral conclusion. Future research lies in carrying out the same study
with large number of comparison parameters, clone detection tools
and subject systems. Recently, many studies presented ﬁndingsthat clones in general do not have adverse effect on quality. At
the same time, we observed some contradicting studies. Such stud-
ies need to be extended using external quality attributes and a
large subject base. The nature of the subject system and program-
mers’ behavior has a profound effect on these studies. In one study,
varied results were noted for the ArgoUML and Ant subject sys-
tems. We need more studies to accurately calculate the increase
in maintenance cost of software due to presence of different types
of clones.
We found two studies that checked the presence of clones in
software requirement speciﬁcations. There is a need to conduct
clone detection studies to investigate redundancy throughout all
documents of software development life cycle. Such repetitions
when removed will lower the maintenance cost of the software
in earlier phases of software development life cycle. We found only
one study which applied clone detection to trace open source
licensing violations. Such studies will be helpful to distinguish be-
tween reuse based and accidently produced clones.
5.2. Clone management – a cross cutting topic
Different clone management tools should be evaluated depend-
ing upon use cases and future tools can be developed catering to
respective use cases.
The systematic map in Fig. 3 helps in identifying which sub top-
ics of clone management have been emphasized, which areas re-
quire further research, which clone detection tools and methods
have high usage in clone management. In the map, we did not ﬁnd
any papers involving more than one tool in any aspect of clone
management. This may indicate a lack of interoperability between
different tools for clone management. We ﬁnd a lack of work in
clone classiﬁcation. To assist the software maintainer, it is impor-Table 14
Commercial subject systems.
Sr. no. Subject System Size (LOC) Language # Classiﬁcation Citation
1 Government system 1 M COBOL and PL/1 1 Clone detection [113]
2 HagerROM (Würzburg University) 87 K Java 1 Clone detection [226]
3 DISLOG development Kit (DDK) 95 K PROLOG 1 Clone detection [226]
4 SPARS-J 47 K C 1 Clone analysis [157]
5 Commercial 460 K ABAP 1 Clone detection [89]
6 Commercial CAD 1.6 M C 1 Clone detection [230]
7 Graph-layout program (IBM) 11 K C 1 Clone detection [130]1190 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
tant to classify clones as ‘‘clones to be retained’’ and ‘‘clones to be
removed’’. We found large number of studies regarding mainte-
nance of code clones by identifying refactoring opportunities.
There is dearth of studies validating the analytical results of clone
detection, clone analysis, clone management, etc. with developers
intent and behavior.
5.3. Implications for research and practice
The systematic review has implications for researchers who are
looking for new concepts in the ﬁeld of software clones, and for
practitioners working in software companies who want to apply
clone detection for software development.
As the research community is still arguing on the exact deﬁni-
tion of the term clone, it is imperative to devise automatic oraclesfor all types of clones. Studies conﬁrm that there is disagreement
between human experts as to whether the candidate code is or is
not a clone. It is a difﬁcult and time-consuming task to manually
classify the candidates as clones or not. Thus, we believe that ex-
perts from industry and academia related to diverse domains of
clone detection should come together to create a veriﬁed reference
corpus of clone candidates in standard subject systems. The study
should be carried out differently for each type of clone and depend-
ing upon use case. Such benchmark suites would make the results
of empirical comparison consistent and reliable for use in research
and industry.
For researcher and practitioners, a number of avenues are open.
Clone management has emerged as a challenging area. Software
developers in industry deal with large amounts of data. So clone
management tools should be scalable and integrated in into devel-
opment environments, to help programmers understand the
behavior of cloning patterns. A comprehensive industrial strength
clone management tool having integrated detection and developer
friendly visualization of clones would help the developers observe
clones as and when they proliferate during development.
The application of clone detection tool depends upon situations
and objectives. There are different circumstances where clone
detection is essential. Some of the areas are: aspect mining [28],
to ﬁnd cross cutting code [29], plagiarism detection [26], software
product lines [171,201] , clones in web sites [146,185] , origin anal-
ysis [159] , quality assessment [172] , detecting licensing violations
[66]. Though these areas are independent research ﬁelds, yet these
areas and clone detection can get beneﬁted from each other. Usu-
ally cross cutting code is scattered in different implementations of
the program. These implementations tend to be functionally simi-
lar, so semantic clone detection technique is helpful in ﬁnding
cross cutting code. In plagiarism detection, the code is copied
and disguised intentionally. By representing the code in an abstractrepresentation like PDG, existing code clone detection tools may be
customized to detect hidden changes in the code. Clone detection
helps in detecting shared and common set of features in software
product lines. Existing systems can be reengineered to obtain reus-
able assets with the help of clone detection. Origin analysis is the
study of detecting the location of changes to the system from
one version to the next. Clone detection may help in origin analysis
with detection of similar function/class/ﬁle across versions. Code
clone across systems may directly lead to licensing violations and
copyright infringements. So clone detection technique can be ap-
plied to detect these violations.
5.4. Limitations of this review
The main limitation of this study is multitude of meanings asso-
ciated with the keyword ‘clone’. We tried to be extremely cautious
in data extraction. Strings like code duplication, redundancy were
manually searched in databases to increase the number of researcharticles in our study. However, manual searches may miss relevant
articles.
Data extraction was carried independently by the researchers.
But only one author reviewed the discarded articles. As far as the
classiﬁcation of studies is concerned, there were disagreements
among researchers. Each researcher classiﬁed all papers individu-
ally before comparing the results. In cases where there was dis-
agreement, the issue was discussed until consensus was reached.
Thus the papers were classiﬁed in several different categories.
6. Conclusions and future work
In this review paper we identiﬁed 213 studies from literature, of
which 100 were found to be research studies of software clone
detection. We have presented the results in different dimensionslike classiﬁcation of clone research, code clone management as
cross cutting domain, types of clones, clone detection tools, clone
detection approaches, internal representations, subject systems,
semantic clones and model clones.
We noticed a great variation in the deﬁnition of the term
‘‘clones’’. We realized the series of the International Workshops
on Detection of Software Clones have made a signiﬁcant contribu-
tion towards promotion of research in the ﬁeld of software clones.
There are recent studies that show that clones can be often used as
principled reengineering techniques, and can be beneﬁcial in many
ways. Also, it is not easy to refactor all the clones due to cost/risk
associated with refactoring. So it is suggested that instead of
removing clones, we should have proper clone management facil-
ities. In order to advance the state of the art in clone management,
one needs to know the advances in clone research itself. We haveattempted to do this by ﬁnding the relevant literature and summa-
rizing it in the form of systematic map. This survey is helpful in
ﬁnding the research gaps in area of software cloning in general
and clone detection in particular.
It is still arguable whether clones are harmful or not. Undoubt-
edly in large case studies some of the clones are intentionally intro-
duced. More studies need to be undertaken to know how harmful
actually clones are. Saha et al. [198] stated that it is important to
understand code clone evolution to know whether clones are
harmful or not and to know the impact of code clones on mainte-
nance. Automatic tools for investigation and visualization of clone
genealogies across different versions of the software are helpful for
developers.
Is cloned code really defect-prone than non-cloned code? There
are too many contradicting studies. The area is still open for a gen-
eral statement. Different attributes of software quality coexist with
software clones. The behavior and impact due to code clones is still
not known. The study of changeability of cloned vs non-cloned sys-tem depends on the choice of application as some applications are
continuously restructured. Such studies should be empirically car-
ried out using different types of clone detectors on large subject
system base to conclude general remarks. Kamiya [115] found
out that code fragments do not appear consistently in all revisions
of the software. The code fragment skips one version and again
reappears in the next revision. This non-continuous code appearing
across revisions of the software need to be validated with develop-
ers’’ intent as to why code has been copied from the old revisions.
Godfrey et al. [73] stressed the need to track the history after
code clones have been detected. It will help in analyzing the rea-
sons as why cloning occurred in ﬁrst place. Knowing the reasons
as to why clones appear have implications on clone detection pro-
cess in particular and clone detection research in general.
There is dearth of research in cloning beyond source code. Juer-
gens [110] identiﬁed different software artifacts where cloning
may occur. He emphasized that phenomenon of clone detection,
reasons for its occurrence, effects of cloning has been studiedD. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1191
thoroughly in source code. Clones do occur in requirement speciﬁ-
cations, models and test cases too. There is an urgent need to ex-
plore the reasons for clones and efﬁcient clone detection
techniques in these software artifacts. Different artifacts have
inherent characteristics which have to be exploited to apply the
clone detection algorithm for that artifact. Empirical studies need
to be carried out to understand the patterns in clone evolution
for these artifacts. Artifact repositories will help in benchmark
and comparative studies for different artifacts. Studies regarding
clone management and their economic trade off’s need to be car-
ried out for each software artifact. We realize that if clones are re-
moved in earlier phases of software development life cycle,
maintenance costs will be cut in the delivered software. We realize
the research direction in use of frequent itemset mining to detect
clones in textual representation of other software artifacts. Latestprogramming paradigms and mobile based software need to be
tested for clones.
Carver et al. [33] emphasized the need to complement the ana-
lytical results of the tool with empirical behavioral studies of the
developer. Human based studies can be used to validate the results
of the analytical study. Various studies take static code as source
code. But the behavior changes at run time. Dynamic code behavior
at run time is not captured yet as part of software clone detection.
The use of self learning technique and history based log techniques
can be applied in the ﬁeld of software clone detection.
Dang et al. [44] discussed seamless integration of clone detec-
tion tool in the IDE. The tool should be ﬂexible, scalable and efﬁ-
cient in detecting real clones (clones which are really interesting
and useful to the developer) and should not report non-useful
and uninteresting clones. Research can be carried out to develop
automatic tools to check the consistency and compatibility of li-
censes in code siblings. There are many language speciﬁc issues
which hinder code clone classiﬁcation. Subjective studies carried
out by several human experts vary a lot on creating reference data
for creating different benchmark suits.
The reliable and scalable detection of behaviorally similar code
is an open research area. In software reuse we need to identify the
most relevant component for given context. From existing soft-
ware repository, developer may ﬁnd many candidate components
for given context, the components that are semantically same
but may differ in one or other criteria such as cyclomatic complex-
ity, algorithmic complexity, time/space trade-off, and known bugs.
With the help of semantic clone detection, developer will be able
to ﬁnd out most suitable and efﬁcient component out of available
candidate components.
We examine that there is clear need to address the lack of empir-
ical studies to examine the effects of cloning in real world models.
Comparison and evaluation of clone detection technique in modeldriven development can help in choosing the right technique based
on application. There is apparent need to classify the comparative
and empirical studies differently for Matlab/Simulink models,
UML models and data ﬂow models as the application area is differ-
ent. Storrle [209] proposed optimal alternative algorithms for mod-
el matching for efﬁcient clone detection of UML models. We
propose to collect comprehensive real world UML models and Mat-
lab/Simulink models and designing model clone oracle to effec-
tively evaluate model clone detection approaches. To enhance the
slow speed of model clone detection and PDG based clone detection
is an open research issue. Higo et al. [80] proposed the use of inter
procedural PDG in detecting identical functionalities. We foresee
the use of multiple threads or parallel machines to speed up and
distribute the task of retrieval and detection in future.
We hope that our study will be useful for any researcher who
wants to carry forward the research in any domain pertaining to
software clones such as clone management, clone detection, cloneanalysis, and impact of software clones on software quality. Fur-
ther our study is extended to model and semantic clone detection
techniques.
Acknowledgements
We thank editor and anonymous reviewers for worthy com-
ments. The comments and suggestions are extremely helpful in
improving the research paper draft. We are also grateful to All In-
dia Council for Technical Education (AICTE), Govt. of India for fund-
ing project titled ‘‘UML based Automated Test Case Generation’’ for
second author.
Appendix A. A quality assessment forms
A.1. Screening question
Section – 1
Does the research paper refer to software clones?
Consider: h
Yes
The paper includes the study of software clones. All
types of studies, i.e. case study, experimental study
or research paper is included. The word ‘clone’ has
got different meanings, so inclusion is highly
cautioush
No
Section – 1 is evaluated ﬁrst. If the reply is positive, we proceeded to section -2.
A.2. Screening question
Section – 2
Key sub-area categorization
Is the research paper focus on software clone
detection?h
Yes
Consider: h
No
– Is the study’s focus or main focus on software clone
detection or not?
– Did the study ﬁt in any one of sub-areas
categorized? (Apparently the study motivated
different categories.)
If the study’s primary focus is on software clone detection, pro-
ceed to section – 3, else proceed to section – 4.
A.3. Detailed questions
Section – 3
Findings
Is there clear statement of the ﬁndings? h
Yes
Consider: h
No
Did the study mention the approach/clone detection
technique?
Has the match detection technique reported?
What is the corresponding transformation technique,1192 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
Appendix A.3 (continued )
Findings
i.e. source representation?
Comparison
Was the data reported sufﬁcient for comparative
analysis?h
Yes
Consider: h
No
Are the necessary parameters for comparison
discussed?
Is the study referring to semantic clones explicitly?
Sampling and subject system
What was the subject system? h
Yes
– Was the subject system size considerable? h
No
– Has the researcher mentioned how the subject
system was identiﬁed and selected?
A.4. Detailed questions
Section – 4
Findings
Did the study mention the type of clone? h
Yes
Consider: h
No
How well the clones are categorized?
Did the study explicitly mentions the type of clone, or
is to be inferred from the study?
Level of usage
Was the tool reported? h
Yes
Consider: h
No
Was the study referring to development of a new tool
or usage of the tool for analysis of a different subject
system?
Appendix B. Data items extracted from all papers
Data item Description
Study identiﬁer Unique ID for the study
Date of data
extraction
Bibliographic data Author, year, title, source
Type of article Journal article, conference article,
workshop paper
Study aims/context/
application domainWhat are the aims of the study, i.e.
search focus, i.e. the research areasthe paper focus on
Study design Classiﬁcation of study – clone
analysis, clone visualization, survey,
comparative analysis, etc.
What is the clone
detection techniqueIt explicitly refers to the clone
detection technique and type of clone
How was comparison Values of important parameters forAppendix A.3 (continued )
Data item Description
carried out? software clone detection, i.e. recall,
precision, application area,
scalability, portability, etc.
Subject system How the data was collected: it refers
to the subject system and its size
Data analysis Data analysis, i.e. corresponding
source representation and match
detection technique are extracted
Developer of the tool
and usageIt refers to the clone detection tool,
developer and usage of the tool
Study ﬁndings Major ﬁndings or conclusions from
the primary study like percentage of
cloned code
Other Does the study explicitly refer to
semantic clone detection or model
based clone detection, any other
important point
Appendix C. Journals/conferences reporting most clone related
research
Publication channel J/C/
W#N
International Conference on Software
MaintenanceC2 0 8
International Conference of Software
EngineeringC1 8 1 0
International Workshop on Software Clones W 18 6
Working Conference on Reverse Engineering C 15 10
International Conference on Program
ComprehensionC1 2 5
International Workshop on Source Code
Analysis and ManipulationW1 1 2
European Conference on Software
Maintenance and ReengineeringC9 4
Object-Oriented Programming, Systems,
Languages & ApplicationsC8 2
Asia Paciﬁc Software Engineering Conference C 7 4
Journal of Systems and Software J 7 2
IEEE Transactions on Software Engineering J 6 3
Journal of Software Maintenance and
Evolution: Research and PracticeJ6 3
European Software Engineering Conference
and the ACM SIGSOFT Symposium on the
Foundations of Software EngineeringC5 3
Conference of the Center for Advanced Studies
on Collaborative ResearchC5 3
International Conference on Automated
Software EngineeringC5 1
Empirical Software Engineering Journal J 4 1
International Symposium on Software Metrics C 4 1
IEEE International Workshop on Website
EvolutionW3 2
Mining Software Repositories C 3 1
International Workshop On Partial Evaluation
And Program ManipulationW2 2
(continued on next page )Appendix B. Appendix A.3 (continued )D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1193
Appendix A.3 (continued )
Publication channel J/C/
W#N
Electronic Notes in Theoretical Computer
ScienceJ2 1
International Symposium on Empirical
Software EngineeringC2 1
International Workshop on Defects in Large
Software SystemsW2 1
J – Journal, C – Conference, W – Workshop, N – Number of studies reporting soft-
ware clone detection as prime study, # – Total number of articles investigated.
Appendix D. Acronyms
ADT Abstract Data Type
AOP Aspect Oriented Programming
API Application Programming Interface
AST Abstract Syntax Tree
CeDAR Clone Detection, Analysis and Refactoring
ConQAT Continuous Quality Assessment Toolkit
CPU Central Processing Unit
CRD Centre for Reviews and Dissemination
DP Dynamic Programming
FIM Frequent Itemset Mining
GPU Graphics Processing Unit
HTML Hyper Text Markup Language
ICA Independent Component AnalysisIDE Integrated Development Environment
IEEE The Institute of Electrical and Electronics Engineers
LCS Longest Common Subsequence
LOC Lines of Code
LSI Latent Semantic Indexing
LSH Locality Sensitive Hashing
PDG Program Dependence Graph
RTF Repeated Tokens Finder
STL Standard Template Library
UML Uniﬁed Modeling Language
XML Extensible Markup Language
XVCL XML Variant Conﬁguration Language
XMI XML Metadata Interchange
References
[1] E. Adar, M. Kim, SoftGUESS: visualization and exploration of code clones in
context, in: Proceedings of 29th International Conference on Software
Engineering (ICSE’07), Minneapolis, MN, USA, 2007, pp. 762–766.
[2] R. Al-Ekram, C. Kapser, R. Holt, M. Godfrey, Cloning by accident: An empirical
study of source code cloning across software systems, in: Proceedings of
International Symposium on Empirical Software Engineering (ISESE’05),
Noosa Heads, Australia, 2005, pp. 376–385.
[3] G. Antoniol, G. Cassaza, M. Di Penta, E. Merlo, Modeling clones evolution
through time series, in: Proceedings of the 17th International Conference on
Software Maintenance (ICSM ’01), 2001, pp. 273–280.
[4] G. Antoniol, U. Villano, E. Merlo, M. Di Penta, Analyzing cloning evolution in
the Linux kernel, Information and Software Technology 44 (13) (2002) 755–
765.
[5] L. Aversano, G. Canfora, A. De Lucia, P. Gallucci, Web site reuse: cloning and
adapting, in: Proceedings of the 3rd International Workshop on Web SiteEvolution (WSE’01), Florence, Italy, 2001, pp. 107–111.
[6] L. Aversano, L. Cerulo, M. Di Penta, How clones are maintained: an empirical
study, in: Proceedings of the 11th European Conference on Software
Maintenance and Reengineering, Amsterdam, The Netherlands, 2007, pp.
81–90.[7] B. Baker, On ﬁnding duplication and near-duplication in large software
systems, in: Proceedings of the 2nd Working Conference on Reverse
Engineering (WCRE’95), Toronto, Ontario, Canada, 1995, pp. 86–95.
[8] M. Balazinska, E. Merlo, M. Dagenais, B. Laguë, K. Kontogiannis, Measuring
clone based reengineering opportunities, in: Proceedings of the 6th
International Software Metrics Symposium (METRICS’99), Boca Raton,Florida, USA, 1999, pp. 292–303.
[9] M. Balazinska, E. Merlo, M. Dagenais, B. Laguë, K. Kontogiannis, Partial
redesign of Java software systems based on clone analysis, in: Proceedings of
the 6th Working Conference on Reverse Engineering (WCRE’99), Atlanta, GA,
USA, 1999, pp. 326–336.
[10] M. Balazinska, E. Merlo, M. Dagenais, B. Laguë, K. Kontogiannis, Advanced
clone-analysis to support object-oriented system refactoring, in: Proceedings
of the 7th Working Conference on Reverse Engineering (WCRE’00), Brisbane,
Queensland, Australia, 2000, pp. 98–107.
[11] M. Balint, T. Gîrba, R. Marinescu, How developers copy, in: Proceedings of the
14th IEEE International Conference on Program Comprehension (ICPC ’06),
Athens, Greece, 2006, pp. 56–68.
[12] T. Bakota, R. Ferenc, T. Gyimóthy, Clone smells in software evolution, in:
Proceedings of the 23rd IEEE International Conference on Software
Maintenance (ICSM’07), Paris, France, 2007, pp. 24–33.
[13] L. Barbour, H. Yuan, Y. Zou, A technique for just-in time clone detection, in:
Proceedings of the 18th IEEE International Conference on ProgramComprehension (ICPC’10), Washington DC, USA, 2010, pp. 76–79.
[14] H. Basit, S. Jarzabek, Detecting higher-level similarity patterns in programs,
in: Proceedings of the 10th European Software Engineering Conference Held
Jointly with 13th ACM SIGSOFT International Symposium on Foundations of
Software Engineering (ESEC/SIGSOFT FSE’05), Lisbon, Portugal, 2005, pp. 156–165.
[15] H. Basit, D. Rajapakse, S. Jarzabek, Beyond templates: a study of clones in the
STL and some general implications, in: Proceedings of the 27th International
Conference on Software Engineering (ICSE’05), St. Louis, Missouri, USA, 2005,
pp. 15–21.
[16] H. Basit, S. Puglisi, W. Smyth, A. Turpin, S. Jarzabek, Efﬁcient token based
clone detection with ﬂexible tokenization, in: Proceedings of the JointMeeting of the European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (ESEC/FSE’07), Dubrovnik,
Croatia, 2007, pp. 513–515.
[17] H. Basit, S. Jarzabek, A data mining approach for detecting higher-level clones
in software, IEEE Transactions on Software Engineering 35 (4) (2009) 497–514.
[18] H. Basit, U. Ali, S. Jarzabek, Viewing simple clones from a structural clones’
perspective, in: Proceedings of 5th International Workshop on Software
Clones, Honolulu, USA, 2011, pp. 1–8.
[19] Project Bauhaus, < http://www.bauhaus-stuggart.de > (accessed April 2012).
[20] S. Bellon, R. Koschke, G. Antoniol, J. Krinke, E. Merlo, Comparison and
evaluation of clone detection tools, IEEE Transactions on SoftwareEngineering 33 (9) (2007) 577–591.
[21] N. Bettenburg, W. Shang, W.M. Ibrahim, B. Adams, Y. Zou, A.E. Hassan, An
empirical study on inconsistent changes to code clones at the release level,
Science of Computer Programming 74 (7) (2010) 1–17.
[22] I. D. Baxter, A. Yahin, L. Moura, M. Sant’Anna, L. Bier, Clone detection using
abstract syntax trees, in: Proceedings of the 14th International Conference on
Software Maintenance (ICSM ’98), Bethesda, Maryland, USA, 1998, pp. 368–
378.
[23] B. Biegel, S. Diehl, JCCD: a ﬂexible and extensible API for implementing
custom code clone detectors, in: Proceedings of 25th International
Conference on Automated Software Engineering, (ASE’10), Antwerp,
Belgium, 2010, pp. 167–168.
[24] B. Biegel, S. Diehl, Highly conﬁgurable and extensible code clone detection, in:
Proceedings of the 17th Working Conference on Reverse Engineering
(WCRE’10), Beverly, MA, USA, 2010, pp. 237–241.
[25] P. Brereton, B.A. Kitchenham, D. Budgen, M. Turner, M. Khalil, Lessons from
applying the systematic literature review process within the softwareengineering domain, The Journal of Systems and Software 80 (4) (2007)
571–583.
[26] R. Brixtel, M. Fontaine, B. Lesner, C. Bazin, R. Robbes, Language independent
clone detection applied to plagiarism detection, in: Proceedings of the 10th
IEEE International Working Conference on Source Code Analysis and
Manipulation (SCAM’10), Timisoara, Romania, 2010, pp. 77–86.
[27] C. Brown, S. Thompson, Clone detection and elimination for Haskell, in:
Proceedings of the ACM SIGPLAN Workshop on Partial Evaluation and
Program Manipulation (PEPM’10), Madrid, Spain, 2010, pp. 111–120.
[28] M. Bruntink, Aspect mining using clone class metrics, in: Proceedings of the
1st Workshop on Aspect Reverse-Engineering Held in Conjunction with 11th
Working Conference on Reverse Engineering (WCRE’04), Delft, TheNetherlands, 2004, p. 5.
[29] M. Bruntink, A. van Deursen, R. van Engelen, T. Tourwe, On the use of clone
detection for identifying crosscutting concern code, IEEE Transactions on
Software Engineering 31 (10) (2005) 804–818.
[30] D. Budgen, P. Brereton, Performing systematic literature reviews in software
engineering, in: Proceedings of the 28th International Conference on
Software Engineering (ICSE’06), Shanghai, China, 2006, pp. 1051–1052.
[31] P. Bulychev, M. Minea, Duplicate code detection using anti-uniﬁcation, in:
Proceedings of Spring/Summer Young Researchers’ Colloquium on Software
Engineering, St. Petersburg, Russia, 2008, pp. 51–54.Appendix C.1194 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
[32] E. Burd, J. Bailey, Evaluating clone detection tools for use during preventative
maintenance, in: Proceedings of the 2nd IEEE International Workshop on
Source Code Analysis and Manipulation (SCAM’02), Montreal, Canada, 2002,
pp. 36–43.
[33] J. Carver, D. Chatterji, N. A. Craft, On the need for human-based empirical
validation of techniques and tools for code clone analysis, in: Proceedings of5th International Workshop on Software Clones, Honolulu, USA, 2011, pp.
61–62.
[34] G. Cassaza, G. Antoniol, U. Villano, E. Merlo, M. Di Penta, Identifying clones in
the Linux kernel, in: Proceedings of the 1st IEEE International Workshop on
Source Code Analysis and Manipulation (SCAM’01), Florence, Italy, 2001, pp.90–97.
[35] M. Chilowicz, É. Duris, G. Roussel, Finding similarities in source code through
factorization, Electronic Notes in Theoretical Computer Science 238 (5)
(2009) 47–62.
[36] M. Chilowicz, É. Duris, G. Roussel, Syntax tree ﬁngerprinting for source code
similarity detection, in: Proceedings of the 17th IEEE International
Conference on Program Comprehension (ICPC’09), Vancouver, BritishColumbia, Canada, 2009, pp. 243–247.
[37] S. Choi, H. Park, H. Lim, T. Han, A static API birthmark for windows binary
executables, The Journal of Systems and software 82 (5) (2009) 862–873.
[38] E. Choi, N. Yoshida, T. Ishio, K. Inoue, T. Sano, Extracting code clones for
refactoring using combinations of clone metrics, in: Proceedings of 5thInternational Workshop on Software Clones, Honolulu, USA, 2011, pp. 7–13.
[39] P. Ciancarini, G.P. Favini, Detecting clones in game playing software,
Entertainment Computing 1 (2009) 9–15.
[40] A. Corazza, S. D. Martino, V. Maggio, G. Scanniello, A tree kernel based
approach for clone detection, in: Proceedings of the 26th IEEE InternationalConference on Software Maintenance (ICSM’10), Timisoara, Romania, 2010,
pp. 1–5.
[41] J.R. Cordy, T.R. Dean, N. Synytskyy, Practical language-independent detection
of near-miss clones, in: Proceedings of the 14th IBM Centre for Advanced
Studies Conference (CASCON’04), Toronto, Ontario, Canada, 2004, pp. 1–12.
[42] M. Dagenais, E. Merlo, B. Laguë, D. Proulx, Clones occurrence in large object
oriented software packages, in: Proceedings of the 8th IBM Centre forAdvanced Studies Conference (CASCON’98), Toronto, Ontario, Canada, 1998,
pp. 192–200.
[43] A.M. Dalgarno, Jump starting software product lines with clone detection, in:
Proceedings of 12th International Software Product Line Conference,
Limerick, Ireland, 2008, pp. 351.
[44] Y. Dang, S. Ge, R. Huang, D. Zhang, Code clone detection experience at
Microsoft, in: Proceedings of 5th International Workshop on Software Clones,
Honolulu, USA, 2011, pp. 63–64.
[45] I.J. Davis, M.W. Godfrey, From whence it came: detecting source code clones
by analyzing assembler, in: Proceedings of the 17th Working Conference on
Reverse Engineering (WCRE’10), Beverly, MA, USA, 2010, pp. 242–246.
[46] M. D. Wit, A. Zaidman, A. van Deursen, Managing code clones using dynamic
change tracking and resolution, in: Proceedings of the 25th IEEE International
Conference on Software Maintenance (ICSM’09), Edmonton, AB, 2009, pp.
169–178.
[47] F. Deissenboeck, B. Hummel, E. Juergens, B. Schätz, S. Wagner, J. Girard, S.
Teuchert, Clone detection in automotive model-based development, in:Proceedings of 30th International Conference on Software Engineering
(ICSE’08), Leipzig, Germany, 2008, pp. 603–612.
[48] F. Deissenboeck, E. Juergens, B. Hummel, S. Wagner, P. Mas, M. Pizka, Tool
support for continuous quality control, IEEE Software 25 (5) (2008) 60–67.
[49] F. Deissenboeck, B. Hummel, E. Juergens, M. Pfaehler, B. Schaetz, Model clone
detection in practice, in: Proceedings of 4th International Workshop on
Software Clones, Cape Town, SA, 2010, pp. 37–44.
[50] M. Di Penta, Evolution doctor: a framework to control software system
evolution, in: Proceedings of the 9th European Conference on Software
Maintenance and Reengineering (CSMR’05), 2005, pp. 280–283.
[51] M. Di Penta, M. Neteler, G. Antoniol, E. Merlo, A language independent
software renovation framework, The Journal of Systems and Software 77 (3)(2005) 225–240.
[52] C. Domann, E. Juergens, J. Streit, The curse of copy & paste-cloning in
requirements speciﬁcations, in: Proceedings of the 3rd International
Symposium on Empirical Software Engineering and Measurement, Lake
Buena Vista, Florida, USA, 2009, pp. 443–446.
[53] E. Duala-Ekoko, M. Robillard, Tracking code clones in evolving software, in:
Proceedings of 29th International Conference on Software Engineering(ICSE’07), Minneapolis, MN, USA, 2007, pp. 158–167.
[54] E. Duala-Ekoko, M. Robillard, CloneTracker: tool support for code clone
management, in: Proceedings of 30th International Conference on Software
Engineering (ICSE’08), Leipzig, Germany, 2008, pp. 843–846.
[55] E. Duala-Ekoko, M. Robillard, Clone region descriptors: representing and
tracking duplication in source code, ACM Transactions on Software
Engineering and Methodology 20 (1) (2010) 1–31.
[56] S. Ducasse, M. Rieger, S. Demeyer, A language independent approach for
detecting duplicated code, in: Proceedings of the 15th International
Conference on Software Maintenance (ICSM’99), Oxford, England, UK, 1999,pp. 109–119.
[57] S. Ducasse, O. Nierstrasz, M. Rieger, On the effectiveness of clone detection by
string matching, Journal on Software Maintenance and Evolution: Research
and Practice 18 (1) (2006) 37–58.[58] W.S. Evans, C.W. Fraser, F. Ma, Clone detection via structural abstraction,
Software Quality Journal 17 (4) (2009) 309–330.
[59] R. Falke, P. Frenzel, R. Koschke, Empirical evaluation of clone detection using
syntax sufﬁx trees, Empirical Software Engineering 13 (6) (2008) 601–643.
[60] R. Fanta, V. Rajlich, Removing clones from the code, Journal of Software
Maintenance, Research and Practice 11 (4) (1999) 223–243.
[61] M. Fowler, K. Beck, T. Brant, W. Opdyke, D. Roberts, Refactoring: Improving
the Design of Existing Code, Addison-Wesley Longman, 1999.
[62] Y. Fukushima, R. Kula, S. Kawaguchi, K. Fushida, M. Nagura, H. Iida, Code clone
graph metrics for detecting diffused code clones, in: Proceedings of the 16th
Asia Paciﬁc Software Engineering Conference (APSEC’09), Penang, Malaysia,2009, pp. 373–380.
[63] M. Gabel, L. Jiang, Z. Su, Scalable detection of semantic clones, in: Proceedings
of 30th International Conference on Software Engineering (ICSE’08), Leipzig,
Germany, 2008, pp. 321–330.
[64] M. Gabel, J. Yang, Y. Yu, M. Goldszmidt, Z. Su, Scalable and systematic
detection of buggy inconsistencies in source code, in: Proceedings of the
International Conference on Object Oriented Programming SystemsLanguages and Applications, Nevada, USA, 2010, pp. 175–190.
[65] K. Gallagher, L. Layman, Are decomposition slices clones? In: Proceedings of
the 11th IEEE International Workshop on Program Comprehension (IWPC’03),
Portland, Oregon, USA, 2003, pp. 251–256.
[66] D.M. German, M. Di Penta, Y.-G Gueheneuc, G. Antoniol, Code siblings:
technical and legal implications of copying code between applications, in:
Proceedings of the 6th IEEE International Working Conference on Mining
Software Repositories (MSR’09), Vancouver, BC, Canada, 2009, pp. 81–90.
[67] D. Gitchell, N. Tran, Sim: a utility for detecting similarity in computer
programs, ACM SIGCSE Bulletin 31 (1) (1999) 266–270.
[68] N. Göde, R. Koschke, Incremental clone detection, in: Proceedings of the 13th
European Conference on Software Maintenance and Reengineering,
Kaiserslautern, Germany, 2009, pp. 219–228.
[69] N. Göde, Evolution of Type-1 clones, in: Proceedings of the 9th IEEE
International Working Conference on Source Code Analysis and
Manipulation (SCAM’09), Edmonton, Canada, 2009, pp. 77–86.
[70] N. Göde, Clone Removal: Fact or Fiction, in: Proceedings of 4th International
Workshop on Software Clones, Cape Town, SA, 2010, pp. 22–40.
[71] N. Göde, J. Harder, Clone stability, in: Proceedings of 15th European
Conference on Software Maintenance and Reengineering, Oldenburg,
Germany, 2011, pp. 65–74.
[72] N. Göde, J. Harder, Oops! ...I changed it again, in: Proceedings of 5th
International Workshop on Software Clones, Honolulu, USA, 2011, pp. 14–20.
[73] M. W. Godfrey, D. M. German, J. Davies, A. Hindle, Determining the
provenance of software artifacts, in: Proceedings of 5th International
Workshop on Software Clones, Honolulu, USA, 2011, pp. 65–66.
[74] S. Grant, J. R. Cordy, Vector space analysis of software clones, in: Proceedings
of the 17th IEEE International Conference on Program Comprehension (ICPC
’09), Vancouver, BC, Canada, 2009, pp. 233–237.
[75] J. Guo Y. Zou, Detecting clones in business applications, in: Proceedings of the
15th Working Conference on Reverse Engineering (WCRE’08), Antwerp,
Belgium, 2008, pp. 91–100.
[76] Y. Hayase, Y. L. Lee, K. Inoue, A criterion for ﬁltering code clone related bugs,
in: Proceedings of the workshop on Defects in large software systems incompanion to International Symposium on Software Testing and Analysis
(DEFECTS ’08), Seattle, Washington, 2008, pp. 37–38.
[77] Y. Higo, Y. Ueda, T. Kamiya, S. Kusumoto, K. Inoue, On software maintenance
process improvement based on code clone analysis, in: Proceedings of the 4th
International Conference on Product Focused Software Process Improvement
(PROFES ’02), Rovaniemi, Finland, 2002, pp. 185–197.
[78] Y. Higo, T. Kamiya, S. Kusumoto, K. Inoue, ARIES: refactoring support
environment based on code clone analysis, in: Proceedings of the 8th
IASTED International Conference on Software Engineering and Applications,
MA, USA, 2004, pp. 222–229.
[79] Y. Higo, T. Kamiya, S. Kusumoto, K. Inoue, ARIES: Refactoring support tool for
code clone, in: Proceedings of 3rd Workshop on Software Quality incompanion to International Conference on Software Engineering (ICSE’05),
St. Louis, Missouri, USA, 2005, pp. 1–4.
[80] Y. Higo, Y. Ueda, S. Kusumoto, K. Inoue, Simultaneous modiﬁcation support
based on code clone analysis, in: Proceedings of the 14th Asia Paciﬁc Software
Engineering Conference (APSEC’07), Nagoya, Japan, 2007, pp. 262–269.
[81] Y. Higo, T. Kamiya, S. Kusumoto, K. Inoue, Method and implementation for
investigating code clones in a software system, Information and SoftwareTechnology 49 (9–10) (2007) 985–998.
[82] Y. Higo, S. Kusumoto, K. Inoue, A metric based approach to identifying
refactoring opportunities for merging code clones in a Java software system,
Journal of Software Maintenance and Evolution: Research and Practice 20 (6)
(2008) 435–461.
[83] Y. Higo, K. Sawa, S. Kusumoto, Problematic code clones identiﬁcation using
multiple detection results, in: Proceedings of the 16th Asia Paciﬁc Software
Engineering Conference (APSEC’09), Penang, Malaysia, 2009, pp. 365–372.
[84] Y. Higo, S. Kusumoto, Code clone detection on specialized PDG’s with
heuristics, in: Proceedings of the 15th European Conference on SoftwareMaintenance and Reengineering (CSMR’11), Oldenburg, Germany, 2011, pp.
75–84.
[85] S. Horwitz, Identifying the semantic and textual differences between two
versions of a program, in: Proceedings of the ACM SIGPLAN’90 Conference onD. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1195
Programming Language Design and Implementation (PLDI’90), White Plains,
New York, 1990, pp. 234–245.
[86] D. Hou, F. Jacob, P. Jablonski, Exploring the design space of proactive tool
support for copy-and-paste programming, in: Proceedings of the Conference
of the Center for Advanced Studies on Collaborative Research (CASCON ’09),
Ontario, Canada, 2009, pp. 188–202.
[87] D. Hou, P. Jablonski, F. Jacob, CnP: Towards an environment for the proactive
management of copy-and-paste programming, in: Proceedings of the 17th
IEEE International Conference on Program Comprehension (ICPC’09),
Vancouver, BC, Canada, 2009, pp. 238–242.
[88] D. Hou, F. Jacob, P. Jablonski, Proactively managing copy-and-paste induced
code clones, in: Proceedings of the 25th IEEE International Conference on
Software Maintenance (ICSM’09), Edmonton, AB, 2009, pp. 391–392.
[89] B. Hummel, E. Juergens, L. Heinemann, M. Conradt, Index-based code clone
detection: Incremental, distributed, scalable, in: Proceedings of the 26th IEEE
International Conference on Software Maintenance (ICSM’10), Timisoara,
Romania, 2010, pp. 1–9.
[90] B. Hummel, E. Juergens, D. Steidl, Index-based model clone detection, in:
Proceedings of 5th International Workshop on Software Clones, Honolulu,
USA, 2011, pp. 21–27.
[91] T. Imai, Y. Kataoka, T. Fukaya, Evaluating software maintenance cost using
functional redundancy metrics, in: Proceedings of 26th Annual International
Computer Software and Applications (COMPSAC’02), Oxford, England, 2002,pp. 299–306.
[92] P. Jablonski, Managing the copy-and-paste programming practice in modern
IDE’s, in: Proceedings of the Conference on Object Oriented Programming
Systems Languages and Applications Companion to the 22nd ACM SIGPLAN
conference on Object-oriented programming systems and applicationscompanion, Montreal, Quebec, Canada, 2007, pp. 933–934.
[93] P. Jablonski, D. Hou, CReN: A tool for tracking copy-and-paste code clones and
renaming identiﬁers consistently in the IDE, in: Proceedings of Eclipse
Technology Exchange Workshop at OOPSLA 2007 (ETX’07), Montreal, Quebec,
Canada, 2007, p. 5.
[94] P. Jablonski, D. Hou, Aiding software maintenance with copy and paste clone
awareness, in: Proceedings of the 18th IEEE International Conference onProgram Comprehension (ICPC’10), Washington DC, USA, 2010, pp. 170–179.
[95] F. Jacob, D. Hou, P. Jablonski, Actively comparing clones inside the code editor,
in: Proceedings of 4th International Workshop on Software Clones, Cape
Town, SA, 2010, pp. 1–8.
[96] K. Jalbert, J. S. Bradbury, Using clone detection to identify bugs in concurrent
software, in: Proceedings of the 26th IEEE International Conference on
Software Maintenance (ICSM’10), Timisoara, Romania, 2010, pp. 1–5.
[97] S. Jarzabek, S. Li, Unifying clones with a generative programming technique: a
case study, Journal of Software Maintenance and Evolution: Research and
Practice, John Wiley & Sons 18 (4) (2006) 267–292.
[98] Z. M. Jiang, A. E. Hassan, R. C. Holt, Visualizing clone cohesion and coupling,
in: Proceedings of the 13th Asia Paciﬁc Software Engineering Conference(APSEC’06), Bangalore, India, 2006, pp. 467–476.
[99] L. Jiang, Z. Su, E. Chiu, Context-based detection of clone-related bugs, in:
Proceedings of the 6th joint meeting of the European Software Engineering
Conference and the ACM SIGSOFT Symposium on the Foundations of Software
Engineering (ESEC/FSE’07), Dubrovnik, Croatia, 2007, pp. 55–64.
[100] L. Jiang, G. Misherghi, Z. Su, S. Glondu, DECKARD: Scalable and accurate tree-
based detection of code clones, in: Proceedings of 29th International
Conference on Software Engineering (ICSE’07), Minneapolis, MN, USA, 2007,
pp. 96–105.
[101] Z.M. Jiang, A.E. Hassan, A framework for studying clones in large software
systems, in: Proceedings of the 7th IEEE International Working Conference on
Source Code Analysis and Manipulation (SCAM’07), Paris, France, 2007, pp.203–212.
[102] L. Jiang, Z. Su, Automatic mining of functionally equivalent code fragments
via random testing, in: Proceedings of 18th International Symposium on
Software Testing and Analysis (ISSTA’09), Chicago, Illinois, USA, 2009, pp. 81–
92.
[103] Jian-lin Huang, Fei-peng Li, Quick similarity measurement of source code
based on sufﬁx array, in: Proceedings of International Conference on
Computational Intelligence and Security, Beijing, China, 2009, pp. 308–311.
[104] J.H. Johnson, Substring matching for clone detection and change tracking, in:
Proceedings of the 10th International Conference on Software Maintenance,
Victoria, British Columbia, Canada, 1994, pp. 120–126.
[105] E. Juergens, F. Deissenboeck, B. Hummel, CloneDetective – a workbench for
clone detection research, in: Proceedings of 31st International Conference on
Software Engineering (ICSE’09), Vancouver, Canada, 2009, pp. 603–606.
[106] E. Juergens, F. Deissenboeck, B. Hummel, S. Wagner, Do code clones matter?
In: Proceedings of 31st International Conference on Software Engineering
(ICSE’09), Vancouver, Canada, 2009, pp. 485–495.
[107] E. Juergens, N. Göde, Achieving accurate clone detection results, in:
Proceedings of 4th International Workshop on Software Clones, Cape Town,
SA, 2010, pp. 1–8.
[108] E. Juergens, F. Deissenboeck, M. Feilkas, B. Hummel, B. Schaetz, S. Wagner, C.
Domann, J, Streit, Can clone detection support quality assessments ofrequirement speciﬁcations? in: Proceedings of 32nd International
Conference on Software Engineering (ICSE’10), Cape Town, South, Africa,
2010, pp. 79–88.[109] E. Juergens, F. Deissenboeck, B. Hummel, Code similarities beyond copy &
paste, in: Proceedings of the 14th European Conference on Software
Maintenance and Reengineering (CSMR’10), Madrid, Spain, 2010, pp. 78–87.
[110] E. Juergens, Research in cloning beyond code: a ﬁrst roadmap, in: Proceedings
of 5th International Workshop on Software Clones, Honolulu, USA, 2011, pp.
67–68.
[111] W. Jung, C. Wu, E. Lee, WSIM: detecting clone pages based on 3-levels of
similarity clues, in: Proceedings of 9th IEEE/ACIS International Conference on
Computer and Information Sciences, Yamagata, Japan, 2010, pp. 702–707.
[112] T. Kamiya, F. Ohata, K. Kundou, S. Kusumoto, K. Inoue, Maintenance support
tools for JAVA Programs: CCFinder and JAAT, in: Proceedings of 23rdInternational Conference on Software Engineering (ICSE’01), Toronto,
Ontario, Canada, 2001, pp. 837–838.
[113] T. Kamiya, S. Kusumoto, K. Inoue, CCFinder: a multi-linguistic token-based
code clone detection system for large scale source code, IEEE Transactions on
Software Engineering 28 (7) (2002) 654–670.
[114] T. Kamiya, The Ofﬁcial CCFinderX website < http://www.ccﬁnder.net >
(accessed April 2012).
[115] T. Kamiya, C. Ghezzi, How code skips over revisions, in: Proceedings of 5th
International Workshop on Software Clones, Honolulu, USA, 2011, pp. 69–70.
[116] C.J. Kapser, M.W. Godfrey, Aiding comprehension of cloning through
categorization, in: Proceedings of the 7th International Workshop on
Principles of Software Evolution (IWPSE’04), Kyoto, Japan, 2004, pp. 85–94.
[117] C.J. Kapser, M.W. Godfrey, Improved tool support for the investigation of
duplication in software, in: Proceedings of the 21st International Conference
on Software Maintenance (ICSM’05), Budapest, Hungary, 2005, pp. 305–314.
[118] C.J. Kapser, M.W. Godfrey, Supporting the analysis of clones in software
systems: a case study, Journal of Software Maintenance and Evolution:Research and Practice 18 (2) (2006) 61–82.
[119] C.J. Kapser, P. Anderson, M. Godfrey, R. Koschke, M. Rieger, F. van
Rysselberghe, P. Weisgerber, Subjectivity in clone judgment: can we ever
agree? in: Duplication, Redundancy, and Similarity in Software, Dagstuhl
Seminar Proceedings, 2007.
[120] C.J. Kapser, M.W. Godfrey, ‘‘Cloning considered harmful’’ considered harmful:
patterns of cloning in software, Empirical Software Engineering 13 (6) (2008)645–692.
[121] S. Kawaguchi, P.K. Garg, M. Matsushita, K. Inoue, Automatic categorization
algorithm for evolvable software archive, in: Proceedings of the 6th
International Workshop on Principles of Software Evolution (IWPSE’03),
Helsinki, Finland, 2003, pp. 195–200.
[122] M. Kim, L. Bergman, T. Lau, D. Notkin, An Ethnographic study of copy and
paste programming practices in OOPL, in: Proceedings of 3rd International
ACM-IEEE Symposium on Empirical Software Engineering (ISESE’04),
Redondo Beach, CA, USA, 2004, pp. 83–92.
[123] M. Kim, D. Notkin, Using a clone genealogy extractor for understanding and
supporting evolution of code clones, in: Proceedings of the 2nd International
Workshop on Mining Software Repositories (MSR’05), Saint Louis, Missouri,USA, 2005, pp. 1–5.
[124] M. Kim, V. Sazawal, D. Notkin, G. C. Murphy, An Empirical study of code clone
genealogies, in: Proceedings of the 10th European software engineering
conference held jointly with 13th ACM SIGSOFT international symposium on
Foundations of software engineering (ESEC/SIGSOFT FSE 2005’05), Lisbon,Portugal, 2005, pp. 187–196.
[125] H. Kim, Y. Jung, S. Kim, and K. Yi, MeCC: Memory comparison-based clone
detector, in: Proceedings of the 33rd International Conference on Software
Engineering (ICSE’11), Honolulu, Hawaii, 2011, pp. 301–310.
[126] M. Kim, Understanding and aiding code evolution by inferring change
patterns, in: Proceedings of 29th International Conference on Software
Engineering (ICSE’07), Minneapolis, MN, USA, 2007, pp. 101–102.
[127] B. A. Kitchenham, S. Charters, Guidelines for performing systematic literature
reviews in software engineering. Technical Report EBSE-2007-01, School of
Computer Science and Mathematics, Keele University, Keele and Department
of Computer Science, University of Durham, Durham, UK, 2007, p. 65.
[128] B. Kitchenham, O.P. Brereton, D. Budgen, M. Turner, J. Bailey, S. Linkman,
Systematic literature reviews in software engineering – a systematic
literature review, Information and Software Technology 51 (1) (2009) 7–15.
[129] E. Kodhai, S. Kanmani, A. Kamatchi, R. Radhika, B.V. Saranya, Detection of
Type-1 and Type-2 code clones using textual analysis and metrics, in:
Proceedings of 2010 International Conference on Recent Trends in
Information, Telecommunication and Computing, Kochi, Kerala, India, 2010,
pp. 241–243.
[130] R. Komondoor, S. Horwitz, Using slicing to identify duplication in source
code, in: Proceedings of the 8th International Symposium on Static Analysis
(SAS’01), vol. LNCS 2126, Paris, France, 2001, pp. 40–56.
[131] K. Kontogiannis, Partial design recovery using dynamic programming, in:
Proceedings of the Conference of the Centre for Advanced Studies onCollaborative research (CASCON’94), Toronto, Ontario, Canada, 2004, p. 34.
[132] K. Kontogiannis, R. Demori, E. Merlo, M. Galler, M. Bernstein, Pattern
matching for clone and concept detection, Automated Software Engineering
3 (1–2) (1996) 77–108.
[133] K. Kontogiannis, Evaluation experiments on the detection of programming
patterns using software metrics, in: Proceedings of the 3rd Working
Conference on Reverse Engineering (WCRE’97), Amsterdam, The
Netherlands, 1997, pp. 44–54.1196 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
[134] R. Koschke, R. Falke, P. Frenzel, Clone detection using abstract syntax sufﬁx
trees, in: Proceedings of the 13th Working Conference on Reverse
Engineering (WCRE’06), Benevento, Italy, 2006, pp. 253–262.
[135] R. Koschke, Survey of research on software clones, in: Duplication,
Redundancy, and Similarity in Software, Dagstuhl Seminar Proceedings,
2007, p. 24.
[136] R. Koschke, Frontiers of software clone management, in: Proceedings of
Frontiers of Software Maintenance (FoSM’08), Beijing, China, 2008, pp. 119–
128.
[137] D. Kozlov, J. Koskinen, M. Sakkinen, J. Markkula, Exploratory analysis of the
relations between code cloning and open source software quality, in:Proceedings of 7th International Conference on the Quality of Information
and Communications Technology, Porto, Portugal, 2010, pp. 358–363.
[138] J. Krinke, Identifying similar code with program dependence graphs, in:
Proceedings of the 8th Working Conference on Reverse Engineering
(WCRE’01), Stuttgart, Germany, 2001, pp. 301–309.
[139] J. Krinke, A study of consistent and inconsistent changes to code clones, in:
Proceedings of the 14th Working Conference on Reverse Engineering(WCRE’07), Vancouver, BC, Canada, 2007, pp. 170–178.
[140] J. Krinke, N. Gold, Y. Jia, D. Binkley, Distinguishing copies from originals in
software clones, in: Proceedings of 4th International Workshop on Software
Clones, Cape Town, SA, 2010, pp. 41–48.
[141] J. Krinke, N. Gold, Y. Jia, D. Binkley, Cloning and Copying between GNOME
projects, in: Proceedings of 7th IEEE International Conference on Mining
Software Repositories, Cape Town, SA, 2010, pp. 98–101.
[142] J. Krinke, Is cloned code more stable than non-cloned code, in: Proceedings of
the 8th IEEE International Working Conference on Source Code Analysis and
Manipulation (SCAM’08), Beijing, China, 2008, pp. 57–66.
[143] J. Krinke, Is cloned code older than non-cloned code? in: Proceedings of 5th
International Workshop on Software Clones, Honolulu, USA, 2011, pp. 28–33.
[144] B. Laguë, D. Proulx, J. Mayrand, E. Merlo, J. Hudepohl, Assessing the beneﬁts of
incorporating function clone detection in a development process, in:
Proceedings of the 13th International Conference on Software Maintenance
(ICSM’97), Bari, Italy, 1997, pp. 314–321.
[145] A. Lakhotia, J. Li, A. Walenstein, Y. Yang, Towards a clone detection
benchmark suite and results archive, in: Proceedings of the 11th IEEE
International Workshop on Program Comprehension (IWPC’03), Portland,
Oregon, USA, 2003, pp. 285–286.
[146] F. Lanubile, T. Mallardo, Finding function clones in web applications, in:
Proceedings of the 7th European Conference on Software Maintenance andReengineering (CSMR’03), Benevento, Italy, 2003, pp. 379–386.
[147] T. Lavoie, M. Eilers-Smith, E. Merlo, Challenging cloning related problems
with GPU-based algorithms, in: Proceedings of 4th International Workshop
on Software Clones, Cape Town, SA, 2010, pp. 25–32.
[148] T. Lavoie, E. Merlo, Automated type-3 clone oracle using Levenshtein metric,
in: Proceedings of 5th International Workshop on Software Clones, Honolulu,
USA, 2011, pp. 34–40.
[149] S. Lee, I. Jeong, SDD: High performance code clone detection system for large
scale source code, in: Proceedings of the Object Oriented Programming
Systems Languages and Applications Companion to the 20th annual ACM
SIGPLAN conference on Object-oriented programming, systems, languages,
and applications (OOPSLA Companion ’05), San Diego, CA, USA, 2005, pp.140–141.
[150] H. Lee, K. Doh, Tree-pattern-based duplicate code detection, in: Proceedings
of International Workshop on Data-intensive Software Management and
Mining, Philadelphia, PA, USA, 2009, pp. 7–12.
[151] Mu-Woong Lee, Jong-Won Roh, Seung-won Hwang, S. Kim, Instant code clone
search, in: Proceedings of 18th International Symposium on Foundations of
Software Engineering, NY, USA, 2010, 167–176.
[152] Z. Li, S. Lu, S. Myagmar, Y. Zhou, CP-Miner: ﬁnding copy–paste and related
bugs in large-scale software code, IEEE Transactions on Software Engineering
32 (3) (2006) 176–192.
[153] H. Li, S. Thompson, Clone detection and removal for Erlang/OPT within a
refactoring environment, in: Proceedings of ACM SIGPLAN Workshop onPartial Evaluation and Program Manipulation (PEPM’09), Savannah, GA, USA,
2009, pp. 169–178.
[154] Z. O. Li, J. Sun, A metric space based software clone detection approach, in:
Proceedings of 2nd International Conference on Software Engineering and
Data Mining, Chengdu, China, 2010, pp. 111–116.
[155] H. Liu, Z. Ma, L. Zhang, W. Shao, Detecting duplications in sequence diagrams
based on sufﬁx trees, in: Proceedings 13th Asia-Paciﬁc Software EngineeringConference (APSEC’06), Bangalore, India, 2006, pp. 269–276.
[156] S. Livieri, Y. Higo, M. Matsushita, K. Inoue, Analysis of the Linux kernel
evolution using code clone coverage, in: Proceedings of the 4th International
Workshop on Mining Software Repositories (MSR’07), Minneapolis, MN, USA,
2007, pp. 22.
[157] S. Livieri, Y. Higo, M. Matsushita, K. Inoue, Very-large scale code clone
analysis and visualization of open source programs using distributed
CCFinder: D-CCFinder, in: Proceedings of the 29th International Conference
on Software Engineering (ICSE’07), Minneapolis, MN, USA, 2007, pp. 106–
115.
[158] A. Lozano, M. Wermelinger, B. Nuseibeh, Evaluating the harmfulness of
cloning: A change based experiment, in: Proceedings of the 4th International
Workshop on Mining Software Repositories (MSR’07), Minneapolis, MN, USA,
2007, p. 4.[159] A. Lozano, M. Wermelinger, Assessing the effects of clones on changeability,
in: Proceedings of the 24th IEEE International Conference on Software
Maintenance (ICSM’08), Beijing, China, 2008, pp. 227–236.
[160] A. Lozano, M. Wermelinger, Tracking clones’ imprint, in: Proceedings of 4th
International Workshop on Software Clones, Cape Town, SA, 2010, pp. 65–72.
[161] G.A. Lucca, M. Di Penta, A.R. Fasolino, An approach to identify duplicated web
pages, in: Proceedings of the 26th International Computer Software and
Applications Conference (COMPSAC’02), Oxford, England, 2002, pp. 481–486.
[162] A. Lucia, R. Francese, G. Scanniello, G. Tortora, Reengineering web
applications based on cloned pattern analysis, in: Proceedings of 12th
International Workshop on Program Comprehension (IWPC’04), Bari, Italy,2004, pp. 132–141.
[163] A. Lucia, R. Francese, G. Scanniello, G. Tortora, Understanding cloned patterns
in web applications, in: Proceedings of the 13th International Workshop on
Program Comprehension (IWPC’05), St. Louis, MO, USA, 2005, pp. 333–336.
[164] A. Lucia, M. Risi, G. Tortora, G. Scanniello, Clustering Algorithms and latent
semantic indexing to indentify similar pages in web applications, in:
Proceedings of the 9th International Workshop on Web Site Evolution(WSE’07), Paris, France, 2007, pp. 65–72.
[165] Y. Ma, D. Woo, Applying a code clone detection method to domain analysis of
device drivers, in: Proceedings of the 14th Asia Paciﬁc Software Engineering
Conference (APSEC’07), Nagoya, Japan, 2007, pp. 254–261.
[166] K. Maeda, Syntax sensitive and language independent detection of code
clones, World Academy of Science, Engineering and Technology 60 (2009)
350–354.
[167] A. Y. Mao, J. R. Cordy, T. R. Dean, Automated conversion of table-based
websites to structured stylesheets using table recognition and clone
detection, in: Proceedings of the 2007 Conference of the Center forAdvanced Studies on Collaborative Research (CASCON’07), Richmond Hill,
Ontario, Canada, 2007, pp. 12–26.
[168] A. Marcus, J. I. Maletic, Identiﬁcation of high-level concept clones in source
code, in: Proceedings of the 16th IEEE International Conference on Automated
Software Engineering (ASE’01), San Diego, CA, USA, 2001, pp. 107–114.
[169] D. Martin, J. R. Cordy, Analyzing web service similarities using contextual
clones, in: Proceedings of 5th International Workshop on Software Clones,Honolulu, USA, 2011, pp. 41–46.
[170] J. Mayrand, C. Leblanc, E.M. Merlo, Experiment on the automatic detection of
function clones in a software system using metrics, in: Proceedings of the
12th International Conference on Software Maintenance (ICSM’96),
Monterey, CA, USA, 1996, pp. 244–253.
[171] T. Mende, F. Beckwermert, R. Koschke, G. Meier, Supporting the Grow-and-
Prune model in software product lines evolution using clone detection, in:
Proceedings of the 12th European Conference on Software Maintenance and
Reengineering, Szeged, Hungary, 2008, pp. 163–172.
[172] A. Monden, D. Nakae, T. Kamiya, S. Sato, K. Matsumoto, Software quality
analysis by code clones in industrial legacy software, in: Proceedings of 8th
IEEE International Symposium on Software Metrics (METRICS’02), Ottawa,Canada, 2002, pp. 87–94.
[173] A. Monden, S. Okahara, Y. Manabe, K. Matsumoto, Guilty or not guilty: using
clone metrics to determine open source licensing violations, IEEE Software 28
(2) (2011) 42–47.
[174] T.T. Nguyen, H.A. Nguyen, N.H. Pham, J.M. Al-Kofahi, T.N. Nguyen, Cleman:
comprehensive clone group evolution management, in: Proceedings of the
23rd IEEE/ACM International Conference on Automated Software
Engineering, L’Aquila, Italy, 2008, pp. 451–454.
[175] T.T. Nguyen, H.A. Nguyen, N.H. Pham, J.M. Al-Kofahi, T.N. Nguyen, Clone-
aware conﬁguration management, in: Proceedings of the 24th IEEE/ACM
International Conference on Automated Software Engineering, Auckland,
New Zealand, 2009, pp. 123–134.
[176] T.T. Nguyen, H.A. Nguyen, N.H. Pham, J.M. Al-Kofahi, T.N. Nguyen, ClemanX:
Incremental clone detection tool for evolving software, in: Proceedings of
31st International Conference on Software Engineering (ICSE’09), Vancouver,
Canada, 2009, pp. 437–438.
[177] T.T. Nguyen, H.A. Nguyen, J.M. Al-Kofahi, N.H. Pham, T.N. Nguyen, Scalable
and incremental clone detection for evolving software, in: Proceedings of the
25th IEEE International Conference on Software Maintenance (ICSM ’09),
Edmonton, AB, 2009, pp. 491–494.
[178] J.R. Pate, R. Tairas, N.A. Craft, Clone Evolution: A Systematic Review, Technical
Report SERG-2010-01, University of Alabama, Alabama, USA, 2010, p. 20.
[179] J.-F. Patenaude, E. Merlo, M. Dagenais, B. Laguë, Extending software quality
assessment techniques to Java systems, in: Proceedings of the 7thInternational Workshop on Program Comprehension (IWPC’99), Pittsburgh,
PA, 1999, pp. 49–56.
[180] A. Perumal, S. Kanmani, E. Kodhai, Extracting the similarity in detected
software clones using metrics, in: Proceedings of International Conference on
Computer and Communication Technology, 2010, Allahabad, Uttar Pradesh,India, pp. 575–579.
[181] K. Petersen, R. Feldt, S. Mujtaba, M. Mattsson, Systematic mapping studies in
software engineering, in: Proceedings of 12th International Conference on
Evaluation and Assessment in Software Engineering (EASE’08), 2008, Bari,
Italy, pp. 71–80.
[182] N.H. Pham, H.A. Nguyen, T.T. Nguyen, J.M. Al-Kofahi, T.N. Nguyen, Complete
and accurate clone detection in graph based models, in: Proceedings of 31st
International Conference on Software Engineering (ICSE’09), Vancouver,
Canada, 2009, pp. 276–286.D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1197
[183] W. Qu, Y. Jia, M. Jiang, Pattern mining of cloned codes in software systems,
Information Sciences 180 (2010) 1–11.
[184] F. Rahman, C. Bird, P. Devanbu, Clones: what is that smell, in: Proceedings of
the 7th IEEE Working Conference on Mining Software Repositories, Cape
Town, South, Africa, 2010, pp. 72–81.
[185] D. Rajapakse, S. Jarzabek, An investigation of cloning in web applications, in:
Proceedings of the Special Interest Tracks and Posters of the 14th
International Conference on World Wide Web (WWW’05), Chiba, Japan,
2005, pp. 924–925.
[186] D. Rajapakse, S. Jarzabek, Using server pages to unify clones in web
applications: A trade-off analysis, in: Proceedings of the 29th InternationalConference of Software Engineering (ICSE’07), Minneapolis, USA, 2007, pp.
116–126.
[187] C.K. Roy, J.R. Cordy, A Survey on Software Clone Detection Research, Technical
Report 2007-541, Queen’s University at Kingston Ontario, Canada, 2007, p.
115.
[188] C.K. Roy, J.R. Cordy, NICAD: Accurate detection of near-miss intentional
clones using ﬂexible pretty-printing and code normalization, in: Proceedingsof the 16th IEEE International Conference on Program Comprehension
(ICPC’08), Amsterdam, The Netherlands, 2008, pp. 172–181.
[189] C.K. Roy, J.R. Cordy, Scenario-based comparison of clone detection
techniques, in: Proceedings of the 16th IEEE International Conference on
Program Comprehension (ICPC’08), Amsterdam, The Netherlands, 2008, pp.153–162.
[190] C.K. Roy, J.R. Cordy, A mutation/injection-based automatic framework for
evaluating code clone detection tools, in: Proceedings of the IEEE
International Conference on Software Testing Veriﬁcation and Validation
Workshops, Denver, Colorado, USA, 2009, pp. 157–166.
[191] C.K. Roy, Detection and analysis of near miss software clones, in: Proceedings
of the 25th IEEE International Conference on Software Maintenance
(ICSM’09), Edmonton, AB, 2009, pp. 447–450.
[192] C.K. Roy, J.R. Cordy, R. Koschke, Comparison and evaluation of code clone
detection techniques and tools: a qualitative approach, Science of Computer
Programming 74 (7) (2009) 470–495.
[193] C.K. Roy, J.R. Cordy, Near miss function clones in open source software: an
empirical study, Journal of Software Maintenance and Evolution: Research
and Practice 22 (3) (2010) 165–189.
[194] C.K. Roy, J.R. Cordy, Are scripting languages really different, in: Proceedings of
4th International Workshop on Software Clones, Cape Town, SA, 2010, pp.
17–24.
[195] F. V. Rysselberghe, S. Demeyer, Evaluating clone detection techniques from a
refactoring perspective, in: Proceedings of the 19th IEEE International
Conference on Automated Software Engineering (ASE’04), Linz, Austria,
2004, pp. 336–339.
[196] A. Saebjornsen, J. Willcock, T. Panas, D. Quinlan, Z. Su, Detecting code clones
in binary executable, in: Proceedings of International Symposium on
Software Testing and Analysis, Chicago, Illinois, USA, 2009, pp. 117–127.
[197] R.K. Saha, M. Asaduzzaman, M.F. Zibran, C.K. Roy, K.A. Schneider, Evaluating
code clone genealogies at release level: An empirical study, in: Proceedings of
the 10th IEEE International Working Conference on Source Code Analysis and
Manipulation (SCAM’10), Timisoara, Romania, 2010, pp. 87–96.
[198] R.K. Saha, C.K. Roy, K.A. Schneider, Visualizing the evolution of code clones,
in: Proceedings of 5th International Workshop on Software Clones, Honolulu,
USA, 2011, pp. 71–72.
[199] Y. Sasaki, T. Yamamoto, Y. Hayase, K. Inoue, Finding ﬁle clones in FreeBSD
ports collection, in: Proceedings of the 7th IEEE Working Conference on
Mining Software Repositories, Cape Town, South, Africa, 2010, pp. 102–105.
[200] S. Schulze, M. Kuhlemann, M. Rosenmüller, Towards a refactoring guideline
using code clone classiﬁcation, in: Proceedings of 2nd Workshop onRefactoring Tools with companion to Conference on Object Oriented
Programming Systems Languages and Applications, Nashville, Tennessee,
2008, p. 4.
[201] S. Schulze, S. Apel, C. Kastner, Code clones in feature oriented software
product lines, in: Proceedings of Generative Programming and ComponentEngineering (GPCE’10), Eindhoven, The Netherlands, 2010, pp. 103–112.
[202] P. Schugerl, Scalable clone detection using description logic, in: Proceedings
of 5th International Workshop on Software Clones, Honolulu, USA, 2011, pp.
47–53.
[203] Gehan M.K. Selim, K.C. Foo, Y. Zou, Enhancing source based clone detection
using intermediate representation, in: Proceedings of the 17th Working
Conference on Reverse Engineering (WCRE’10), Beverly, MA, USA, 2010, pp.227–236.
[204] Gehan M.K. Selim, L. Barbour, W. Shang, B. Adams, A.E. Hassan, Y. Zou,
Studying the impact of clones on software defects, in: Proceedings of the 17th
Working Conference on Reverse Engineering (WCRE’10), Beverly, MA, USA,
2010, pp. 13–21.
[205] D.M. Shawky, A.F. Ali, An approach for assessing similarity metrics used in
metric based clone detection techniques, in: Proceedings on 3rd IEEE
International Conference on Computer Science and Information Technology,
Chengdu, China, 2010, pp. 580–584.
[206] D.M. Shawky, A.F. Ali, Modeling clones evolution in open source systems
through chaos theory, in: Proceedings on 2nd International Conference on
Software Technology and Engineering, San Juan, Puerto Rico, 2010, pp. VI-
159–VI-164.
[207] Tool Simian < http://www.harukizaemon.com/simian/index.html > (accessed
April 2012).[208] Tool SimScan < http://www.blue-edge.bg/download.html > (accessed April
2012).
[209] H. Storrle, Towards clone detection in UML domain models, in: Proceedings
of European Conference on Software Architecture (ECSA’10), Copenhagen,
Denmark, 2010, pp. 285–293.
[210] A. Sutton, H. Kagdi, J.I. Maletic, G. Volkert, Hybridizing evolutionary
algorithms and clustering algorithms to ﬁnd source-code clones, in:
Proceedings of Genetic and Evolutionary Computation Conference
(GECCO’05), Washington DC, USA, 2005, pp. 1079–1080.
[211] N. Synytskyy, J.R. Cordy, T. Dean, Resolution of static clones in dynamic web
pages, in: Proceedings of 5th IEEE International Workshop on Web SiteEvolution (WSE’03), Amsterdam, The Netherlands, 2003, pp. 49–56.
[212] R. Tairas, Clone detection and refactoring, in: Proceedings of the Conference
on Object Oriented Programming Systems Languages and Applications
Companion to the 21st ACM SIGPLAN Symposium on Object-Oriented
Programming Systems, Languages, and Applications, Portland, Oregon, USA,
2006, pp. 780–781.
[213] R. Tairas, J. Gray, I. D. Baxter, Visualization of clone detection results, in:
Proceedings of the 2006 OOPSLA Workshop on Eclipse Technology eXchange,
Portland, Oregon, USA, 2006, pp. 50–54.
[214] R. Tairas, J. Gray, Phoenix-based clone detection using sufﬁx trees, in:
Proceedings of the 44th Annual Southeast Regional Conference (ACM-SE’06),
Melbourne, Florida, USA, 2006, pp. 679–684.
[215] R. Tairas, J. Gray, I.D. Baxter, Visualizing clone detection results, in:
Proceedings of the 22nd IEEE/ACM International Conference on Automated
Software Engineering (ASE’07), Atlanta, Georgia, USA, 2007, pp. 549–550.
[216] R. Tairas, Clone maintenance through analysis and refactoring, in:
Proceedings of the 2008 Foundations of Software Engineering DoctoralSymposium, Atlanta, GA, USA, 2008, pp. 29–32.
[217] R. Tairas, Centralizing clone group representation and maintenance, in:
Proceedings of the Conference on Object Oriented Programming Systems
Languages and Applications Companion to the 24th ACM SIGPLAN
Conference on Object Oriented Programming Systems Languages and
Applications, Orlando, Florida, USA, 2009, pp. 781–782.
[218] R. Tairas, J. Gray, Get to know your clones with CeDAR, in: Proceedings of
Conference on Object Oriented Programming Systems Languages and
Applications Companion to 24th ACM SIGPLAN Conference on Object
Oriented Programming Systems Languages and Applications, 2009, Orlando,
Florida, USA, pp. 817–818.
[219] R. Tairas, J. Gray, An information retrieval process to aid in the analysis of
code clones, Empirical Software Engineering 14 (1) (2009) 33–56.
[220] R. Tairas, J. Gray, Sub-clone refactoring in open source software artifacts, in:
Proceedings of ACM Symposium on Applied Computing (SAC’10), Sierre,
Switzerland, 2010, pp. 2373–2374.
[221] R. Tairas, F. Jacob, J. Gray, Representing clones in a localized manner, in:
Proceedings of 5th International Workshop on Software Clones, Honolulu,
USA, 2011, pp. 54–60.
[222] R. Tiarks, R. Koschke, R. Falke, An assessment of type-3 clones as detected by
state-of-the-art tools, in: Proceedings of the 9th IEEE International Working
Conference on Source Code Analysis and Manipulation (SCAM’09), Edmonton,
Canada, 2009, pp. 67–76.
[223] S. Thummalapenta, L. Cerulo, L. Aversano, M. Di Penta, An empirical study on
the maintenance of source code clones, Empirical Software Engineering 15
(1) (2010) 1–34.
[224] Y. Ueda, T. Kamiya, S. Kusumoto, K. Inoue, On detection of gapped code clones
using gap locations, in: Proceedings 9th Asia–Paciﬁc Software Engineering
Conference (APSEC’02), Gold Coast, Queensland, Australia, 2002, pp. 327–
336.
[225] Y. Ueda, T. Kamiya, S. Kusumoto, K. Inoue, Gemini: Maintenance support
environment based on code clone analysis, in: Proceedings of the 8th IEEE
Symposium on Software Metrics (METRICS’02), Ottawa, Canada, 2002, pp.
67–76.
[226] V. Wahler, D. Seipel, J.W. Gudenberg, G. Fischer, Clone detection in source
code by frequent itemset techniques, in: Proceedings of the 4th IEEEInternational Workshop Source Code Analysis and Manipulation (SCAM’04),
Chicago, IL, USA, 2004, pp. 128–135.
[227] A. Walenstein, N. Jyoti, J. Li, Y. Yang, A Lakhotia, Problems creating task-
relevant clone detection reference data, in: Proceedings of the 10th Working
Conference on Reverse Engineering (WCRE’03), Victoria, BC, Canada, 2003,
pp. 285–295.
[228] R. Wettel, R. Marinescu, Archeology of code duplication: Recovering
duplication chains from small duplication fragments, in: Proceedings of the
7th International Symposium on Symbolic and Numeric Algorithms for
Scientiﬁc, Computing, 2005, p. 8.
[229] J. Whaley, M.S. Lam, Cloning- based context- sensitive pointer alias analysis
using binary decision diagrams, in: Proceedings of the InternationalConference on Programming Language Design and Implementation
(PLDI’04), Washington DC, USA, 2004, pp. 131–144.
[230] T. Yamashina, H. Uwano, K. Fushida, Y. Kamei, M. Nagura, S. Kawaguchi, H.
Iida, SHINOBI: a tool for automatic code clone detection in the IDE, in:
Proceedings of the 16th Working Conference on Reverse Engineering(WCRE’09), Lille, France, 2009, pp. 313–314.
[231] W. Yang, Identifying syntactic differences between two programs, Software
Practice and Experience 21 (7) (1991) 739–755.
[232] R. Yokomori, H. Siy, N. Yoshida, M. Noro, K. Inoue, Measuring the effects of
aspect-oriented refactoring on component relationships: two case studies, in:1198 D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199
Proceedings of 10th Aspect-Oriented Software Development Conference
(AOSD’11), Pernambuco, Brazil, 2011, pp. 215–226.
[233] N. Yoshida, T. Ishio, M. Matsushita, K. Inoue, Retrieving similar code
fragments based on identiﬁer similarity for defect detection, in:
Proceedings of the 2008 workshop on Defects in large software systems in
companion to International Symposium on Software Testing and Analysis(DEFECTS’08), Seattle, Washington, 2008, pp. 41–42.
[234] N. Yoshida, Y. Higo, T. Kamiya, S. Kusumoto, K. Inoue, On refactoring support
based on code clone dependency relation, in: Proceedings of the 11th IEEEInternational Software Metrics Symposium (METRICS’05), Como, Italy, 2005,
pp. 16–25.
[235] N. Yoshida, T. Hattori, K. Inoue, Finding similar defects using synonymous
identiﬁer retrieval, in: Proceedings of 4th International Workshop on
Software Clones, Cape Town, SA, 2010, pp. 49–56.
[236] Y. Zhang, H. A. Basit, S. Jarzabek, D. Anh, M. Low, Query-based ﬁltering and
graphical view generation for clone analysis, in: Proceedings of the 24th IEEE
International Conference on Software Maintenance (ICSM’08), Beijing, China,
2008, pp. 376–385.D. Rattan et al. / Information and Software Technology 55 (2013) 1165–1199 1199


Software Evolution – Reader
Edition 2025/2026 – Version 0.31
Paul Klint1 4, Jurgen Vinju1 4 7, Tijs van der Storm (guest lecturer)1 6, Magiel
Bruntink3, Davy Landman4, Vadim Zaytsev (guest lecturer)5, Simon Baars2 8,
Riemer van Rozen1, Georgia Samaritaki (teacher)2, Martin Bor2,
Damian Frölich (teacher)2, and Thomas van Binsbergen (course coordinator)2
1Software Analysis & Transformation, Centrum Wiskunde & Informatica
2Master of Software Engineering, University of Amsterdam
3Software Improvement Group
4SWAT.engineering
5University of Twente
6University of Groningen
7Eindhoven University of Technology
8Picnic
October 22, 2025
Abstract
This is a reader to the course Software Evolution. It describes course goals, a
week-by-week course schedule, obligatory assignments and grading. In a nutshell,
this manual explains how to pass this course1. Updates are provided on Canvas.
1 Course Overview
Software Evolution is a course in the Master of Software Engineering at the Uni-
versity of Amsterdam of 6 ECTS. We provide descriptions of course material in
Section 1.2, required course activities in Section 1.3, a detailed schedule in Sec-
tion 1.4, and reading in Section 1.5. Section 2 describes the practical assignments.
Please read this document carefully!
1This reader does not explain how to get the most out of this course, that’s up to you.
Software Evolution’s Evolution. The Software Evolution course itself has evolved over
the years. Thanks and kudos for developing and maintaining this course and its assignments
go to: Prof. Dr. Paul Klint, Prof. Dr. Jurgen Vinju, Dr. Magiel Bruntink, Dr. Vadim
Zaytsev, and Dr. Riemer van Rozen. Current editor: Dr. L. Thomas van Binsbergen.
1
1.1 Goals
“The graduate masters the methods and techniques needed to analyze an existing
software system and to enable it to evolve given changing requirements.”
The following are the official learning objectives of the course:
•Understand a wide range of challenges stemming from the fact that software
is developed in large, dynamic teams, is subjected to changing requirements
and needs to be adapted to new contexts
•Apply language engineering and empirical software engineering techniques to
large code-bases to analyse them using various software quality metrics (e.g.
to measure maintainability)
•Analysescientificcontributionsfromselectedpapersaddressingthechallenges
in software evolution discussed in lectures and covered in practical assign-
ments
•Evaluate one’s own implementation of a software analysis tool by experi-
menting with the implementation (e.g. tweaking parameters or implementa-
tion choices), drawing comparisons with alternative approaches in literature,
and/or against a set of clearly specified requirements
The first objective is covered primarily through the lectures, the discussions
during the lectures and the reading material. The second objective is covered pri-
marily by the first practical assignment (Series 1). The third objective is covered
primarily by the academic reading and writing assignment (Annotated Bibliogra-
phy). The fourth objective is covered primarily by the second practical assignment
(Series 2). Notice the big difference between ‘apply’ (second objective, Series 1)
and ‘evaluate’ (fourth objective, Series 2) which is reflected in the fact that Series
2 is graded primarily on the strength of your evaluation and less so, compared to
Series 1, on the achieved results.
1.2 Course Material
Slides & Papers. We provide a selection of scientific papers and lecture slides,
which are available on Canvas. Additional papers can be found at the
•ACM Digital Library http://www.acm.org/dl
•IEEE Digital Library http://ieeexplore.ieee.org
andhttps://www.computer.org
Rascal.For the practical lab assignments we use the metaprogramming
language and language workbench R ascal2. Rascalhas a built-in Tutorthat
provides explanations on concepts and interactive exercises for learning to apply
language features. A non-interactive version is available online3. Additionally,
questions can be posed on Stackoverflow4using the rascaltag, and issues can be
reported on GitHub5.
2http://www.rascal-mpl.org
3http://docs.rascal-mpl.org/unstable/TutorHome
4http://stackoverflow.com/questions/tagged/rascal
5https://github.com/usethesource/rascal/issues
2
1.3 Required Course Activities
The course consists of activities related to reading scientific papers, discussing
those papers, attending lectures and working on assignments in the practical lab.
All students are encouraged to work in the lab during the scheduled contact hours
and to make the most out of these moments by asking for feedback from peers and
teachers.
•Reading: Students study a selection of scientific papers each week, as well
as the slides that accompany the lecture. Please check the course schedule
for detailed information in Section 1.4 and weekly reading in Section 1.5.
•Writing: For the practical assignments technical reports are to be written
that describe and reflect on the contributions made by the project as well as
how the contributions are related to scientific papers. These can be papers
recommended in this reader or found by the students themselves. Special
attention is given to analyzing scientific papers and discussing papers as part
of an annotated bibliography. The bibliography and the (other) assignments
are discussed towards the end of this reader.
•Lecture: Throughout the course several (guest) lectures are given on topics
that relate to the papers being studied or the projects being executed. These
lecture hours are announced in advance, for example on the course schedule
in Section 1.4. The group discusses the concepts, problems and solutions
introduced during these lectures.
•Practical Lab: Students work on practical assignments in pairs. During
contact hours, students are encouraged to ask for feedback with the teachers,
improving their work over several iterations before finally handing it in before
the deadline. The (series 2) projects are presented and demonstrated in the
final week of the course.
1.3.1 Grading
The course grade is the average of three grades6, for practical lab Series 1 and
Series 2 and an individual grade for an Annotated Bibliography of papers you have
studied7. Grades are calculated as follows.
grade(series1, annotated_bibliography, series2) =
(grade(series1) + grade(annotated_bibliography) + grade(series2))/3
There are no opportunities for resits or deadline extensions unless for extenu-
ating circumstances to be communicated with the study advisor.
1.3.2 Submission Guidelines
When submitting your code for Series 1 andSeries 2
•Do not submit the files of smallsql and hsqldb
6Note: UvA’s rounding rules apply.
7Note: Practical lab Series 0 is mandatory but not graded.
3
•Only submit 1 single compressed file
•Check the description of the assignment for the precise contents
1.4 Course Schedule
Table 1 shows a week-by-week schedule of topics, lecture dates and lecturers. The
columns Subject,DateandLecturer respectively show a brief description of the
subjectsforthatweek, thedateofthelecture, andthenameofthe(guest)lecturer.
The table is subject to possible changes.
Week Subject Lecturer Time
1 Introduction to Software Evolution[22, 13] Thomas M 11-13
2 Introduction to Rascal[19, 18] Tommaso M 11-12
The EASY method in Rascal Tijs van der Storm M 12-13
3 Software Metrics at SIG[12, 3] Bugra Yildiz M 11-13
Dennis Bijlsma
4 Clone Detection and Management[20, 16] Damian M 11-13
5 Semantics and Equality[4, 5] Thomas M 11-13
6 Breaking Changes[25, 24, 6] Lina Ochoa Venegas M 11-13
7 Rejuvenating a 40y old DSL environment Davy Landman M 11-13
8
Table 1: Course Plan: Lecture Topics, Lecture Dates, Lecturers and Question hours
Software evolution involves a lot of self-study and it is important to make the
most out of the contact hours that are available, especially during the lab hours.
1.5 Reading
This is the list of recommended papers per week of the course as relevant to the
lectures of that week. Some of the papers mentioned here are mandatory for the
annotated bibliography, as indicated in the description of that assignment.
Week 1
•T.Mens. “SoftwareEvolution”. In: ed.byT.MensandS.Demeyer. Springer,
2008. Chap. 1. Introduction and Roadmap: History and Challenges of Soft-
ware Evolution, pp. 2–11. isbn: 978-3-540-76440-3. doi:10.1007/978-3-
540-76440-3
•I. Herraiz et al. “The Evolution of the Laws of Software Evolution: A Discus-
sion Based on a Systematic Literature Review”. In: ACM Comput. Surv. 46.2
(Dec. 2013), pp. 1–28. issn: 0360-0300. doi:10.1145/2543581.2543595
Week 2
4
•I. Heitlager, T. Kuipers, and J. Visser. “A Practical Model for Measuring
Maintainability”. In: Quality of Information and Communications Technol-
ogy, 2007. QUATIC 2007. 6th International Conference on the . 2007, pp.30–
39.doi:10.1109/QUATIC.2007.8
•R. Baggen et al. “Standardized Code Quality Benchmarking for Improving
Software Maintainability”. In: Software Quality Journal 20.2 (June 2012),
pp. 287–307. issn: 1573-1367. doi:10.1007/s11219-011-9144-9
Week 3
•P. Klint, T. v. d. Storm, and J. Vinju. “RASCAL: A Domain Specific Lan-
guage for Source Code Analysis and Manipulation”. In: Proceedings of the
2009 Ninth IEEE International Working Conference on Source Code Analysis
and Manipulation, SCAM 2009, Edmonton, AB, Canada, September 20–21,
2009. IEEE, 2009, pp. 168–177. isbn: 978-0-7695-3793-1. doi:10.1109/
SCAM.2009.28
•P. Klint, T. van der Storm, and J. Vinju. “Rascal, 10 Years Later”. In:
2019 19th International Working Conference on Source Code Analysis and
Manipulation (SCAM) . 2019, pp. 139–139. isbn: 978-1-7281-4937-0. doi:
10.1109/SCAM.2019.00023
Week 4
•R. Koschke. “Software Evolution”. In: ed. by T. Mens and S. Demeyer.
Springer, 2008. Chap. 2. Identifying and Removing Software Clones, pp. 15–
36.isbn: 978-3-540-76440-3. doi:10.1007/978-3-540-76440-3
•C. Kapser and M. W. Godfrey. “‘Cloning Considered Harmful’ Considered
Harmful”. In: 2006 13th Working Conference on Reverse Engineering . Oct.
2006, pp. 19–28. doi:10.1109/WCRE.2006.1
Week5 Thefollowingreadingisrecommendedforthelecturesandisnotmanda-
tory for the annotated bibliography, unless state differently elsewhere:
•B. Basten et al. “Modular language implementation in Rascal – experience
report”. In: Science of Computer Programming 114(2015). LDTA(Language
Descriptions, Tools, and Applications) Tool Challenge, pp. 7–19. issn: 0167-
6423. doi:10.1016/j.scico.2015.11.003
•L.T.vanBinsbergen,P.D.Mosses,andN.Sculthorpe. “ExecutableComponent-
Based Semantics”. In: Journal of Logical and Algebraic Methods in Program-
ming103 (Feb. 2019), pp. 184–212. doi:10.1016/j.jlamp.2018.12.004
Week6 Thefollowingreadingisrecommendedforthelecturesandisnotmanda-
tory for the annotated bibliography, unless state differently elsewhere:
•L. Ochoa et al. “Breaking bad? Semantic versioning and impact of breaking
changes in Maven Central”. In: Empir. Softw. Eng. 27.3 (2022), p. 61. doi:
10.1007/s10664-021-10052-y
A replication study of :
5
–S. Raemaekers, A. van Deursen, and J. Visser. “Semantic versioning and
impact of breaking changes in the Maven repository”. In: Journal of
Systems and Software 129 (2017), pp. 140–158. issn: 0164-1212. doi:
10.1016/j.jss.2016.04.008
•L. Ochoa, T. Degueule, and J. Falleri. “BreakBot: Analyzing the Impact of
Breaking Changes to Assist Library Evolution”. In: 2022 IEEE/ACM 44th
International Conference on Software Engineering: New Ideas and Emerging
Results (ICSE-NIER) . 2022, pp. 26–30. doi:10.1145/3510455.3512783
•C. Bogart et al. “When and How to Make Breaking Changes: Policies and
Practices in 18 Open Source Software Ecosystems”. In: 30.4 (July 2021).
issn: 1049-331X. doi:10.1145/3447245
Week7 Thefollowingreadingisrecommendedforthelecturesandisnotmanda-
tory for the annotated bibliography, unless state differently elsewhere:
•V. Zaytsev. “Software Language Engineers’ Worst Nightmare”. In: Proceed-
ings of Software Language Engineering 2020 (SLE 2020) . Nov. 2020. doi:
10.1145/3426425.3426933
•V. Zaytsev. “Modelling of Language Syntax and Semantics: The Case of the
Assembler Compiler”. In: Journal of Object Technology 19.2 (July 2020). Ed.
by A. Vallecillo. The 16th European Conference on Modelling Foundations
and Applications (ECMFA 2020), 5:1–22. issn: 1660-1769. doi:10.5381/
jot.2020.19.2.a5
Publications related to Master and Course Projects
The following papers have resulted from student projects related to this course.
These papers serve as inspirational examples only, and are not required for the
annotated bibliography assignment.
•A. Hamid and V. Zaytsev. “Detecting Refactorable Clones by Slicing Pro-
gram Dependence Graphs”. In: Post-proceedings of the Seventh Seminar
on Advanced Techniques and Tools for Software Evolution, SATToSE 2014,
L’Aquila, Italy, July 9–11, 2014 . Ed. by D. di Ruscio and V. Zaytsev.
Vol. 1354. CEUR Workshop Proceedings. CEUR-WS.org, 2014, pp. 37–
48.url:https://dare.uva.nl/search?identifier=d0ad3c4a- 5d65-
44d7-bbe9-2c062598c64b
•J. Jansen, A. Oprescu, and M. Bruntink. “The Impact of Automated Code
Quality Feedback in Programming Education”. In: Proceedings of the Semi-
nar Series on Advanced Techniques and Tools for Software Evolution, SAT-
ToSE 2017, Madrid, Spain, June 7–9, 2017 . Vol. 2070. CEUR Workshop
Proceedings. CEUR-WS.org, 2017. url:http : / / ceur - ws . org / Vol -
2070/paper-04.pdf
•N. Lodewijks. “Analysis of a Clone-and-Own Industrial Automation System:
An Exploratory Study”. In: Proceedings of the Seminar Series on Advanced
Techniques and Tools for Software Evolution, SATToSE 2017, Madrid, Spain,
6
June 7–9, 2017 . Vol. 2070. CEUR Workshop Proceedings. CEUR-WS.org,
2017. url:http://ceur-ws.org/Vol-2070/paper-05.pdf
•R. van Rozen and Q. Heijn. “Measuring Quality of Grammars for Procedural
Level Generation”. In: Proceedings of the 13th International Conference on
Foundations of Digital Games, FDG 2018, as part of the 9th Workshop on
Procedural Content Generation, PCG 2018, Malmö, Sweden, August 7–10,
2018. ACM, 2018, pp. 1–8. doi:10.1145/3235765.3235821
•S. Baars and S. Meester. “CodeArena: Inspecting and Improving Code Qual-
ity Metrics using Minecraft”. In: Proceedings of the 2nd International Confer-
ence on Technical Debt, TechDebt@ICSE 2019, Montreal, QC, Canada, May
26–27, 2019 . Ed. by P. Avgeriou and K. Schmid. IEEE, 2019, pp. 68–70.
doi:10.1109/TechDebt.2019.00023
•D. Frolich and L. T. van Binsbergen. “A Generic Back-End for Exploratory
Programming”. In: Trends in Functional Programming: 22nd International
Symposium, TFP 2021, Virtual Event, February 17–19, 2021, Revised Se-
lected Papers . Berlin, Heidelberg: Springer-Verlag, 2021, pp. 24–43. isbn:
978-3-030-83977-2. doi:10.1007/978-3-030-83978-9_2
Recent Master Theses Related to the Software Evolution
The following links point to selected Master theses that have been published in
the library of the university:
•Stefan Vlastuin (InfoSupport), 2024:
https://scripties.uba.uva.nl/search?id=record_55066
•Floris van Leeuwen (Software Improvement Group), 2024:
https://scripties.uba.uva.nl/search?id=record_55281
•Jorrit Stutterheim (Internal), 2023:
https://scripties.uba.uva.nl/search?id=record_53890
•Matthias van Ingen (Software Improvement Group), 2023:
https://scripties.uba.uva.nl/search?id=record_53892
•Andreea Moise (Software Improvement Group), 2023:
https://scripties.uba.uva.nl/search?id=record_53889
•Núria Bruch Tàrrega (Software Improvement Group), 2020:
https://scripties.uba.uva.nl/search?id=record_29378
7
2 Assignments
Students are required to complete three obligatory practical assignment series for
this course. During the first (Series 0) you work alone. This series is approved
but not graded. During the second and third (Series 1 and 2) you work in the
same group of two students. When you have completed the assignment you can
request your lecturer to approve your work by explaining what you did. Detailed
submission instructions are in this reader. Deadlines are at the very end of the
week. Table 2 shows how to work on assignments and Table 3 when to work on
assignments and deadlines to deliver them.
Deliverable Type of work
Practical Lab Series 0 Individual work
Practical Lab Series 1 Team work
Practical Lab Series 2 Team work
Annotated Bibliography Individual work
Table 2: Assignments and how to work on them.
Week Practical Lab Writing /Reading Deadline
1 Series 0 and 1 Annotated Bibliography Series 0
2 Series 1 Annotated Bibliography
3 Series 1 Annotated Bibliography Series 1 – see Canvas
4 Series 2 Annotated Bibliography
5 Series 2 Annotated Bibliography
6 Series 2 Annotated Bibliography
7 Series 2 Annotated Bibliography Series 2 – see Canvas
8 Presentations Series 2 Annotated Bibliography Annotated Bibliography
Table 3: When to work on assignments and deadlines to deliver them.
Next we describe the practical assignments, which include details on grading
for each assignment series.
8
Annotated Bibliography
The (guest) lectures of this course are associated with recommended reading. In
this assignment you structure your own thoughts and critical reflections on these
papers by writing a scientific paper in the form of an ‘annotated bibliography’.
Collaboration
You need to perform this assignment individually. You are allowed to discuss
literature with other students, but have to write the annotated bibliography alone.
Reading lists
For your annotated bibliography you will read the following mandatory papers
plus a chosen extension focusing on a certain topic relevant to software evolution
(you choose a list, not individual papers; no mixing allowed):
Mandatory
•T.Mens. “SoftwareEvolution”. In: ed.byT.MensandS.Demeyer. Springer,
2008. Chap. 1. Introduction and Roadmap: History and Challenges of Soft-
ware Evolution, pp. 2–11. isbn: 978-3-540-76440-3. doi:10.1007/978-3-
540-76440-3
•I. Herraiz et al. “The Evolution of the Laws of Software Evolution: A Discus-
sion Based on a Systematic Literature Review”. In: ACM Comput. Surv. 46.2
(Dec. 2013), pp. 1–28. issn: 0360-0300. doi:10.1145/2543581.2543595
•R. Koschke. “Software Evolution”. In: ed. by T. Mens and S. Demeyer.
Springer, 2008. Chap. 2. Identifying and Removing Software Clones, pp. 15–
36.isbn: 978-3-540-76440-3. doi:10.1007/978-3-540-76440-3
•C. Kapser and M. W. Godfrey. “‘Cloning Considered Harmful’ Considered
Harmful”. In: 2006 13th Working Conference on Reverse Engineering . Oct.
2006, pp. 19–28. doi:10.1109/WCRE.2006.1
Choice 1: Metrics
•I. Heitlager, T. Kuipers, and J. Visser. “A Practical Model for Measuring
Maintainability”. In: Quality of Information and Communications Technol-
ogy, 2007. QUATIC 2007. 6th International Conference on the . 2007, pp.30–
39.doi:10.1109/QUATIC.2007.8
•R. Baggen et al. “Standardized Code Quality Benchmarking for Improving
Software Maintainability”. In: Software Quality Journal 20.2 (June 2012),
pp. 287–307. issn: 1573-1367. doi:10.1007/s11219-011-9144-9
•N. Fenton. “Software Measurement: A Necessary Scientific Basis”. In: IEEE
Transactions on Software Engineering 20.3 (Mar. 1994), pp. 199–206. issn:
0098-5589. doi:10.1109/32.268921
•T. L. Alves, C. Ypma, and J. Visser. “Deriving metric thresholds from bench-
mark data”. In: 2010 IEEE International Conference on Software Mainte-
nance. 2010, pp. 1–10. doi:10.1109/ICSM.2010.5609747
9
•L. Ochoa et al. “Breaking bad? Semantic versioning and impact of breaking
changes in Maven Central”. In: Empir. Softw. Eng. 27.3 (2022), p. 61. doi:
10.1007/s10664-021-10052-y
•L. Ochoa, T. Degueule, and J. Falleri. “BreakBot: Analyzing the Impact of
Breaking Changes to Assist Library Evolution”. In: 2022 IEEE/ACM 44th
International Conference on Software Engineering: New Ideas and Emerging
Results (ICSE-NIER) . 2022, pp. 26–30. doi:10.1145/3510455.3512783
Choice 2: Software Language Engineering
•P. Klint, T. v. d. Storm, and J. Vinju. “RASCAL: A Domain Specific Lan-
guage for Source Code Analysis and Manipulation”. In: Proceedings of the
2009 Ninth IEEE International Working Conference on Source Code Analysis
and Manipulation, SCAM 2009, Edmonton, AB, Canada, September 20–21,
2009. IEEE, 2009, pp. 168–177. isbn: 978-0-7695-3793-1. doi:10.1109/
SCAM.2009.28
•B. Basten et al. “Modular language implementation in Rascal – experience
report”. In: Science of Computer Programming 114(2015). LDTA(Language
Descriptions, Tools, and Applications) Tool Challenge, pp. 7–19. issn: 0167-
6423. doi:10.1016/j.scico.2015.11.003
•S. Erdweg et al. “The State of the Art in Language Workbenches: Con-
clusions from the Language Workbench Challenge”. In: Software Language
Engineering – Proceedings of the 6th International Conference, SLE 2013,
Indianapolis, IN, USA, October 26–28, 2013 . Ed. by M. Erwig, R. F. Paige,
and E. Van Wyk. Vol. 8225. LNCS. Springer, 2013, pp. 197–217. isbn:
978-3-319-02654-1. doi:10.1007/978-3-319-02654-1_11
•V. Zaytsev. “Software Language Engineers’ Worst Nightmare”. In: Proceed-
ings of Software Language Engineering 2020 (SLE 2020) . Nov. 2020. doi:
10.1145/3426425.3426933
•V. Zaytsev. “Modelling of Language Syntax and Semantics: The Case of the
Assembler Compiler”. In: Journal of Object Technology 19.2 (July 2020). Ed.
by A. Vallecillo. The 16th European Conference on Modelling Foundations
and Applications (ECMFA 2020), 5:1–22. issn: 1660-1769. doi:10.5381/
jot.2020.19.2.a5
•L.T.vanBinsbergen,P.D.Mosses,andN.Sculthorpe. “ExecutableComponent-
Based Semantics”. In: Journal of Logical and Algebraic Methods in Program-
ming103 (Feb. 2019), pp. 184–212. doi:10.1016/j.jlamp.2018.12.004
Assignment
•Content. For each paper on the selected reading list you write a concise
discussion (2-4 coherent paragraphs in your own words) of the paper.
•Format. Submissions should use the article format, single column, standard
page width (i.e. do not modify the margins), 11 point font, using the font
family Times New Roman. Use the template shown in Figure 1 without
10
modificationsotherthanyourpersonaldetails, introduction, andannotations.
All submissions should be in PDF format.
Page limit. Submissions are limited to 6 pages excluding the section titled ‘Ref-
erences’. Submissions that exceed the page limit will not be graded or penalised.
The lectures provide a presentation of (some of) the reading material, but of
course this is subject to the teacher’s interpretations and preferences. In your text
you argue your own critical opinion, a perspective on the subject matter that is
well-argued, insightful, and can be adopted by the reader. A good text is clear,
concise, presents relevant argumentation and displays critical thinking. As a piece
of academic writing, you should cite other literature that you find yourself in order
to support your claims and strengthen your argument.
Tips
Examplequestionsyoucanconsideransweringintheannotationsarethefollowing.
What can be learnt from a paper, what is its intended audience, and what are its
scientific contributions? How are these contributions evaluated? Does the paper
have practical implications, and what are the costs and benefits of applying the
proposed approach or best practices (if any)? What is the research methodology,
and how are its claims validated and evaluated? Are there threats to validity?
How does the paper relate to other work, and to the state-of-the-art?
You cannot answer all these questions within the page limit; you will have to
choose a focus for your discussion, a theme that you return to for each of the
papers, such as: practicality, (potential) impact, relation to software evolution,
methodology, validity, up-to-dateness, etc.
We encourage you to compare some annotated bibliographies, e.g., see Cornell’s
guidelines8. Your paper contains the following elements as discussed in the reading
assignments from “Preparation Master Project”.
•Introduction. The annotated bibliography should be a self-contained article
which requires an introduction. An introduction usually describes the topic
(e.g., the chosen theme) and intended audience.
•Annotations per paper. Every paper must have a self-contained annota-
tion of 2-4 paragraphs as described above. Every annotation should mention
essential elements of the paper and contain a (critical) reflection.
Please consider the following (non-exhaustive) general academic writing tips.
•Use active voice, i.e. avoid passive voice.
•Try to avoid first-person pronouns (but keep an active voice).
•If a first-person pronoun is warranted, use ‘authorial we’ (also ‘royal we’),
•Use the present tense where possible.
•Avoid ambiguous references such as arising from ‘it’, ‘this’, etc.
•Be concise and to the point.
•Avoid repetition. Use your space economically.
•Split complex sentences. Every sentence ideally makes one (new) point.
8http://guides.library.cornell.edu/annotatedbibliography
11
\ documentclass [11 pt ]{ article }
\ usepackage [ backend =biber , style = numeric , natbib =true , doi =false , isbn =false ,
issn =false , firstinits =true , maxcitenames =1, maxbibnames =99]{ biblatex }
% populate papers . bib with the bibtex entries of the annotated papers and
any papers cited in your annotations
\ addbibresource { papers .bib }
\ begin { document }
\ title { Title Text }
\ author { Name ( and student number )\\ Affiliation \\ Email }
\ maketitle
\ subsubsection *{ Introduction }
Write a short , concise introduction explaining the focus you decided to
apply in your reflections given in the annotations .
\ subsubsection *{ Bibliography }
% your annotations go here , using \ fullcite {name -of - paper } followed by
your annotation . Continue in the style started here .
{\\\ noindent \em\ fullcite { Mens 2008 Ch 1}\\\ indent }
The start of the annotation ...
% next citation
{\\\ noindent \em\ fullcite { Herraiz 2013}\\\ indent }
Second annotation ... etc .
\ clearpage %% the references do not count to the page limit
\ printbibliography
\ end { document }
Figure 1: Annotated Bibliography LaTeX Template
Grading
The annotated bibliography will be graded using the following model:
Factor Base grade
modification
Missing name and/or introduction paragraph -0.5
Writing quality: proper spelling, grammar, and structure. -1.0 to +1.0
Each paper on the reading list that is missing or not covered in
sufficient depth in the bibliography.-0 to -0.5 per paper
The bibliography clearly argues the students critical opinion on the
contents of the papers.+0 to +1.0
The bibliography considers literature outside of the reading list to
support argumentation.+0 to +1.0
Table 4: Grading Conditions and Scoring for the Annotated Bibliography
The base grade is 7. For this grade you need to produce an annotated bibli-
ography that conforms to the assignment described above. The factors of Table 4
modify the base grade. The grade range is 1 to 10.
Deadline
The annotated bibliography should be delivered in course week 8.
The precise deadline is on Canvas.
12
]
Practical Lab Series 0 – R ascalBasics
Rascalis a meta-programming language and language workbench that enables
constructing source code analyzers, programming languages, compilers and tools.
We will use R ascalfor the practical labs of this course.
In this lab you learn the basic facts about R ascal[19, 17, 18] and practice
applying its language features. The idea is that you learn to interact with R ascal
using VScode by doing a few small challenges in Rascal. As a reference for learning
Rascal syntax, you can use the Rascal concepts page linked to below.
Documentation
Please consult the following pages as your main references for Rascal:
•Installation instructions,
•Rascal reference manual, and
•Rascal recipes pages
The recipes are useful example programs that show a large set of the features of
the language by implementing example algorithms and small languages.
Note that both R ascal, its tooling and its documentation are under constant
revision. As a consequence, bugs in the language or tooling may be encountered
whileworkingonyourexamples. Theseshouldbereportedinthemethoddescribed
below. The links above are to the new documentation. The old documentation
can be found here when needed. The VScode plugin is a new addition to R ascal’s
toolbox; traditionally R ascalprograms were developed using the Eclipse plugin
or the command-line shell using the .JAR provided. You might also like to take
a look at the R ascalsource code. Since 2024, Rascal support for Eclipse can be
considered deprecated.
Questions and Bugs Reports
Please use the following platforms for questions and bug reports.
•We invite you to pose questions and to share how to resolve issues on Slack.
•Technical questions related to Rascal, should be asked on Stackoverflow using
the rascal tag: http://stackoverflow.com/questions/tagged/rascal .
•Bug reports can be submitted on GitHub.
https://github.com/usethesource/rascal/issues .
Collaboration
Please do the exercises for Series 0 individually. After all, you should be able to
program in R ascalindividually after Series 0.
13
Assignment
Teach yourself R ascal:
•Study its concepts, language features, library and try recipes.
https://new.rascal-mpl.org/docs/Recipes/
•Solve the Series 0 problems posted on Canvas as preparation for Series 1/2.
You will be assisted in the laboratory to install the system and type your first
expressions and statements. Please ask the teachers any question about R ascal
or the exercises you might have. It will be hard work!
Grading
This series is not graded. Please explore, investigate and study R ascaluntil you
are confident you have sufficient knowledge to start Series 1.
Deadline
You should finish Series 0 in the first week of the course in order to start Series 1.
14
Practical Lab Series 1 – Software Metrics
In Series 1 we focus on software metrics. Software metrics are used (for example)
by the Software Improvement Group ( http://www.sig.eu ) to gain an overview of
the quality of software systems and to pinpoint problem areas that may cause low
maintainability. Some relevant questions are:
1. Which metrics are used?
2. How are these metrics computed?
3. How well do these metrics indicate what we really want to know about these
systems and how can we judge that?
4. How can we improve any of the above?
In other words, in this assignments you concern yourself with the motivation,
interpretation and implementation of metrics. The SIG Maintainability Model
provides an answer to question 1. You can read about it here:
•I. Heitlager, T. Kuipers, and J. Visser. “A Practical Model for Measuring
Maintainability”. In: Quality of Information and Communications Technol-
ogy, 2007. QUATIC 2007. 6th International Conference on the . 2007, pp.30–
39.doi:10.1109/QUATIC.2007.8 .
•Additional reading is provided by Baggen et al.[3], Visser et al.[34] and
online https://www.sig.eu/resources/sig-models/
Question 2 is partially answered by the 2007 paper referred to above and by you
in your programming for this assignment. The remaining questions are answered
in the report.
Collaboration
Series 1 and 2 are executed in (the same) pairs. You can work together as a pair
on all aspects of this assignment. You can brainstorm with anybody else about
the contents of your report, but for this assignment you are not allowed to look at
code from other groups or exchange solutions in detail with other groups. Golden
rule: “exchange ideas, not solutions!”
Assignment
Using Rascal, design and build a tool that calculates the SIG Maintainability
Model scores for a Java project. Document your approach in a report that com-
plements the implementation, e.g., by describing relevant design decisions, tests,
results, and what you did to address threats to validity. Make sure that your re-
port (also) answers all the questions of the above introduction.
Calculate at least the following metrics:
•Volume,
•Unit Size,
•Unit Complexity,
15
•Duplication.
For all metrics you calculate the actual metric values, for Unit Size and Unit
Complexity you additionally calculate a risk profile, and finally each metric gets a
score based on the SIG model ( −−,−,o,+,++).
Calculate scores for at least the following maintainability aspects based on the
SIG model:
•Maintainability (overall),
•Analysability,
•Changeability,
•Testability.
You can earn bonus points by also implementing the Test Quality metric and
a score for the Stability maintainability aspect.
Your tool should print textual output that contains all of the above information
in a way that is efficient with space, easy to read and makes it easy to confirm the
calculations.
Use the following zip file to obtain compilable versions of two Java systems
(smallsql and hsqldb): zip file9
•smallsql is a small system to use for experimentation and testing. Import
as-is into your IDE and ignore build errors.
•hsqldbis a larger system to demonstrate scalability.
Hints
•Create a Java project with example files to test your solution on (using the
Rascal test functionality).
•Create a Java project for each of the two systems, smallsql and hsqldb. Some
few lines of code will still not compile, but commenting them out would not
change the metrics too much. So commenting out just a few lines is ok in
this case. It saves time!
Grading
You submit a singlezip file containing the source code , a PDF of your report, and
adocument containing the output your tool produces for the test projects. The
files are checked for plagiarism automatically. You will be graded using the follow-
ing model. The base grade is 7. For this grade you need an implementation that
conforms to the assignment described above. Furthermore, your solution has a
sensible design and code implementation. In your report you explain and motivate
how your solution reads the Java code and calculates the metrics, the rankings, re-
flects on (additional) metrics and threats to validity. Your implementation should
be runnable when submitted. To demonstrate scalability empirically, also submit
ascriptthat makes it possible to reproduce your experiment(s) without effort.
9http://homepages.cwi.nl/~jurgenv/teaching/evolution1314/assignment1.zip
16
Condition Max grade
modifier
The metric value (total LOC) or ranking for Volume deviate without
good motivation-1.0
The metric value (%) or ranking for Duplication deviate without good
motivation-1.0
The risk profile or ranking for Unit Size deviate without good motivation -1.0
The risk profile or ranking for Unit Complexity deviate without good
motivation-1.0
The scores calculated for the maintainability aspects deviate without
good motivation-0.5
Your report critically reflects on the implementation of the metrics,
discusses design choices and possible alternatives-1.0 to +1.0
Your tool produces outputthat makes it easy to reproduce and verify the
(intermediate and overall) results of your analysis-0.5 to +0.5
You have implemented Test Quality and Stability and can argue the
correctness of your implementation+0.5
Your tool scalesto larger projects regarding running times as demon-
strated by an analysis of the algorithmic complexity of your algorithms
and/or through an empirical analysis of running the tool on projects of
various sizing (including smallsql and hsqldb) in the report+1.0
Yourcodeis well-structured, modular, separates concerns, has automated
tests and is easy to maintain-0.5 to +1.0
You have found another metric in the literature that is not in the SIG
Maintainability Model, can argue why and how it would improve the re-
sults, and implemented the metric.+1.0
Table 5: Grading Conditions and Scoring for Series 1
Table 5 shows conditions and how they modify the grade (the teachers have a
reference implementation that provides outputs for comparison).
Deadline
The deadline for handing in your submission is given on canvas.
17
Practical Lab Series 2 – Clone Detection
Code cloning is a phenomenon that is of both scientific and practical interest. In
the lecture and the related papers, clone detection and management techniques
were discussed, as well as the various arguments surrounding the problems that
code cloning causes.
In this lab we will build our own clone detection and management tools. Such
tools should be of help to software engineers like yourselves, so be sure that your
solution will at least satisfy your own needs! Compared to Lab Series 1, this
assignment will be more open. Your solution will be graded using more generic
criteria, with a stronger emphasis on motivation, argumentation, evaluation and
reflection. You will need to use literature discussed and referenced in the lectures
to find and motivate good solutions.
Collaboration
Complete the assignment in the same group as for Series 1. You can brainstorm,
but for this assignment you are not allowed to look at code from other groups or
exchange solutions in detail with other groups. The Golden Rule still applies.
Assignment
In this assignment you will implement AST-based clone detection and use it to
produce clones and statistics about clones for a given Java project (we use smallsql
and hsqldb again). After this first step you will either:
•Implement and compare clone detection algorithms, including clones of Type
II and Type III (back-end route)
•Implement and evaluate interactive visualizations of clones (classes) that aid
software maintenance (front-end route)
In both cases you will have to present a design of your solution (algorithms or
visualisations), draw from existing literature for your design, describe the imple-
mentation of your solution, and provide a thorough evaluation and reflection on
your design. These aspects are to be covered in a written report and in a presen-
tation in the last week of the course. The rubric gives considerably more weight
to evaluation and reflection compared to Series 1, emphasizing the more research-
minded nature of Series 2.
The assignment consists of two main deliverables. Some parts are only required
for the chosen route (where indicated):
1. Working prototype implementation of a clone management tool, consisting of
the following elements:
(a) An AST-based clone detector whose back-end is written in Rascal that
detects at least Type I clones in a Java project:
•Detected clone classes are written to a file in a textual representation.
•Clone classes that are strictly included in others are dropped from
the results (subsumption).
18
(b) A report of cloning statistics showing at least the % of duplicated lines,
number of clones, number of clone classes, biggest clone (in lines), biggest
clone class (in members), and example clones.
(c) (front-end route ) Insightful, interactive visualizations of cloning in a
project that help with software maintenance (at least two complementary
ones). The lecture discusses several example visualizations you could use.
(d) (back-end route ) A benchmark Java project that serves to demonstrate
the correctness of your clone detection algorithms with respect to the
types of clones they are meant to detect.
2. A written report that (1) describes, (2) motivates, and (3) reflects on the
following elements (not in order):
(a) Anexplanationoftheimplementationofyourclonedetectionalgorithm(s).
(b) (front-end route ) The requirements your tool satisfies from the per-
spective of a maintainer (see for instance [32]), and the related imple-
mentation choices.
(c) (front-end route ) The implementation of your visualization(s) and a
critical reflection (positive and negative) that establishes to which extent
the requirements have been satisfied by your visualizations
(d) (back-end route ) The exact type of clones your tool detects, giving
a sufficiently detailed definition that enables critical assessment of your
benchmark.
(e) (back-end route ) A detailed discussion of the (differences in) cloning
statistics produced by your different algorithms.
To score higher grade than the base grade additional work needs to be done.
For example, implementing many algorithms or visualisations of different kinds or
doing work from the other route. For details, see Table 6.
Implementation
The clone detection algorithms must be in implemented in pure R ascal. The
visualisations can be written in other languages.
Grading
Series 2 is primarily assessed on the report you submit. You will also give a
mandatory presentation that complements your report and can influence your
grade. Your submission includes a PDF file of your report, the source-code of
your implementation and the textual output reports produced for smallsql and
hsqldb. The files are checked for plagiarism automatically. You will not receive
a grade if you do not support a report or the source code, or if you do not give
a presentation. The presentation should describe the design of your solution(s)
and details the process and results of your evaluation. The presentation is a joint
presentation between both members of the group.
To qualify for grading you first need a solution that complies to the assignment
as described. The base grade is 7 and the conditions laid out in Table 6 modify
the grade.
19
Condition Max grade
modifier
(implementation ) Type I clone classes are incorrectly detected. -1.0
(implementation ) Missing textual output reports (including statistics)
for smallsql or hsqldb-0.5
(report) Type I algorithm is described incompletely or incomprehensibly. -1.0
(report) Unfounded, unsupported, or illogical motivations for the design -1.0
(back-end route ) Benchmark is limited in scope or not thorough. -1.0
(back-end route ) Comparisons between implemented algorithms is lack-
ing or superficial.-1.0
(front-end route ) Cloning visualizations are not interactive, do not give
insight, or do not work properly.-1.0
(front-endroute )Requirementsarenotclearlydefinedornotsufficiently
reflected upon.-1.0
(front-end route ) Correct detection of Type II, III, or IV clone classes +1.0
(back-end route ) Correct detection of Type IV clone classes +1.0
(presentation ) Well-motivated design of solution(s) presented clearly -0.5 to +0.5
(presentation ) Sound evaluation of solution(s) presented clearly -0.5 to +0.5
(presentation ) Insightful discussion in response to questions -0.5 to +0.5
You have designed, implemented, and evaluated additional solutions +2.0
The implementation, explanation or evaluation of a (mandatory or extra)
solution was executed with excellence+1.0
Table 6: Grading Conditions and Scoring for Series 2
Deadline
The deadline for handing in your submission is given on canvas. Shortly after the
deadline, the presentation sessions will be held according to a schedule announced
in due course.
Related Work on Software Clones
The following resources can help you get acquainted with clone management:
•C. K. Roy, J. R. Cordy, and R. Koschke. “Comparison and Evaluation of
Code Clone Detection Techniques and Tools: A Qualitative Approach”. In:
Sci. Comput. Program. 74.7 (May 2009), pp. 470–495. issn: 0167-6423. doi:
10.1016/j.scico.2009.02.007
•D. Rattan, R. Bhatia, and M. Singh. “Software Clone Detection: A Sys-
tematic Review”. In: Information and Software Technology 55.7 (July 2013),
pp. 1165–1199. issn: 0950-5849. doi:10.1016/j.infsof.2013.01.008 .
•C. K. Roy, M. F. Zibran, and R. Koschke. “The Vision of Software Clone
Management: Past, Present, and Future (Keynote paper)”. In: Software
20
Maintenance, Reengineering and Reverse Engineering (CSMR-WCRE), 2014
Software Evolution Week - IEEE Conference on . Feb. 2014, pp. 18–33. doi:
10.1109/CSMR-WCRE.2014.6747168
•C. Kapser and M. W. Godfrey. “‘Cloning Considered Harmful’ Considered
Harmful”. In: 2006 13th Working Conference on Reverse Engineering . Oct.
2006, pp. 19–28. doi:10.1109/WCRE.2006.1
•A. Hamid and V. Zaytsev. “Detecting Refactorable Clones by Slicing Pro-
gram Dependence Graphs”. In: Post-proceedings of the Seventh Seminar
on Advanced Techniques and Tools for Software Evolution, SATToSE 2014,
L’Aquila, Italy, July 9–11, 2014 . Ed. by D. di Ruscio and V. Zaytsev.
Vol. 1354. CEUR Workshop Proceedings. CEUR-WS.org, 2014, pp. 37–
48.url:https://dare.uva.nl/search?identifier=d0ad3c4a- 5d65-
44d7-bbe9-2c062598c64b
The first three are overviews [29, 27, 28], and there is one highly cited contro-
versial piece [16], the last one is an example paper that can result from a Master’s
thesis – it is easy to read and contains a simplified brief overview of the field [10].
Related Work on Visualization
Papers:
•H. Murakami, Y. Higo, and S. Kusumoto. “ClonePacker: A Tool for Clone
Set Visualization”. In: Proceedings of the 22nd International Conference on
Software Analysis, Evolution and Reengineering . Ed. by Y.-G. Gueheneuc,
B. Adams, and A. Serebrenik. IEEE, 2015, pp. 474–478. isbn: 978-1-4799-
8469-5. doi:10.1109/SANER.2015.7081859
•L. Voinea and A. C. Telea. “Visual Clone Analysis with SolidSDD”. in: Pro-
ceedings of the Second IEEE Working Conference on Software Visualization .
IEEE, 2014, pp. 79–82. doi:10.1109/VISSOFT.2014.22
•A. Hanjalic. “ClonEvol: Visualizing Software Evolution with Code Clones”.
In:Proceedings of the First IEEE Working Conference on Software Visual-
ization. IEEE, 2013, pp. 1–4. doi:10.1109/VISSOFT.2013.6650525
Visualization Libraries:
•Salix is a library for interactive tools and visualizations in R ascalusing a
browser10. Several demos are available, including live programming of state
machines, similar to the running example of [31]. – powerful yet experimental
•ExamplesofexternalvisualisationlibrariesareD311,vis12,Vega13andGephi14.
10https://github.com/cwi-swat/salix
11https://d3js.org
12http://visjs.org
13https://vega.github.io/vega/
14https://gephi.org
21
2.1 Related Work on Benchmarks
•K. Jezek and J. Dietrich. “API Evolution and Compatibility: A Data Corpus
and Tool Evaluation”. In: Journal of Object Technology 16.4 (Aug. 2017),
2:1–23. issn: 1660-1769. doi:10.5381/jot.2017.16.4.a2
•J. Svajlenko and C. K. Roy. “BigCloneEval: A Clone Detection Tool Evalua-
tion Framework with BigCloneBench”. In: 2016 IEEE International Confer-
ence on Software Maintenance and Evolution (ICSME) . 2016, pp. 596–600.
doi:10.1109/ICSME.2016.62 (see also15)
15https://github.com/jeffsvajlenko/BigCloneEval
22
References
[1] T. L. Alves, C. Ypma, and J. Visser. “Deriving metric thresholds from bench-
mark data”. In: 2010 IEEE International Conference on Software Mainte-
nance. 2010, pp. 1–10. doi:10.1109/ICSM.2010.5609747 .
[2] S. Baars and S. Meester. “CodeArena: Inspecting and Improving Code Qual-
ity Metrics using Minecraft”. In: Proceedings of the 2nd International Con-
ference on Technical Debt, TechDebt@ICSE 2019, Montreal, QC, Canada,
May 26–27, 2019 . Ed. by P. Avgeriou and K. Schmid. IEEE, 2019, pp. 68–
70.doi:10.1109/TechDebt.2019.00023 .
[3] R.Baggen,J.P.Correia,K.Schill,andJ.Visser.“StandardizedCodeQuality
Benchmarking for Improving Software Maintainability”. In: Software Quality
Journal 20.2 (June 2012), pp. 287–307. issn: 1573-1367. doi:10 . 1007 /
s11219-011-9144-9 .
[4] B. Basten, J. van den Bos, M. Hills, P. Klint, A. Lankamp, B. Lisser, A. van
der Ploeg, T. van der Storm, and J. Vinju. “Modular language implementa-
tion in Rascal – experience report”. In: Science of Computer Programming
114 (2015). LDTA (Language Descriptions, Tools, and Applications) Tool
Challenge, pp. 7–19. issn: 0167-6423. doi:10.1016/j.scico.2015.11.003 .
[5] L.T.vanBinsbergen,P.D.Mosses,andN.Sculthorpe.“ExecutableComponent-
Based Semantics”. In: Journal of Logical and Algebraic Methods in Program-
ming103 (Feb. 2019), pp. 184–212. doi:10.1016/j.jlamp.2018.12.004 .
[6] C. Bogart, C. Kästner, J. Herbsleb, and F. Thung. “When and How to Make
BreakingChanges:PoliciesandPracticesin18OpenSourceSoftwareEcosys-
tems”. In: 30.4 (July 2021). issn: 1049-331X. doi:10.1145/3447245 .
[7] S. Erdweg, T. van der Storm, M. Völter, M. Boersma, R. Bosman, W. R.
Cook, A. Gerritsen, A. Hulshout, S. Kelly, A. Loh, G. D. P. Konat, P. J.
Molina, M. Palatnik, R. Pohjonen, E. Schindler, K. Schindler, R. Solmi,
V. A. Vergu, E. Visser, K. van der Vlist, G. H. Wachsmuth, and J. van der
Woning. “The State of the Art in Language Workbenches: Conclusions from
the Language Workbench Challenge”. In: Software Language Engineering –
Proceedings of the 6th International Conference, SLE 2013, Indianapolis, IN,
USA, October 26–28, 2013 . Ed. by M. Erwig, R. F. Paige, and E. Van Wyk.
Vol. 8225. LNCS. Springer, 2013, pp. 197–217. isbn: 978-3-319-02654-1. doi:
10.1007/978-3-319-02654-1_11 .
[8] N. Fenton. “Software Measurement: A Necessary Scientific Basis”. In: IEEE
Transactions on Software Engineering 20.3 (Mar. 1994), pp. 199–206. issn:
0098-5589. doi:10.1109/32.268921 .
[9] D. Frolich and L. T. van Binsbergen. “A Generic Back-End for Exploratory
Programming”. In: Trends in Functional Programming: 22nd International
Symposium, TFP 2021, Virtual Event, February 17–19, 2021, Revised Se-
lected Papers . Berlin, Heidelberg: Springer-Verlag, 2021, pp. 24–43. isbn:
978-3-030-83977-2. doi:10.1007/978-3-030-83978-9_2 .
23
[10] A. Hamid and V. Zaytsev. “Detecting Refactorable Clones by Slicing Pro-
gram Dependence Graphs”. In: Post-proceedings of the Seventh Seminar on
Advanced Techniques and Tools for Software Evolution, SATToSE 2014,
L’Aquila, Italy, July 9–11, 2014 .Ed.byD.diRuscioandV.Zaytsev.Vol.1354.
CEURWorkshopProceedings.CEUR-WS.org,2014,pp.37–48. url:https:
/ / dare . uva . nl / search ? identifier = d0ad3c4a - 5d65 - 44d7 - bbe9 -
2c062598c64b .
[11] A. Hanjalic. “ClonEvol: Visualizing Software Evolution with Code Clones”.
In:Proceedings of the First IEEE Working Conference on Software Visual-
ization. IEEE, 2013, pp. 1–4. doi:10.1109/VISSOFT.2013.6650525 .
[12] I. Heitlager, T. Kuipers, and J. Visser. “A Practical Model for Measuring
Maintainability”. In: Quality of Information and Communications Technol-
ogy, 2007. QUATIC 2007. 6th International Conference on the . 2007, pp. 30–
39.doi:10.1109/QUATIC.2007.8 .
[13] I. Herraiz, D. Rodriguez, G. Robles, and J. M. Gonzalez-Barahona. “The
Evolution of the Laws of Software Evolution: A Discussion Based on a Sys-
tematic Literature Review”. In: ACM Comput. Surv. 46.2 (Dec. 2013), pp. 1–
28.issn: 0360-0300. doi:10.1145/2543581.2543595 .
[14] J. Jansen, A. Oprescu, and M. Bruntink. “The Impact of Automated Code
Quality Feedback in Programming Education”. In: Proceedings of the Semi-
nar Series on Advanced Techniques and Tools for Software Evolution, SAT-
ToSE 2017, Madrid, Spain, June 7–9, 2017 . Vol. 2070. CEUR Workshop
Proceedings. CEUR-WS.org, 2017. url:http://ceur-ws.org/Vol-2070/
paper-04.pdf .
[15] K. Jezek and J. Dietrich. “API Evolution and Compatibility: A Data Corpus
and Tool Evaluation”. In: Journal of Object Technology 16.4 (Aug. 2017),
2:1–23. issn: 1660-1769. doi:10.5381/jot.2017.16.4.a2 .
[16] C. Kapser and M. W. Godfrey. “‘Cloning Considered Harmful’ Considered
Harmful”. In: 2006 13th Working Conference on Reverse Engineering . Oct.
2006, pp. 19–28. doi:10.1109/WCRE.2006.1 .
[17] P. Klint, T. van der Storm, and J. Vinju. “EASY Meta-programming with
Rascal”. In: Generative and Transformational Techniques in Software Engi-
neering III: International Summer School, GTTSE 2009, Braga, Portugal,
July 6–11, 2009. Revised Papers . Ed. by J. M. Fernandes, R. Lämmel, J.
Visser, and J. Saraiva. Springer, 2011, pp. 222–289. isbn: 978-3-642-18023-
1.doi:10.1007/978-3-642-18023-1_6 .
[18] P. Klint, T. van der Storm, and J. Vinju. “Rascal, 10 Years Later”. In:
2019 19th International Working Conference on Source Code Analysis and
Manipulation (SCAM) .2019,pp.139–139. isbn:978-1-7281-4937-0. doi:10.
1109/SCAM.2019.00023 .
24
[19] P. Klint, T. v. d. Storm, and J. Vinju. “RASCAL: A Domain Specific Lan-
guage for Source Code Analysis and Manipulation”. In: Proceedings of the
2009 Ninth IEEE International Working Conference on Source Code Anal-
ysis and Manipulation, SCAM 2009, Edmonton, AB, Canada, September
20–21, 2009 . IEEE, 2009, pp. 168–177. isbn: 978-0-7695-3793-1. doi:10.
1109/SCAM.2009.28 .
[20] R. Koschke. “Software Evolution”. In: ed. by T. Mens and S. Demeyer.
Springer, 2008. Chap. 2. Identifying and Removing Software Clones, pp. 15–
36.isbn: 978-3-540-76440-3. doi:10.1007/978-3-540-76440-3 .
[21] N. Lodewijks. “Analysis of a Clone-and-Own Industrial Automation System:
An Exploratory Study”. In: Proceedings of the Seminar Series on Advanced
Techniques and Toolsfor Software Evolution, SATToSE2017, Madrid, Spain,
June 7–9, 2017 . Vol. 2070. CEUR Workshop Proceedings. CEUR-WS.org,
2017. url:http://ceur-ws.org/Vol-2070/paper-05.pdf .
[22] T. Mens. “Software Evolution”. In: ed. by T. Mens and S. Demeyer. Springer,
2008. Chap. 1. Introduction and Roadmap: History and Challenges of Soft-
ware Evolution, pp. 2–11. isbn: 978-3-540-76440-3. doi:10.1007/978-3-
540-76440-3 .
[23] H. Murakami, Y. Higo, and S. Kusumoto. “ClonePacker: A Tool for Clone
Set Visualization”. In: Proceedings of the 22nd International Conference on
Software Analysis, Evolution and Reengineering . Ed. by Y.-G. Gueheneuc,
B. Adams, and A. Serebrenik. IEEE, 2015, pp. 474–478. isbn: 978-1-4799-
8469-5. doi:10.1109/SANER.2015.7081859 .
[24] L. Ochoa, T. Degueule, and J. Falleri. “BreakBot: Analyzing the Impact of
Breaking Changes to Assist Library Evolution”. In: 2022 IEEE/ACM 44th
International Conference on Software Engineering: New Ideas and Emerging
Results (ICSE-NIER) . 2022, pp. 26–30. doi:10.1145/3510455.3512783 .
[25] L. Ochoa, T. Degueule, J. Falleri, and J. J. Vinju. “Breaking bad? Semantic
versioning and impact of breaking changes in Maven Central”. In: Empir.
Softw. Eng. 27.3 (2022), p. 61. doi:10.1007/s10664-021-10052-y .
[26] S. Raemaekers, A. van Deursen, and J. Visser. “Semantic versioning and
impact of breaking changes in the Maven repository”. In: Journal of Systems
and Software 129 (2017), pp. 140–158. issn: 0164-1212. doi:10.1016/j.
jss.2016.04.008 .
[27] D. Rattan, R. Bhatia, and M. Singh. “Software Clone Detection: A Sys-
tematic Review”. In: Information and Software Technology 55.7 (July 2013),
pp. 1165–1199. issn: 0950-5849. doi:10.1016/j.infsof.2013.01.008 .
[28] C. K. Roy, M. F. Zibran, and R. Koschke. “The Vision of Software Clone
Management:Past,Present,andFuture(Keynotepaper)”.In: Software Main-
tenance, Reengineering andReverse Engineering (CSMR-WCRE), 2014 Soft-
ware Evolution Week - IEEE Conference on . Feb. 2014, pp. 18–33. doi:
10.1109/CSMR-WCRE.2014.6747168 .
25
[29] C. K. Roy, J. R. Cordy, and R. Koschke. “Comparison and Evaluation of
Code Clone Detection Techniques and Tools: A Qualitative Approach”. In:
Sci. Comput. Program. 74.7 (May 2009), pp. 470–495. issn: 0167-6423. doi:
10.1016/j.scico.2009.02.007 .
[30] R. van Rozen and Q. Heijn. “Measuring Quality of Grammars for Procedural
Level Generation”. In: Proceedings of the 13th International Conference on
Foundations of Digital Games, FDG 2018, as part of the 9th Workshop on
Procedural Content Generation, PCG 2018, Malmö, Sweden, August 7–10,
2018. ACM, 2018, pp. 1–8. doi:10.1145/3235765.3235821 .
[31] R. van Rozen and T. van der Storm. “Toward Live Domain-Specific Lan-
guages: From Text Differencing to Adapting Models at Run Time”. In:
Software & Systems Modeling 18.1 (Feb. 2019). Special Section Paper on
STAF2015.ReceivedJune27th2016.RevisedMay26th2017.AcceptedJune
20th2017.FirstOnlineAugust14th2017,pp.195–212. issn:1619-1374. doi:
10.1007/s10270-017-0608-7 .
[32] M.-A. D. Storey, F. D. Fracchia, and H. A. Müller. “Cognitive Design El-
ements to Support the Construction of a Mental Model during Software
Exploration”. In: Journal of Systems and Software 44.3 (1999), pp. 171–185.
issn: 0164-1212. doi:10.1016/S0164-1212(98)10055-9 .
[33] J. Svajlenko and C. K. Roy. “BigCloneEval: A Clone Detection Tool Evalua-
tion Framework with BigCloneBench”. In: 2016 IEEE International Confer-
ence on Software Maintenance and Evolution (ICSME) . 2016, pp. 596–600.
doi:10.1109/ICSME.2016.62 .
[34] J. Visser, S. Rigal, R. van der Leek, P. van Eck, and G. Wijnholds. Building
Maintainable Software, Java Edition: Ten Guidelines for Future-Proof Code .
1st ed. O’Reilly, 2016. isbn: 9781491953525.
[35] L. Voinea and A. C. Telea. “Visual Clone Analysis with SolidSDD”. In: Pro-
ceedings of the Second IEEE Working Conference on Software Visualization .
IEEE, 2014, pp. 79–82. doi:10.1109/VISSOFT.2014.22 .
[36] V. Zaytsev. “Modelling of Language Syntax and Semantics: The Case of the
Assembler Compiler”. In: Journal of Object Technology 19.2 (July 2020). Ed.
by A. Vallecillo. The 16th European Conference on Modelling Foundations
and Applications (ECMFA 2020), 5:1–22. issn: 1660-1769. doi:10.5381/
jot.2020.19.2.a5 .
[37] V. Zaytsev. “Software Language Engineers’ Worst Nightmare”. In: Proceed-
ings of Software Language Engineering 2020 (SLE 2020) . Nov. 2020. doi:
10.1145/3426425.3426933 .
26